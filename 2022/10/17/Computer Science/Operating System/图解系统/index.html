<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>图解系统 | Quanrui&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="Quanrui's Blog" />
  
  <meta name="description" content="1 硬件结构1.1 冯诺依曼模型在 1945 年冯诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了图灵机的设计，而且还提出用电子元件构造计算机，并约定了用二进制进行计算和存储。 最重要的是定义计算机基本结构为 5 个部分，分别是运算器、控制器、存储器、输入设备、输出设备，这 5 个部分也被称为冯诺依曼模型。   运算器、控制器是在CPU里的，存储器就我们常见的内存，输入输出设备则是计">
<meta property="og:type" content="article">
<meta property="og:title" content="图解系统">
<meta property="og:url" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/index.html">
<meta property="og:site_name" content="Quanrui&#39;s Blog">
<meta property="og:description" content="1 硬件结构1.1 冯诺依曼模型在 1945 年冯诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了图灵机的设计，而且还提出用电子元件构造计算机，并约定了用二进制进行计算和存储。 最重要的是定义计算机基本结构为 5 个部分，分别是运算器、控制器、存储器、输入设备、输出设备，这 5 个部分也被称为冯诺依曼模型。   运算器、控制器是在CPU里的，存储器就我们常见的内存，输入输出设备则是计">
<meta property="og:locale">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/image-20221018175333096.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%95%B0%E6%8D%AE%E6%AE%B5%E4%B8%8E%E6%AD%A3%E6%96%87%E6%AE%B5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%AD%98%E5%82%A8%E5%8C%BA%E5%88%86%E7%BA%A7.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E5%85%B3%E7%B3%BB%E5%9B%BE.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%AD%98%E5%82%A8%E5%99%A8%E6%88%90%E6%9C%AC%E7%9A%84%E5%AF%B9%E6%AF%94.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%BC%93%E5%AD%98%E4%BD%93%E7%B3%BB1.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/CPU%E6%9E%B6%E6%9E%84.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%86%99%E7%9B%B4%E8%BE%BE.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%86%99%E5%9B%9E1.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E4%BE%8B%E5%AD%90.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E4%BE%8B%E5%AD%902.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/MESI%E5%8D%8F%E8%AE%AE.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/int1.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%8F%8D%E7%A0%81.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E9%9D%9E%E5%8F%8D%E7%A0%81.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E9%9D%9E%E5%8F%8D%E7%A0%81%E8%BF%90%E7%AE%97.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E8%A1%A5%E7%A0%81%E8%BF%90%E7%AE%97%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%8D%81%E8%BF%9B%E5%88%B6%E5%B0%8F%E6%95%B0%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%97%A0%E9%99%90%E5%B0%8F%E6%95%B0.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%B0%8F%E6%95%B0%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B62.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/IEEE%E6%A0%87%E5%87%86.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/float.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/float%E5%AD%98%E5%82%A8.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/float%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BE%8B%E5%AD%90.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/72ab76ba697e470b8ceb14d5fc5688d9.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/a9ed979e2ed8414f9828767592aadc21.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/c5e2ab63e6ee4c8db575f3c7c9c85962.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/6142bc3c917e4a6298bdb62936e0d332.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/08a8e315fedc4a858060db5cb4a654af.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/7884f4d8db4949f7a5bb4bbd0f452609.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/8f187878c809414ca2486b0b71e8880e.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/19296e249b2240c29f9c52be70f611d5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%9B%9B%E7%BA%A7%E5%88%86%E9%A1%B5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/a3cdf27646b24614a64cfc5d7ccffa35.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E9%A1%B5%E8%A1%A8%E9%A1%B9%E5%AD%97%E6%AE%B5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%9C%80%E4%BC%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/FIFO%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%97%B6%E9%92%9F%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/8904fb89ae0c49c4b0f2f7b5a0a7b099.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/3a6cb4e3f27241d3b09b4766bb0b1124.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/48403193b7354e618bf336892886bcff.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/5-%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/12-PCB%E7%8A%B6%E6%80%81%E9%93%BE%E8%A1%A8%E7%BB%84%E7%BB%87.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/13-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/14-%E5%8D%95%E7%BA%BF%E7%A8%8Bmp4%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/15-%E5%A4%9A%E8%BF%9B%E7%A8%8Bmp4-%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/17-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B-%E4%B8%80%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/18-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B-%E4%B8%80%E5%AF%B9%E4%B8%80%E5%85%B3%E7%B3%BB.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/19-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/22-LWP.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/4-%E8%BF%9B%E7%A8%8B%E7%A9%BA%E9%97%B4.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/9-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/10-%E4%BF%A1%E5%8F%B7%E9%87%8F-%E4%BA%92%E6%96%A5.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/11-%E4%BF%A1%E5%8F%B7%E9%87%8F-%E5%90%8C%E6%AD%A5.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E4%BA%92%E6%96%A5%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%8C%81%E6%9C%89%E5%B9%B6%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E4%B8%8D%E5%8F%AF%E5%89%A5%E5%A4%BA%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%8E%AF%E8%B7%AF%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%9B%AE%E5%BD%95%E9%A1%B9%E5%92%8C%E7%B4%A2%E5%BC%95%E5%85%B3%E7%B3%BB%E5%9B%BE.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%86%99%E5%88%B0%E7%A3%81%E7%9B%98%E8%BF%87%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%96%87%E4%BB%B6%E5%88%86%E9%85%8D%E8%A1%A8.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E9%93%BE%E5%BC%8F%E7%B4%A2%E5%BC%95%E5%9D%97.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%9D%97.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83-20221019142022165.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A9%BA%E9%97%B2%E8%A1%A8%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A9%BA%E9%97%B2%E5%9D%97%E9%93%BE%E8%A1%A8.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%9D%97%E7%BB%84.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%9B%AE%E5%BD%95%E5%93%88%E5%B8%8C%E8%A1%A8.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A1%AC%E9%93%BE%E6%8E%A5-2.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E8%BD%AF%E9%93%BE%E6%8E%A5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/72568a29816fa9b505f15edac68adee2.jpeg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/cbba24cac4668625c4e32d8cf641cf9c.jpeg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/503d7d5d3f330d64fcade48b312f767d.jpeg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/1541c881598f554920355f0a3c5780fd.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.jpg">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%9C%80%E7%9F%AD%E5%AF%BB%E9%81%93%E6%97%B6%E9%97%B4%E4%BC%98%E5%85%88.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-SCAN%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-LOOK%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-LOOK%E7%AE%97%E6%B3%95.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/I_O%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/DMA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/I_O%E8%BD%AF%E4%BB%B6%E5%88%86%E5%B1%82.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/tcp_socket.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%A4%9A%E8%BF%9B%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E7%BA%BF%E7%A8%8B%E6%B1%A0.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/epoll.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/Proactor.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/d3279ad754257977f98e702cb156e9cf.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/025ddcaabece1f4b5823dfb1fb7340ef.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/ed14c96417e08b4f916e0cd23d12b7bd.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/392c54cfb9ec47f5191008aa1d27d6b5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/0ea3960fef48d4cbaeb4bec4345301e7.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/83d7f363643353c92d252e34f1d4f687.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/30c2c70721c12f9c140358fbdc5f2282.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/f8909edef2f3949f8945bb99380baab3.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/31485046f1303b57d8aaeaab103ea7ab.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/d528bae6fcec2357ba2eb8f324ad9fd5.png">
<meta property="og:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/dbb57b8d6071d011d05eeadd93269e13.png">
<meta property="article:published_time" content="2022-10-17T05:26:24.000Z">
<meta property="article:modified_time" content="2023-01-01T10:42:10.519Z">
<meta property="article:author" content="MU Quanrui">
<meta property="article:tag" content="Computer Science">
<meta property="article:tag" content="Operating System">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/images/image-20221018175333096.png">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

  
<link rel="stylesheet" href="/css/style.css">


 <!--加载prettify代码高亮样式-->
<link href="/google-code-prettify/tranquil-heart.css" type="text/css" rel="stylesheet" />

  
<script src="/js/pace.min.js"></script>

  

  
  


  <!--加载条样式-->
  <style>
    .pace .pace-progress {
    	background-image: linear-gradient(90deg, #F79533 0%, #F37055 15%, #EF4E7B 30%, #A166AB 44%, #5073B8 58%, #1098AD 72%, #07B39B 86%, #6DBA82 100%);
    	height: 3px;
    }
    .pace .pace-progress-inner {
     	box-shadow: 0 0 10px #1E92FB, 0 0 5px #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
    	border-top-color: #1E92FB;	/*上边框颜色*/
    	border-left-color: #1E92FB;	/*左边框颜色*/
    }
  </style>

<meta name="generator" content="Hexo 5.2.0"></head>


<body>
  <div id="background"></div><!--背景颜色/图片-->
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">

        <div id="header-menu" class="header-menu-pos animated">


<a target="_blank" rel="noopener" href="https://github.com/muquanrui" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#FFA500; color:#fff; position: absolute; top: 0; border: 0; left: 0; transform: scale(-1, 1);" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>


            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">Quanrui&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                    <a  href="/categories">
                        <i class="fa fa-book"></i>
                        <span>Categories</span>
                    </a>
                    
                    <a  href="/tags">
                        <i class="fa fa-tags"></i>
                        <span>Tags</span>
                    </a>
                    
                    <a  href="/about">
                        <i class="fa fa-user"></i>
                        <span>About</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        Quanrui&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        Carpe diem.
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Home" target="_blank" href="//muquanrui.com">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="//github.com/muquanrui">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                        <a title="Google" target="_blank" href="//google.com">
                            <i class="fa fa-google fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-Computer Science/Operating System/图解系统" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="post-title" itemprop="name">
      图解系统
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/Operating-System/">Operating System</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2022-10-17
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>          
        </li>
      </ul>
       <span class="post-count">文章字数:65.2k字 &nbsp &nbsp  
         阅读时长:227分钟</span>
    </div>
  
        
          
      </header>
    

    <div class="article-entry post-content" itemprop="articleBody">

    
    



      
            
            <h1 id="1-硬件结构"><a href="#1-硬件结构" class="headerlink" title="1 硬件结构"></a>1 硬件结构</h1><h2 id="1-1-冯诺依曼模型"><a href="#1-1-冯诺依曼模型" class="headerlink" title="1.1 冯诺依曼模型"></a>1.1 冯诺依曼模型</h2><p>在 1945 年冯诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了图灵机的设计，而且还提出用电子元件构造计算机，并约定了用二进制进行计算和存储。</p>
<p>最重要的是定义计算机基本结构为 5 个部分，分别是<strong>运算器</strong>、<strong>控制器</strong>、<strong>存储器</strong>、<strong>输入设备</strong>、<strong>输出设备</strong>，这 5 个部分也被称为冯诺依曼模型。</p>
<img src="images/image-20221018175333096.png" alt="image-20221018175333096" style="zoom:50%;" />

<p>运算器、控制器是在CPU里的，存储器就我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。存储单元和输入输出设备要与CPU打交道的话，离不开总线。所以，它们之间的关系如下图：</p>
<p><img src="images/%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B.png" alt="img"></p>
<h3 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h3><p>我们的程序和数据都是存储在<strong>内存</strong>（Memory），存储的区域是线性的。在计算机数据存储中，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，这种结构好似我们程序里的数组，所以内存的读写任何一个数据的速度都是一样的。</p>
<h3 id="中央处理器"><a href="#中央处理器" class="headerlink" title="中央处理器"></a>中央处理器</h3><p>中央处理器也就是我们常说的 CPU，32 位和 64 位 CPU 最主要区别在于一次能计算多少字节数据：</p>
<ul>
<li>32 位 CPU 一次可以计算 4 个字节；</li>
<li>64 位 CPU 一次可以计算 8 个字节；</li>
</ul>
<p>这里的 32 位和 64 位，通常称为 CPU 的位宽。</p>
<p>之所以 CPU 要这样设计，是为了能计算更大的数值，如果是 8 位的 CPU，那么一次只能计算 1 个字节 0~255 范围内的数值，这样就无法一次完成计算 10000 * 500 ，于是为了能一次计算大数的运算，CPU 需要支持多个 byte 一起计算，所以 CPU 位宽越大，可以计算的数值就越大，比如说 32 位 CPU 能计算的最大整数是 4294967295。</p>
<p>CPU 内部还有一些组件，常见的有<strong>寄存器</strong>（Register）、<strong>控制单元</strong>（Control Unit）和<strong>逻辑运算单元</strong>（Arithmetic Logic Unit）等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。</p>
<p>寄存器主要作用是存储计算时的数据，你可能好奇为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快，常见的种类有：</p>
<ul>
<li>通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。</li>
<li>程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令的地址。</li>
<li>指令寄存器，用来存放程序计数器指向的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。</li>
</ul>
<h3 id="总线"><a href="#总线" class="headerlink" title="总线"></a>总线</h3><p><strong>总线</strong>（Bus）是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：</p>
<ul>
<li>地址总线，用于指定 CPU 将要操作的内存地址；</li>
<li>数据总线，用于读写内存的数据；</li>
<li>控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；</li>
</ul>
<p>当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线：</p>
<ol>
<li>首先要通过「地址总线」来指定内存的地址；</li>
<li>然后通过「控制总线」控制是读或写命令；</li>
<li>最后通过「数据总线」来传输数据；</li>
</ol>
<h3 id="输入、输出设备"><a href="#输入、输出设备" class="headerlink" title="输入、输出设备"></a>输入、输出设备</h3><p>输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。期间，如果输入设备是键盘，按下按键时是需要和 CPU 进行交互的，这时就需要用到控制总线了。</p>
<h2 id="1-2-线路位宽与-CPU-位宽"><a href="#1-2-线路位宽与-CPU-位宽" class="headerlink" title="1.2 线路位宽与 CPU 位宽"></a>1.2 线路位宽与 CPU 位宽</h2><p>数据是如何通过线路传输的呢？其实是通过操作电压，低电压表示 0，高压电压则表示 1。</p>
<p>如果构造了高低高这样的信号，其实就是 101 二进制数据，十进制则表示 5，如果只有一条线路，就意味着每次只能传递 1 bit 的数据，即 0 或 1，那么传输 101 这个数据，就需要 3 次才能传输完成，这样的效率非常低。</p>
<p>这样一位一位传输的方式，称为串行，下一个 bit 必须等待上一个 bit 传输完成才能进行传输。当然，想一次多传一些数据，增加线路即可，这时数据就可以并行传输。为了避免低效率的串行传输的方式，线路的位宽最好一次就能访问到所有的内存地址。</p>
<p>CPU 要想操作的内存地址就需要地址总线：</p>
<ul>
<li>如果地址总线只有 1 条，那每次只能表示 「0 或 1」这两种地址，所以 CPU 能操作的内存地址最大数量为 2（2^1）个（注意，不要理解成同时能操作 2 个内存地址）；</li>
<li>如果地址总线有 2 条，那么能表示 00、01、10、11 这四种地址，所以 CPU 能操作的内存地址最大数量为 4（2^2）个。</li>
</ul>
<p>那么，想要 CPU 操作 4G 大的内存，那么就需要 32 条地址总线，因为 2 ^ 32 = 4G。</p>
<p>CPU 的位宽最好不要小于线路位宽，比如 32 位 CPU 控制 40 位宽的地址总线和数据总线的话，工作起来就会非常复杂且麻烦，所以 32 位的 CPU 最好和 32 位宽的线路搭配，因为 32 位 CPU 一次最多只能操作 32 位宽的地址总线和数据总线。</p>
<p>如果用 32 位 CPU 去加和两个 64 位大小的数字，就需要把这 2 个 64 位的数字分成 2 个低位 32 位数字和 2 个高位 32 位数字来计算，先加个两个低位的 32 位数字，算出进位，然后加和两个高位的 32 位数字，最后再加上进位，就能算出结果了，可以发现 32 位 CPU 并不能一次性计算出加和两个 64 位数字的结果。</p>
<p>对于 64 位 CPU 就可以一次性算出加和两个 64 位数字的结果，因为 64 位 CPU 可以一次读入 64 位的数字，并且 64 位 CPU 内部的逻辑运算单元也支持 64 位数字的计算。</p>
<p>但是并不代表 64 位 CPU 性能比 32 位 CPU 高很多，很少应用需要算超过 32 位的数字，所以如果计算的数额不超过 32 位数字的情况下，32 位和 64 位 CPU 之间没什么区别的，只有当计算超过 32 位数字的情况下，64 位的优势才能体现出来。</p>
<p>另外，32 位 CPU 最大只能操作 4GB 内存，就算你装了 8 GB 内存条，也没用。而 64 位 CPU 寻址范围则很大，理论最大的寻址空间为 2^64（128T）。</p>
<h2 id="1-3-程序执行的基本过程"><a href="#1-3-程序执行的基本过程" class="headerlink" title="1.3 程序执行的基本过程"></a>1.3 程序执行的基本过程</h2><p>程序实际上是一条一条指令，所以程序的运行过程就是把每一条指令一步一步的执行起来，负责执行指令的就是 CPU 了。一个程序执行的时候，CPU 会根据程序计数器里的内存地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。</p>
<p>CPU 从程序计数器读取指令、到执行、再到下一条指令，这个过程会不断循环，直到程序执行结束，这个不断循环的过程被称为 <strong>CPU 的指令周期</strong>。</p>
<h3 id="a-1-2-执行具体过程"><a href="#a-1-2-执行具体过程" class="headerlink" title="a = 1 + 2 执行具体过程"></a>a = 1 + 2 执行具体过程</h3><p>CPU 是不认识 a = 1 + 2 这个字符串，这些字符串只是方便我们程序员认识，要想这段程序能跑起来，还需要把整个程序翻译成汇编语言的程序，这个过程称为编译成汇编代码。</p>
<p>针对汇编代码，我们还需要用汇编器翻译成机器码，这些机器码由 0 和 1 组成的机器语言，这一条条机器码，就是一条条的计算机指令，这个才是 CPU 能够真正认识的东西。</p>
<p>下面来看看 a = 1 + 2 在 32 位 CPU 的执行过程。</p>
<p>程序编译过程中，编译器通过分析代码，发现 1 和 2 是数据，于是程序运行时，内存会有个专门的区域来存放这些数据，这个区域就是「数据段」。如下图，数据 1 和 2 的区域位置：</p>
<ul>
<li>数据 1 被存放到 0x100 位置；</li>
<li>数据 2 被存放到 0x104 位置；</li>
</ul>
<p>注意，数据和指令是分开区域存放的，存放指令区域的地方称为「正文段」（或者叫程序段）。</p>
<p>编译器会把 a = 1 + 2 翻译成 4 条指令，存放到正文段中。如图，这 4 条指令被存放到了 0x200 ~ 0x20c 的区域中：</p>
<p><img src="images/%E6%95%B0%E6%8D%AE%E6%AE%B5%E4%B8%8E%E6%AD%A3%E6%96%87%E6%AE%B5.png" alt="img"></p>
<ul>
<li>0x200 的内容是 load 指令将 0x100 地址中的数据 1 装入到寄存器 R0；</li>
<li>0x204 的内容是 load 指令将 0x104 地址中的数据 2 装入到寄存器 R1；</li>
<li>0x208 的内容是 add 指令将寄存器 R0 和 R1 的数据相加，并把结果存放到寄存器 R2；</li>
<li>0x20c 的内容是 store 指令将寄存器 R2 中的数据存回数据段中的 0x108 地址中，这个地址也就是变量 a 内存中的地址；</li>
</ul>
<p>编译完成后，具体执行程序的时候，程序计数器会被设置为 0x200 地址，然后依次执行这 4 条指令。</p>
<h3 id="指令"><a href="#指令" class="headerlink" title="指令"></a>指令</h3><p>事实上指令的内容是一串二进制数字的机器码，每条指令都有对应的机器码，CPU 通过解析机器码来知道指令的内容。不同的 CPU 有不同的指令集，也就是对应着不同的汇编语言和不同的机器码。</p>
<p>指令从功能角度划分，可以分为 5 大类：</p>
<ul>
<li>数据传输类型的指令，比如 store/load 是寄存器与内存间数据传输的指令，mov 是将一个内存地址的数据移动到另一个内存地址的指令；</li>
<li>运算类型的指令，比如加减乘除、位运算、比较大小等等，它们最多只能处理两个寄存器中的数据；</li>
<li>跳转类型的指令，通过修改程序计数器的值来达到跳转执行指令的过程，比如编程中常见的 if-else、switch-case、函数调用等。</li>
<li>信号类型的指令，比如发生中断的指令 trap；</li>
<li>闲置类型的指令，比如指令 nop，执行后 CPU 会空转一个周期；</li>
</ul>
<p>CPU 的硬件参数都会有 GHz 这个参数，比如一个 1 GHz 的 CPU，指的是时钟频率是 1 G，代表着 1 秒会产生 1G 次数的脉冲信号，每一次脉冲信号高低电平的转换就是一个周期，称为<strong>时钟周期</strong>。对于 CPU 来说，在一个时钟周期内，CPU 仅能完成一个最基本的动作，时钟频率越高，时钟周期就越短，工作速度也就越快。</p>
<p>一个时钟周期一定能执行完一条指令吗？答案是不一定的，大多数指令不能在一个时钟周期完成，通常需要若干个时钟周期。不同的指令需要的时钟周期是不同的，加法和乘法都对应着一条 CPU 指令，但是乘法需要的时钟周期就要比加法多。</p>
<h2 id="1-4-存储器的层次结构"><a href="#1-4-存储器的层次结构" class="headerlink" title="1.4 存储器的层次结构"></a>1.4 存储器的层次结构</h2><p>我们想象中一个场景，大学期末准备考试了，你前去图书馆临时抱佛脚。那么，在看书的时候，我们的大脑会思考问题，也会记忆知识点，另外我们通常也会把常用的书放在自己的桌子上，当我们要找一本不常用的书，则会去图书馆的书架找。</p>
<p>就是这么一个小小的场景，已经把计算机的存储结构基本都涵盖了。</p>
<p>我们可以把 CPU 比喻成我们的大脑，大脑正在思考的东西，就好比 CPU 中的<strong>寄存器</strong>，处理速度是最快的，但是能存储的数据也是最少的，毕竟我们也不能一下同时思考太多的事情，除非你练过。</p>
<p>我们大脑中的记忆，就好比 <strong>CPU Cache</strong>，中文称为 CPU 高速缓存，处理速度相比寄存器慢了一点，但是能存储的数据也稍微多了一些。</p>
<p>CPU Cache 通常会分为 L1、L2、L3 三层，其中 <strong>L1 Cache</strong> 通常分成「数据缓存」和「指令缓存」，L1 是距离 CPU 最近的，因此它比 L2、L3 的读写速度都快、存储空间都小。我们大脑中短期记忆，就好比 L1 Cache，而长期记忆就好比 <strong>L2/L3 Cache</strong>。</p>
<p>寄存器和 CPU Cache 都是在 CPU 内部，跟 CPU 挨着很近，因此它们的读写速度都相当的快，但是能存储的数据很少，毕竟 CPU 就这么丁点大。</p>
<p>知道 CPU 内部的存储器的层次分布，我们放眼看看 CPU 外部的存储器。</p>
<p>当我们大脑记忆中没有资料的时候，可以从书桌或书架上拿书来阅读，那我们桌子上的书，就好比<strong>内存</strong>，我们虽然可以一伸手就可以拿到，但读写速度肯定远慢于寄存器，那图书馆书架上的书，就好比<strong>硬盘</strong>，能存储的数据非常大，但是读写速度相比内存差好几个数量级，更别说跟寄存器的差距了。</p>
<p>我们从图书馆书架取书，把书放到桌子上，再阅读书，我们大脑就会记忆知识点，然后再经过大脑思考，这一系列过程相当于，数据从硬盘加载到内存，再从内存加载到 CPU 的寄存器和 Cache 中，然后再通过 CPU 进行处理和计算。</p>
<p>对于存储器，它的速度越快、能耗会越高、而且材料的成本也是越贵的，以至于速度快的存储器的容量都比较小。CPU 里的寄存器和 Cache，是整个计算机存储器中价格最贵的，虽然存储空间很小，但是读写速度是极快的，而相对比较便宜的内存和硬盘，速度肯定比不上 CPU 内部的存储器，但是能弥补存储空间的不足。</p>
<p>存储器通常可以分为这么几个级别：</p>
<p><img src="images/%E5%AD%98%E5%82%A8%E5%8C%BA%E5%88%86%E7%BA%A7.png" alt="img"></p>
<p><img src="images/%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="img"></p>
<p><img src="images/%E5%AD%98%E5%82%A8%E5%99%A8%E6%88%90%E6%9C%AC%E7%9A%84%E5%AF%B9%E6%AF%94.png" alt="img"></p>
<h3 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h3><p>最靠近 CPU 的控制单元和逻辑计算单元的存储器，就是寄存器了，它使用的材料速度也是最快的，因此价格也是最贵的，那么数量不能很多。</p>
<p>存储器的数量通常在几十到几百之间，每个寄存器可以用来存储一定的字节（byte）的数据。比如：</p>
<p>32 位 CPU 中大多数寄存器可以存储 4 个字节；<br>64 位 CPU 中大多数寄存器可以存储 8 个字节。<br>寄存器的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写，CPU 时钟周期跟 CPU 主频息息相关，比如 2 GHz 主频的 CPU，那么它的时钟周期就是 1/2G，也就是 0.5ns（纳秒）。</p>
<p>CPU 处理一条指令的时候，除了读写寄存器，还需要解码指令、控制指令执行和计算。如果寄存器的速度太慢，则会拉长指令的处理周期，从而给用户的感觉，就是电脑「很慢」。</p>
<h3 id="CPU-Cache"><a href="#CPU-Cache" class="headerlink" title="CPU Cache"></a>CPU Cache</h3><p>CPU Cache 用的是一种叫 SRAM（Static Random-Access Memory，静态随机存储器） 的芯片。</p>
<p>SRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，而一旦断电，数据就会丢失了。</p>
<p>在 SRAM 里面，一个 bit 的数据，通常需要 6 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间下，能存储的数据是有限的，不过也因为 SRAM 的电路简单，所以访问速度非常快。</p>
<p>CPU 的高速缓存，通常可以分为 L1、L2、L3 这样的三层高速缓存，也称为一级缓存、二级缓存、三级缓存。</p>
<h4 id="L1-高速缓存"><a href="#L1-高速缓存" class="headerlink" title="L1 高速缓存"></a>L1 高速缓存</h4><p>L1 高速缓存的访问速度几乎和寄存器一样快，通常只需要 2~4 个时钟周期，而大小在几十 KB 到几百 KB 不等。</p>
<p>每个 CPU 核心都有一块属于自己的 L1 高速缓存，指令和数据在 L1 是分开存放的，所以 L1 高速缓存通常分成指令缓存和数据缓存。</p>
<h4 id="L2-高速缓存"><a href="#L2-高速缓存" class="headerlink" title="L2 高速缓存"></a>L2 高速缓存</h4><p>L2 高速缓存同样每个 CPU 核心都有，但是 L2 高速缓存位置比 L1 高速缓存距离 CPU 核心 更远，它大小比 L1 高速缓存更大，CPU 型号不同大小也就不同，通常大小在几百 KB 到几 MB 不等，访问速度则更慢，速度在 10~20 个时钟周期。</p>
<h4 id="L3-高速缓存"><a href="#L3-高速缓存" class="headerlink" title="L3 高速缓存"></a>L3 高速缓存</h4><p>L3 高速缓存通常是多个 CPU 核心共用的，位置比 L2 高速缓存距离 CPU 核心 更远，大小也会更大些，通常大小在几 MB 到几十 MB 不等，具体值根据 CPU 型号而定。</p>
<p>访问速度相对也比较慢一些，访问速度在 20~60个时钟周期。</p>
<h3 id="内存-1"><a href="#内存-1" class="headerlink" title="内存"></a>内存</h3><p>内存用的芯片和 CPU Cache 有所不同，它使用的是一种叫作 DRAM （Dynamic Random Access Memory，动态随机存取存储器） 的芯片。</p>
<p>相比 SRAM，DRAM 的密度更高，功耗更低，有更大的容量，而且造价比 SRAM 芯片便宜很多。</p>
<p>DRAM 存储一个 bit 数据，只需要一个晶体管和一个电容就能存储，但是因为数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原因，只有不断刷新，数据才能被存储起来。</p>
<p>DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问的速度会更慢，内存速度大概在 200~300 个 时钟周期之间。</p>
<h3 id="SSD-HDD-硬盘"><a href="#SSD-HDD-硬盘" class="headerlink" title="SSD/HDD 硬盘"></a>SSD/HDD 硬盘</h3><p>SSD（Solid-state disk） 就是我们常说的固体硬盘，结构和内存类似，但是它相比内存的优点是断电后数据还是存在的，而内存、寄存器、高速缓存断电后数据都会丢失。内存的读写速度比 SSD 大概快 10~1000 倍。</p>
<p>当然，还有一款传统的硬盘，也就是机械硬盘（Hard Disk Drive, HDD），它是通过物理读写的方式来访问数据的，因此它访问速度是非常慢的，它的速度比内存慢 10W 倍左右。</p>
<p>由于 SSD 的价格快接近机械硬盘了，因此机械硬盘已经逐渐被 SSD 替代了。</p>
<h3 id="存储器的层次关系"><a href="#存储器的层次关系" class="headerlink" title="存储器的层次关系"></a>存储器的层次关系</h3><p>CPU 并不会直接和每一种存储器设备直接打交道，而是<strong>每一种存储器设备只和它相邻的存储器设备打交道</strong>。</p>
<p>比如，CPU Cache 的数据是从内存加载过来的，写回数据的时候也只写回到内存，CPU Cache 不会直接把数据写到硬盘，也不会直接从硬盘加载数据，而是先加载到内存，再从内存加载到 CPU Cache 中。</p>
<p>另外，当 CPU 需要访问内存中某个数据的时候，如果寄存器有这个数据，CPU 就直接从寄存器取数据即可，如果寄存器没有这个数据，CPU 就会查询 L1 高速缓存，如果 L1 没有，则查询 L2 高速缓存，L2 还是没有的话就查询 L3 高速缓存，L3 依然没有的话，才去内存中取数据。因此存储层次结构也形成了缓存的体系。</p>
<p><img src="images/%E7%BC%93%E5%AD%98%E4%BD%93%E7%B3%BB1.png" alt="img"></p>
<h2 id="1-5-CPU-缓存一致性"><a href="#1-5-CPU-缓存一致性" class="headerlink" title="1.5 CPU 缓存一致性"></a>1.5 CPU 缓存一致性</h2><p>现代CPU的架构：</p>
<p><img src="images/CPU%E6%9E%B6%E6%9E%84.png" alt="img"></p>
<p>CPU Cache 是由很多个 Cache Line 组成的，CPU Line 是 CPU 从内存读取数据的基本单位，而 CPU Line 是由各种标志（Tag）+ 数据块（Data Block）组成，你可以在下图清晰的看到：</p>
<p><img src="images/Cache%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84.png" alt="img"></p>
<p>我们当然期望 CPU 读取数据的时候，都是尽可能地从 CPU Cache 中读取，而不是每一次都要从内存中获取数据。所以，身为程序员，我们要尽可能写出缓存命中率高的代码，这样就有效提高程序的性能。</p>
<p>事实上，数据不光是只有读操作，还有写操作，那么如果数据写入 Cache 之后，内存与 Cache 相对应的数据将会不同，这种情况下 Cache 和内存数据都不一致了，于是我们肯定是要把 Cache 中的数据同步到内存里的。</p>
<p>问题来了，那在什么时机才把 Cache 中的数据写回到内存呢？为了应对这个问题，下面介绍两种针对写入数据的方法：</p>
<ul>
<li>写直达（Write Through）</li>
<li>写回（Write Back）</li>
</ul>
<h3 id="写直达"><a href="#写直达" class="headerlink" title="写直达"></a>写直达</h3><p>保持内存与 Cache 一致性最简单的方式是，把数据同时写入内存和 Cache 中，这种方法称为写直达（Write Through）。</p>
<p><img src="images/%E5%86%99%E7%9B%B4%E8%BE%BE.png" alt="img"></p>
<p>在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了：</p>
<ul>
<li>如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；</li>
<li>如果数据没有在 Cache 里面，就直接把数据更新到内存里面。</li>
</ul>
<p>写直达法很直观，也很简单，但是问题明显，无论数据在不在 Cache 里面，每次写操作都会写回到内存，这样写操作将会花费大量的时间，无疑性能会受到很大的影响。</p>
<h3 id="写回"><a href="#写回" class="headerlink" title="写回"></a>写回</h3><p>为了要减少数据写回内存的频率，就出现了写回（Write Back）的方法。</p>
<p>在写回机制中，当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提高系统的性能。</p>
<p><img src="images/%E5%86%99%E5%9B%9E1.png" alt="img"></p>
<ul>
<li>如果当发生写操作时，数据已经在 CPU Cache 里的话，则把数据更新到 CPU Cache 里，同时标记 CPU Cache 里的这个 Cache Block 为脏（Dirty）的，这个脏的标记代表这个时候，我们 CPU Cache 里面的这个 Cache Block 的数据和内存是不一致的，这种情况是不用把数据写到内存里的；</li>
<li>如果当发生写操作时，数据所对应的 Cache Block 里存放的是「别的内存地址的数据」的话，就要检查这个 Cache Block 里的数据有没有被标记为脏的：</li>
<li>如果是脏的话，我们就要把这个 Cache Block 里的数据写回到内存，然后再把当前要写入的数据，先从内存读入到 Cache Block 里，然后再把当前要写入的数据写入到 Cache Block，最后也把它标记为脏的；</li>
<li>如果 Cache Block 里面的数据没有被标记为脏，则就直接将数据写入到这个 Cache Block 里，然后再把这个 Cache Block 标记为脏的就好了。</li>
</ul>
<p>可以发现写回这个方法，在把数据写入到 Cache 的时候，只有在缓存不命中，同时数据对应的 Cache 中的 Cache Block 为脏标记的情况下，才会将数据写到内存中，而在缓存命中的情况下，则在写入后 Cache 后，只需把该数据对应的 Cache Block 标记为脏即可，而不用写到内存里。</p>
<p>这样的好处是，如果我们大量的操作都能够命中缓存，那么大部分时间里 CPU 都不需要读写内存，自然性能相比写直达会高很多。</p>
<p>为什么缓存没命中时，还要定位 cache block？这是因为此时是要判断数据即将写入到 cache block 里的位置，是否被「其他数据」占用了此位置，如果这个「其他数据」是脏数据，那么就要帮忙把它写回到内存。</p>
<h3 id="缓存一致性问题"><a href="#缓存一致性问题" class="headerlink" title="缓存一致性问题"></a>缓存一致性问题</h3><p>现在 CPU 都是多核的，由于 L1/L2 Cache 是多个核心各自独有的，那么会带来多核心的缓存一致性（Cache Coherence） 的问题，如果不能保证缓存一致性的问题，就可能造成结果错误。</p>
<p>假设 A 号核心和 B 号核心同时运行两个线程，都操作共同的变量 i（初始值为 0 ）。</p>
<p><img src="images/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E4%BE%8B%E5%AD%90.png" alt="img"></p>
<p>这时如果 A 号核心执行了 i++ 语句的时候，为了考虑性能，使用了我们前面所说的写回策略，先把值为 1 的执行结果写入到 L1/L2 Cache 中，然后把 L1/L2 Cache 中对应的 Block 标记为脏的，这个时候数据其实没有被同步到内存中的，因为写回策略，只有在 A 号核心中的这个 Cache Block 要被替换的时候，数据才会写入到内存里。</p>
<p>如果这时旁边的 B 号核心尝试从内存读取 i 变量的值，则读到的将会是错误的值，因为刚才 A 号核心更新 i 值还没写入到内存中，内存中的值还依然是 0。这个就是所谓的缓存一致性问题，A 号核心和 B 号核心的缓存，在这个时候是不一致，从而会导致执行结果的错误。</p>
<p><img src="images/%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E4%BE%8B%E5%AD%902.png" alt="img"></p>
<p>那么，要解决这一问题，就需要一种机制，来同步两个不同核心里面的缓存数据。要实现的这个机制的话，要保证做到下面这 2 点：</p>
<ul>
<li>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（Write Propagation）；</li>
<li>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串行化（Transaction Serialization）。</li>
</ul>
<p>第一点写传播很容易就理解，当某个核心在 Cache 更新了数据，就需要同步到其他核心的 Cache 里。而对于第二点事务的串行化，我们举个例子来理解它。</p>
<p>假设我们有一个含有 4 个核心的 CPU，这 4 个核心都操作共同的变量 i（初始值为 0 ）。A 号核心先把 i 值变为 100，而此时同一时间，B 号核心先把 i 值变为 200，这里两个修改，都会「传播」到 C 和 D 号核心。</p>
<p>那么问题就来了，C 号核心先收到了 A 号核心更新数据的事件，再收到 B 号核心更新数据的事件，因此 C 号核心看到的变量 i 是先变成 100，后变成 200；而如果 D 号核心收到的事件是反过来的，则 D 号核心看到的是变量 i 先变成 200，再变成 100，虽然是做到了写传播，但是各个 Cache 里面的数据还是不一致的。</p>
<p>所以，我们要保证 C 号核心和 D 号核心都能看到相同顺序的数据变化，比如变量 i 都是先变成 100，再变成 200，这样的过程就是事务的串行化。</p>
<p>要实现事务串行化，要做到 2 点：</p>
<ul>
<li>CPU 核心对于 Cache 中数据的操作，需要同步给其他 CPU 核心；</li>
<li>要引入「锁」的概念，如果两个 CPU 核心里有相同数据的 Cache，那么对于这个 Cache 数据的更新，只有拿到了「锁」，才能进行对应的数据更新。</li>
</ul>
<h3 id="总线嗅探"><a href="#总线嗅探" class="headerlink" title="总线嗅探"></a>总线嗅探</h3><p>写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。最常见实现的方式是总线嗅探（Bus Snooping）。</p>
<p>还是以前面的 i 变量例子来说明总线嗅探的工作机制，当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的广播事件，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache。</p>
<p>可以发现，总线嗅探方法很简单， CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这无疑会加重总线的负载。</p>
<p>另外，总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串行化。</p>
<p>于是，有一个协议基于总线嗅探机制实现了事务串行化，也用状态机机制降低了总线带宽压力，这个协议就是 MESI 协议，这个协议就做到了 CPU 缓存一致性。</p>
<h3 id="MESI-协议"><a href="#MESI-协议" class="headerlink" title="MESI 协议"></a>MESI 协议</h3><p>MESI 协议其实是 4 个状态单词的开头字母缩写，分别是：</p>
<ul>
<li>Modified，已修改</li>
<li>Exclusive，独占</li>
<li>Shared，共享</li>
<li>Invalidated，已失效</li>
</ul>
<p>这四个状态来标记 Cache Line 四个不同的状态：</p>
<ul>
<li>「已修改」状态就是我们前面提到的脏标记，代表该 Cache Block 上的数据已经被更新过，但是还没有写到内存里。</li>
<li>「已失效」状态，表示的是这个 Cache Block 里的数据已经失效了，不可以读取该状态的数据。</li>
<li>「独占」和「共享」状态都代表 Cache Block 里的数据是干净的，也就是说，这个时候 Cache Block 里的数据和内存里面的数据是一致性的。<ul>
<li>「独占」和「共享」的差别在于，独占状态的时候，数据只存储在一个 CPU 核心的 Cache 里，而其他 CPU 核心的 Cache 没有该数据。这个时候，如果要向独占的 Cache 写数据，就可以直接自由地写入，而不需要通知其他 CPU 核心，因为只有你这有这个数据，就不存在缓存一致性的问题了，于是就可以随便操作该数据。</li>
<li>在「独占」状态下的数据，如果有其他核心从内存读取了相同的数据到各自的 Cache ，那么这个时候，独占状态下的数据就会变成共享状态。那么「共享」状态代表着相同的数据在多个 CPU 核心的 Cache 里都有，所以当我们要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后再更新当前 Cache 里面的数据。</li>
</ul>
</li>
</ul>
<p>举个具体的例子来看看这四个状态的转换：</p>
<ol>
<li>当 A 号 CPU 核心从内存读取变量 i 的值，数据被缓存在 A 号 CPU 核心自己的 Cache 里面，此时其他 CPU 核心的 Cache 没有缓存该数据，于是标记 Cache Line 状态为「独占」，此时其 Cache 中的数据与内存是一致的；</li>
<li>然后 B 号 CPU 核心也从内存读取了变量 i 的值，此时会发送消息给其他 CPU 核心，由于 A 号 CPU 核心已经缓存了该数据，所以会把数据返回给 B 号 CPU 核心。在这个时候， A 和 B 核心缓存了相同的数据，Cache Line 的状态就会变成「共享」，并且其 Cache 中的数据与内存也是一致的；</li>
<li>当 A 号 CPU 核心要修改 Cache 中 i 变量的值，发现数据对应的 Cache Line 的状态是共享状态，则要向所有的其他 CPU 核心广播一个请求，要求先把其他核心的 Cache 中对应的 Cache Line 标记为「无效」状态，然后 A 号 CPU 核心才更新 Cache 里面的数据，同时标记 Cache Line 为「已修改」状态，此时 Cache 中的数据就与内存不一致了。</li>
<li>如果 A 号 CPU 核心「继续」修改 Cache 中 i 变量的值，由于此时的 Cache Line 是「已修改」状态，因此不需要给其他 CPU 核心发送消息，直接更新数据即可。</li>
<li>如果 A 号 CPU 核心的 Cache 里的 i 变量对应的 Cache Line 要被「替换」，发现 Cache Line 状态是「已修改」状态，就会在替换前先把数据同步到内存。</li>
</ol>
<p>所以，可以发现当 Cache Line 状态是「已修改」或者「独占」状态时，修改更新其数据不需要发送广播给其他 CPU 核心，这在一定程度上减少了总线带宽压力。</p>
<p>事实上，整个 MESI 的状态可以用一个有限状态机来表示它的状态流转。还有一点，对于不同状态触发的事件操作，可能是来自本地 CPU 核心发出的广播事件，也可以是来自其他 CPU 核心通过总线发出的广播事件。下图即是 MESI 协议的状态图：</p>
<p><img src="images/MESI%E5%8D%8F%E8%AE%AE.png" alt="img"></p>
<p>![img](images/ MESI状态转换表格.png)</p>
<h2 id="1-6-数字在计算机中的表示"><a href="#1-6-数字在计算机中的表示" class="headerlink" title="1.6 数字在计算机中的表示"></a>1.6 数字在计算机中的表示</h2><h3 id="为什么负数要用补码表示？"><a href="#为什么负数要用补码表示？" class="headerlink" title="为什么负数要用补码表示？"></a>为什么负数要用补码表示？</h3><p>十进制数转二进制采用的是除 2 取余法，比如数字 8 转二进制的过程如下图：</p>
<p><img src="images/%E5%8D%81%E8%BF%9B%E5%88%B6%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6.png" alt="img"></p>
<p>「整数类型」的数字在计算机的存储方式很简单，也很直观，就是将十进制的数字转换成二进制即可。</p>
<p>我们以 int 类型的数字作为例子，int 类型是 32 位的，其中最高位是作为「符号标志位」，正数的符号位是 0，负数的符号位是 1，剩余的 31 位则表示二进制数据。</p>
<p>那么，对于 int 类型的数字 1 的二进制数表示如下：</p>
<p><img src="images/int1.png" alt="img"></p>
<p>负数在计算机中是以「补码」表示的，所谓的补码就是把正数的二进制全部取反再加 1，比如 -1 的二进制是把数字 1 的二进制取反后再加 1，如下图：</p>
<p><img src="images/%E5%8F%8D%E7%A0%81.png" alt="img"></p>
<p>为什么计算机要用补码的方式来表示负数？在回答这个问题前，我们假设不用补码的方式来表示负数，而只是把最高位的符号标志位变为 1 表示负数，如下图过程：</p>
<p><img src="images/%E9%9D%9E%E5%8F%8D%E7%A0%81.png" alt="img"></p>
<p>如果采用这种方式来表示负数的二进制的话，试想一下 -2 + 1 的运算过程，如下图：</p>
<p><img src="images/%E9%9D%9E%E5%8F%8D%E7%A0%81%E8%BF%90%E7%AE%97.png" alt="img"></p>
<p>按道理，-2 + 1 = -1，但是上面的运算过程中得到结果却是 -3，可以发现，这种负数的表示方式是不能用常规的加法来计算了，需要特殊处理，比如可以先判断数字是否为负数，如果是负数就要把加法操作变成减法操作才可以得到正确对结果。</p>
<p>因此，如果负数不是使用补码的方式表示，在做基本对加减法运算的时候还需要多一步操作来判断是否为负数，如果为负数，还得把加法反转成减法，或者把减法反转成加法，这就非常不好了，毕竟加减法运算在计算机里是很常使用的，所以为了性能考虑，应该要尽量简化这个运算过程。</p>
<p>而用了补码的表示方式，对于负数的加减法操作，实际上是和正数加减法操作一样的。你可以看到下图，用补码表示的负数在运算 -2 + 1 过程的时候，其结果是正确的：</p>
<p><img src="images/%E8%A1%A5%E7%A0%81%E8%BF%90%E7%AE%97%E8%BF%87%E7%A8%8B.png" alt="img"></p>
<h3 id="十进制小数与二进制的转换"><a href="#十进制小数与二进制的转换" class="headerlink" title="十进制小数与二进制的转换"></a>十进制小数与二进制的转换</h3><p>数部分的转换不同于整数部分，它采用的是乘 2 取整法，将十进制中的小数部分乘以 2 作为二进制的一位，然后继续取小数部分乘以 2 作为下一位，直到不存在小数为止。</p>
<p>以 8.625 转二进制作为例子，直接上图：</p>
<p><img src="images/%E5%8D%81%E8%BF%9B%E5%88%B6%E5%B0%8F%E6%95%B0%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6.png" alt="img"></p>
<p>最后把「整数部分 + 小数部分」结合在一起后，其结果就是 1000.101。</p>
<p>但是，并不是所有小数都可以用二进制表示，前面提到的 0.625 小数是一个特例，刚好通过乘 2 取整法的方式完整的转换成二进制。</p>
<p>如果我们用相同的方式，来把 0.1 转换成二进制，过程如下：</p>
<p><img src="images/%E6%97%A0%E9%99%90%E5%B0%8F%E6%95%B0.png" alt="img"></p>
<p>可以发现，0.1 的二进制表示是无限循环的。</p>
<p>由于计算机的资源是有限的，所以是没办法用二进制精确的表示 0.1，只能用「近似值」来表示，就是在有限的精度情况下，最大化接近 0.1 的二进制数，于是就会<strong>造成精度缺失的情况</strong>。</p>
<p>对于二进制小数转十进制时，需要注意一点，小数点后面的指数幂是负数。</p>
<p>比如，二进制 0.1 转成十进制就是 2^(-1)，也就是十进制 0.5，二进制 0.01 转成十进制就是 2^-2，也就是十进制 0.25，以此类推。</p>
<p>举个例子，二进制 1010.101 转十进制的过程，如下图：</p>
<p><img src="images/%E5%B0%8F%E6%95%B0%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B62.png" alt="img"></p>
<h3 id="计算机是怎么存小数的？"><a href="#计算机是怎么存小数的？" class="headerlink" title="计算机是怎么存小数的？"></a>计算机是怎么存小数的？</h3><p>1000.101 这种二进制小数是「定点数」形式，代表着小数点是定死的，不能移动，如果你移动了它的小数点，这个数就变了， 就不再是它原来的值了。</p>
<p>然而，计算机并不是这样存储的小数的，计算机存储小数的采用的是<strong>浮点数</strong>，名字里的「浮点」表示小数点是可以浮动的。</p>
<p>比如 1000.101 这个二进制数，可以表示成 1.000101 x 2^3，类似于数学上的科学记数法。</p>
<p>既然提到了科学计数法，我再帮大家复习一下。</p>
<p>比如有个很大的十进制数 1230000，我们可以也可以表示成 1.23 x 10^6，这种方式就称为科学记数法。</p>
<p>该方法在小数点左边只有一个数字，而且把这种整数部分没有前导 0 的数字称为规格化，比如 1.0 x 10^(-9) 是规格化的科学记数法，而 0.1 x 10^(-9) 和 10.0 x 10^(-9) 就不是了。</p>
<p>因此，如果二进制要用到科学记数法，同时要规范化，那么不仅要保证基数为 2，还要保证小数点左侧只有 1 位，而且必须为 1。</p>
<p>所以通常将 1000.101 这种二进制数，规格化表示成 1.000101 x 2^3，其中，最为关键的是 000101 和 3 这两个东西，它就可以包含了这个二进制小数的所有信息：</p>
<ul>
<li>000101 称为尾数，即小数点后面的数字；</li>
<li>3 称为指数，指定了小数点在数据中的位置；</li>
</ul>
<p>现在绝大多数计算机使用的浮点数，一般采用的是 IEEE 制定的国际标准，这种标准形式如下图：</p>
<p><img src="images/IEEE%E6%A0%87%E5%87%86.png" alt="img"></p>
<ul>
<li>符号位：表示数字是正数还是负数，为 0 表示正数，为 1 表示负数；</li>
<li>指数位：指定了小数点在数据中的位置，指数可以是负数，也可以是正数，指数位的长度越长则数值的表达范围就越大；</li>
<li>尾数位：小数点右侧的数字，也就是小数部分，比如二进制 1.0011 x 2^(-2)，尾数部分就是 0011，而且尾数的长度决定了这个数的精度，因此如果要表示精度更高的小数，则就要提高尾数位的长度；</li>
</ul>
<p>用 32 位来表示的浮点数，则称为单精度浮点数，也就是我们编程语言中的 float 变量，而用 64 位来表示的浮点数，称为双精度浮点数，也就是 double 变量，它们的结构如下：</p>
<p><img src="images/float.png" alt="img"></p>
<ul>
<li>double 的尾数部分是 52 位，float 的尾数部分是 23 位，由于同时都带有一个固定隐含位（这个后面会说），所以 double 有 53 个二进制有效位，float 有 24 个二进制有效位，所以所以它们的精度在十进制中分别是 log10(2^53) 约等于 15.95 和 log10(2^24) 约等于 7.22 位，因此 double 的有效数字是 15<del>16 位，float 的有效数字是 7</del>8 位，这些有效位是包含整数部分和小数部分；</li>
<li>double 的指数部分是 11 位，而 float 的指数位是 8 位，意味着 double 相比 float 能表示更大的数值范围；</li>
</ul>
<p>那二进制小数，是如何转换成二进制浮点数的呢？以 10.625 作为例子：</p>
<p><img src="images/float%E5%AD%98%E5%82%A8.png" alt="img"></p>
<p>首先，我们计算出 10.625 的二进制小数为 1010.101。</p>
<p>然后把小数点，移动到第一个有效数字后面，即将 1010.101 右移 3 位成 1.010101，右移 3 位就代表 +3，左移 3 位就是 -3。</p>
<p>float 中的「指数位」就跟这里移动的位数有关系，把移动的位数再加上「偏移量」，float 的话偏移量是 127，相加后就是指数位的值了，即指数位这 8 位存的是 10000010（十进制 130），因此你可以认为「指数位」相当于指明了小数点在数据中的位置。</p>
<p>1.010101 这个数的小数点右侧的数字就是 float 里的「尾数位」，由于尾数位是 23 位，则后面要补充 0，所以最终尾数位存储的数字是 01010100000000000000000。</p>
<p>在算指数的时候，你可能会有疑问为什么要加上偏移量呢？</p>
<p>前面也提到，指数可能是正数，也可能是负数，即指数是有符号的整数，而有符号整数的计算是比无符号整数麻烦的，所以为了减少不必要的麻烦，在实际存储指数的时候，需要把指数转换成无符号整数。</p>
<p>float 的指数部分是 8 位，IEEE 标准规定单精度浮点的指数取值范围是 -126 ~ +127，于是为了把指数转换成无符号整数，就要加个偏移量，比如 float 的指数偏移量是 127，这样指数就不会出现负数了。</p>
<p>比如，指数如果是 8，则实际存储的指数是 8 + 127（偏移量）= 135，即把 135 转换为二进制之后再存储，而当我们需要计算实际的十进制数的时候，再把指数减去「偏移量」即可。</p>
<p>细心的朋友肯定发现，移动后的小数点左侧的有效位（即 1）消失了，它并没有存储到 float 里。</p>
<p>这是因为 IEEE 标准规定，二进制浮点数的小数点左侧只能有 1 位，并且还只能是 1，既然这一位永远都是 1，那就可以不用存起来了。</p>
<p>于是就让 23 位尾数只存储小数部分，然后在计算时会自动把这个 1 加上，这样就可以节约 1 位的空间，尾数就能多存一位小数，相应的精度就更高了一点。</p>
<p>那么，对于我们在从 float 的二进制浮点数转换成十进制时，要考虑到这个隐含的 1，转换公式如下：</p>
<p><img src="images/float%E8%BD%AC%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%BE%8B%E5%AD%90.png" alt="img"></p>
<h3 id="0-1-0-2-0-3"><a href="#0-1-0-2-0-3" class="headerlink" title="0.1 + 0.2 == 0.3 ?"></a>0.1 + 0.2 == 0.3 ?</h3><p>前面提到过，并不是所有小数都可以用「完整」的二进制来表示的，比如十进制 0.1 在转换成二进制小数的时候，是一串无限循环的二进制数，计算机是无法表达无限循环的二进制数的，毕竟计算机的资源是有限。</p>
<p>因此，计算机只能用「近似值」来表示该二进制，那么意味着计算机存放的小数可能不是一个真实值。</p>
<p>因此，在计算机中 0.1 + 0.2 并不等于完整的 0.3。</p>
<p>这主要是因为有的小数无法用「完整」的二进制来表示，所以计算机里只能采用近似数的方式来保存，那两个近似数相加，得到的必然也是一个近似数。</p>
<h1 id="2-内存管理"><a href="#2-内存管理" class="headerlink" title="2 内存管理"></a>2 内存管理</h1><h2 id="2-1-虚拟内存"><a href="#2-1-虚拟内存" class="headerlink" title="2.1 虚拟内存"></a>2.1 虚拟内存</h2><p>单片机没有操作系统，每次写完代码，都需要借助工具把程序烧录进去，这样程序才能跑起来。而且，单片机的 CPU 是直接操作内存的「物理地址」。在这种情况下，要想在内存中同时运行两个程序是不可能的。如果第一个程序在 2000 的位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容，所以同时运行两个程序是根本行不通的，这两个程序会立刻崩溃。</p>
<p>这里关键的问题是这两个程序都引用了绝对物理地址，而这正是我们最需要避免的。操作系统是如何解决这个问题呢？</p>
<p>我们可以把进程所使用的地址「隔离」开来，即让操作系统为每个进程分配独立的一套「<strong>虚拟地址</strong>」，人人都有，大家自己玩自己的地址就行，互不干涉。但是有个前提：每个进程都不能直接访问物理地址，至于虚拟地址最终怎么落到物理内存里，对进程来说是透明的，操作系统已经把这些都安排的明明白白了。</p>
<p>因此，<strong>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来</strong>。程序访问虚拟地址的时候，由操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，这样就不会冲突了。</p>
<p>这里就引出了两种地址的概念：</p>
<ul>
<li>我们程序所使用的内存地址叫做<strong>虚拟内存地址（</strong>Virtual Memory Address）</li>
<li>实际存在硬件里面的空间地址叫<strong>物理内存地址</strong>（Physical Memory Address）。</li>
</ul>
<p>操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的<strong>内存管理单元</strong>（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存，如下图所示：</p>
<p><img src="images/72ab76ba697e470b8ceb14d5fc5688d9.png" alt="img"></p>
<p>那么操作系统如何管理虚拟地址与物理地址之间的关系？主要有两种方式，即分段管理和分页管理。</p>
<h2 id="2-2-内存分段"><a href="#2-2-内存分段" class="headerlink" title="2.2 内存分段"></a>2.2 内存分段</h2><h3 id="分段机制介绍"><a href="#分段机制介绍" class="headerlink" title="分段机制介绍"></a>分段机制介绍</h3><p>程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用<strong>分段</strong>（Segmentation）的形式把这些段分离出来。</p>
<p>分段机制下的虚拟地址由两部分组成：</p>
<ul>
<li><strong>段选择因子</strong>：段选择因子就保存在段寄存器里面。段选择因子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。</li>
<li><strong>段内偏移量</strong>：虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。</li>
</ul>
<p><img src="images/a9ed979e2ed8414f9828767592aadc21.png" alt="img"></p>
<p>在上面，知道了虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：</p>
<p><img src="images/c5e2ab63e6ee4c8db575f3c7c9c85962.png" alt="img"></p>
<p>如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。</p>
<p>分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：</p>
<ul>
<li>内存碎片的问题</li>
<li>内存交换的效率低的问题</li>
</ul>
<h3 id="内存碎片的问题"><a href="#内存碎片的问题" class="headerlink" title="内存碎片的问题"></a>内存碎片的问题</h3><p>我们来看看这样一个例子。假设有 1G 的物理内存，用户执行了多个程序，其中：</p>
<ul>
<li>游戏占用了 512MB 内存</li>
<li>浏览器占用了 128MB 内存</li>
<li>音乐占用了 256 MB 内存</li>
</ul>
<p>这个时候，如果我们关闭了浏览器，则空闲内存还有 1024 - 512 - 256 = 256MB。如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。</p>
<p><img src="images/6142bc3c917e4a6298bdb62936e0d332.png" alt="img"></p>
<p>内存碎片主要分为，<strong>内部内存碎片</strong>和<strong>外部内存碎片</strong>。内存分段管理可以做到段根据实际需求分配内存，所以有多少需求就分配多大的段，所以<strong>不会出现内部内存碎片</strong>。</p>
<p>但是由于每个段的长度不固定，所以多个段未必能恰好使用所有的内存空间，会产生了多个不连续的小物理内存，导致新的程序无法被装载，所以<strong>会出现外部内存碎片的问题</strong>。</p>
<p>解决「外部内存碎片」的问题可以使用<strong>内存交换</strong>。把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里，不过在读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。</p>
<p>这个内存交换空间，在 Linux 系统里也就是我们常看到的 <code>Swap</code> 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。</p>
<h3 id="内存交换的效率低的问题"><a href="#内存交换的效率低的问题" class="headerlink" title="内存交换的效率低的问题"></a>内存交换的效率低的问题</h3><p>对于多进程的系统来说，用分段的方式，外部内存碎片是很容易产生的，产生了外部内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。</p>
<p>因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。</p>
<p>所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。</p>
<p>为了解决内存分段的「外部内存碎片」和「内存交换效率低」的问题，就出现了内存分页。</p>
<h2 id="2-3-内存分页"><a href="#2-3-内存分页" class="headerlink" title="2.3 内存分页"></a>2.3 内存分页</h2><h3 id="分页机制介绍"><a href="#分页机制介绍" class="headerlink" title="分页机制介绍"></a>分页机制介绍</h3><p>要解决分段机制的这些问题，那么就要想出能少出现一些内存碎片的办法。另外，当需要进行内存交换的时候，让需要交换写入或者从磁盘装载的数据更少一点，这样就可以解决问题了。这个办法，也就是内存<strong>分页</strong>（Paging）。</p>
<p>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫<strong>页</strong>（Page）。在 Linux 下，每一页的大小为 <code>4KB</code>。</p>
<p>虚拟地址与物理地址之间通过页表来映射，如下图：</p>
<p><img src="images/08a8e315fedc4a858060db5cb4a654af.png" alt="img"></p>
<p>页表是存储在内存里的，<strong>内存管理单元</strong>（MMU）就做将虚拟内存地址转换成物理地址的工作。而当进程访问的虚拟地址在页表中查不到时，系统会产生一个<strong>缺页异常</strong>，由用户态切换到内核态，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。</p>
<h3 id="分页如何解决分段的问题？"><a href="#分页如何解决分段的问题？" class="headerlink" title="分页如何解决分段的问题？"></a>分页如何解决分段的问题？</h3><p>内存分页由于内存空间都是预先划分好的，也就不会像内存分段一样，在段与段之间会产生间隙非常小的内存，这正是分段会产生外部内存碎片的原因。而采用了分页，<strong>页与页之间是紧密排列的，所以不会有外部碎片</strong>。</p>
<p>但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制<strong>会有内部内存碎片的现象</strong>。</p>
<p>如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉（LRU），也就是暂时写在硬盘上，称为<strong>换出</strong>（Swap Out）。一旦需要的时候，再加载进来，称为<strong>换入</strong>（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，<strong>内存交换的效率就相对比较高</strong>。</p>
<p>更进一步地，分页的方式使得我们在<strong>加载程序的时候，不再需要一次性都把程序加载到物理内存中</strong>。我们完全可以在进行虚拟内存和物理内存的页之间映射后，不直接真的把页加载到物理内存里，而是只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。</p>
<h3 id="虚拟地址和物理地址的映射"><a href="#虚拟地址和物理地址的映射" class="headerlink" title="虚拟地址和物理地址的映射"></a>虚拟地址和物理地址的映射</h3><p>在分页机制下，虚拟地址分为两部分，<strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图：</p>
<p><img src="images/7884f4d8db4949f7a5bb4bbd0f452609.png" alt="img"></p>
<p>对于一个内存地址转换，其实就是这样三个步骤：</p>
<ol>
<li>把虚拟内存地址，切分成页号和偏移量；</li>
<li>根据页号，从页表里面，查询对应的物理页号；</li>
<li>直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。</li>
</ol>
<h3 id="多级页表"><a href="#多级页表" class="headerlink" title="多级页表"></a>多级页表</h3><p>虚拟内存的页和物理内存的页又是如何映射呢？</p>
<p><img src="images/8f187878c809414ca2486b0b71e8880e.png" alt="img"></p>
<p>上图展示了一个简单的分页映射，这看起来似乎没什么毛病，但是放到实际中操作系统，这种简单的分页是肯定会有问题，主要是存在<strong>空间上的缺陷</strong>。</p>
<p>因为操作系统是可以同时运行非常多的进程的，这就意味着页表会非常的庞大。</p>
<p>比如在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），那么就有大约 100 万 （2^20） 个页，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表，那么，100 个进程的话，就需要 400MB 的内存来存储页表，这是非常大的内存了，更别说 64 位的环境了。</p>
<p>要解决上面的问题，就需要采用一种叫作<strong>多级页表</strong>（Multi-Level Page Table）的解决方案。</p>
<p>在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 4KB 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：</p>
<p><img src="images/19296e249b2240c29f9c52be70f611d5.png" alt="img"></p>
<p>问题是，分了二级表，映射 4GB 地址空间就需要 4KB（一级页表）+ 4MB（二级页表）的内存，这样占用空间不是更大了吗？当然，如果 4GB 的虚拟地址全部都映射到了物理内存上的话，二级分页占用空间确实是更大了，但是，我们往往不会为一个进程分配那么多内存。</p>
<p>每个进程都有 4GB 的虚拟地址空间，而显然对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。</p>
<p>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即<strong>可以在需要时才创建二级页表</strong>。做个简单的计算，假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）= 0.804MB，这对比单级页表的 4MB 是不是一个巨大的节约？</p>
<p>那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。</p>
<p>我们把二级分页再推广到多级页表，就会发现页表占用的内存空间更少了，这一切都要归功于对局部性原理的充分应用。</p>
<p>对于 64 位的系统，两级分页肯定不够了，就变成了四级目录，分别是：</p>
<ul>
<li>全局页目录项 PGD（Page Global Directory）</li>
<li>上层页目录项 PUD（Page Upper Directory）</li>
<li>中间页目录项 PMD（Page Middle Directory）</li>
<li>页表项 PTE（Page Table Entry）</li>
</ul>
<p><img src="images/%E5%9B%9B%E7%BA%A7%E5%88%86%E9%A1%B5.png" alt="img"></p>
<h3 id="TLB"><a href="#TLB" class="headerlink" title="TLB"></a>TLB</h3><p>多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的工序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。</p>
<p>程序是有局部性的，即在一段时间内，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。我们就可以利用这一特性，把最常访问的几个页表项存储到访问速度更快的硬件，于是计算机科学家们就在 CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 <strong>Cache</strong>，这个 Cache 就是 <strong>TLB</strong>（Translation Lookaside Buffer） ，通常称为页表缓存、转址旁路缓存、快表等。</p>
<p><img src="images/a3cdf27646b24614a64cfc5d7ccffa35.png" alt="img"></p>
<p>在 CPU 芯片里面，封装了内存管理单元（Memory Management Unit）芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。TLB 的命中率其实是很高的，因为局部性原理表明程序最常访问的页就那么几个。</p>
<h2 id="2-4-页面置换算法"><a href="#2-4-页面置换算法" class="headerlink" title="2.4 页面置换算法"></a>2.4 页面置换算法</h2><h3 id="缺页中断"><a href="#缺页中断" class="headerlink" title="缺页中断"></a>缺页中断</h3><p>当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。它与一般中断的主要区别在于：</p>
<ul>
<li>缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。</li>
<li>缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。</li>
</ul>
<p>缺页中断的处理流程如下图：</p>
<p><img src="images/%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8%E6%B5%81%E7%A8%8B.png" alt="缺页中断的处理流程"></p>
<ol>
<li>在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。</li>
<li>如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。</li>
<li>操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。</li>
<li>找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。</li>
<li>页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。</li>
<li>最后，CPU 重新执行导致缺页异常的指令。</li>
</ol>
<p>第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。</p>
<p>此外，页表项通常有如下图的字段：</p>
<p><img src="images/%E9%A1%B5%E8%A1%A8%E9%A1%B9%E5%AD%97%E6%AE%B5.png" alt="img"></p>
<ul>
<li>状态位：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。</li>
<li>访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。</li>
<li>修改位：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。</li>
<li>硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。</li>
</ul>
<h3 id="页面置换的作用"><a href="#页面置换的作用" class="headerlink" title="页面置换的作用"></a>页面置换的作用</h3><p>虚拟内存的管理整个流程：</p>
<p><img src="images/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png" alt="虚拟内存的流程"></p>
<p>页面置换算法的功能是，<strong>当出现缺页异常，需调入新页面，而内存已满时，选择被置换的物理页面</strong>，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页，那其算法目标则是尽可能减少页面的换入换出的次数。</p>
<p>常见的页面置换算法有如下几种：</p>
<ul>
<li>最佳页面置换算法（OPT）</li>
<li>先进先出置换算法（FIFO）</li>
<li>最近最久未使用的置换算法（LRU）</li>
<li>时钟页面置换算法（Lock）</li>
<li>最不常用置换算法（LFU）</li>
</ul>
<h3 id="最佳页面置换算法（OPT）"><a href="#最佳页面置换算法（OPT）" class="headerlink" title="最佳页面置换算法（OPT）"></a>最佳页面置换算法（OPT）</h3><p>最佳页面置换算法基本思路是，<strong>置换在「未来」最长时间不访问的页面。</strong></p>
<p>所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。</p>
<p>假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：</p>
<p><img src="images/%E6%9C%80%E4%BC%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="最佳页面置换算法"></p>
<p>在这个请求的页面序列中，缺页共发生了 7 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 4 次。</p>
<p>这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。</p>
<h3 id="先进先出置换算法（FIFO）"><a href="#先进先出置换算法（FIFO）" class="headerlink" title="先进先出置换算法（FIFO）"></a>先进先出置换算法（FIFO）</h3><p>既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以<strong>选择在内存驻留时间很长的页面进行中置换</strong>，这个就是「先进先出置换」算法的思想。</p>
<p>还是以前面的请求的页面序列为例：</p>
<p><img src="images/FIFO%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="先进先出置换算法"></p>
<p>在这个请求的页面序列中，缺页共发生了 10 次，页面置换共发生了 7 次，跟最佳页面置换算法比较起来，性能明显差了很多。</p>
<h3 id="最近最久未使用的置换算法（LRU）"><a href="#最近最久未使用的置换算法（LRU）" class="headerlink" title="最近最久未使用的置换算法（LRU）"></a>最近最久未使用的置换算法（LRU）</h3><p>最近最久未使用（LRU）的置换算法的基本思路是，发生缺页时，<strong>选择最长时间没有被访问的页面进行置换</strong>，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。</p>
<p>这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。</p>
<p>还是之前的例子：</p>
<p><img src="images/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="最近最久未使用的置换算法"></p>
<p>在这个请求的页面序列中，缺页共发生了 9 次，页面置换共发生了 6 次，跟先进先出置换算法比较起来，性能提高了一些。</p>
<p>虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。</p>
<p>困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。</p>
<h3 id="时钟页面置换算法（Lock）"><a href="#时钟页面置换算法（Lock）" class="headerlink" title="时钟页面置换算法（Lock）"></a>时钟页面置换算法（Lock）</h3><p>那有没有一种即能优化置换的次数，也能方便实现的算法呢？时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。</p>
<p>该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。当发生缺页中断时，算法首先检查表针指向的页面：</p>
<ul>
<li>如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；</li>
<li>如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；</li>
</ul>
<p><img src="images/%E6%97%B6%E9%92%9F%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="时钟页面置换算法"></p>
<h3 id="最不常用置换算法（LFU）"><a href="#最不常用置换算法（LFU）" class="headerlink" title="最不常用置换算法（LFU）"></a>最不常用置换算法（LFU）</h3><p>最不常用（LFU）算法是当发生缺页中断时，<strong>选择「访问次数」最少的那个页面</strong>，并将其淘汰。</p>
<p>它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。</p>
<p>看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。</p>
<p>还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。</p>
<p>那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。</p>
<h2 id="2-5-段页式内存管理"><a href="#2-5-段页式内存管理" class="headerlink" title="2.5 段页式内存管理"></a>2.5 段页式内存管理</h2><p>内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为<strong>段页式内存管理</strong>：</p>
<ul>
<li>先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；</li>
<li>接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页。</li>
</ul>
<p>这样，地址结构就由<strong>段号、段内页号和页内位移</strong>三部分组成。</p>
<p>用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：</p>
<p><img src="images/8904fb89ae0c49c4b0f2f7b5a0a7b099.png" alt="img"></p>
<p>段页式地址变换中要得到物理地址须经过三次内存访问：</p>
<ol>
<li>第一次访问段表，得到页表起始地址；</li>
<li>第二次访问页表，得到物理页号；</li>
<li>第三次将物理页号与页内位移组合，得到物理地址。</li>
</ol>
<h2 id="2-6-Linux-内存管理"><a href="#2-6-Linux-内存管理" class="headerlink" title="2.6 Linux 内存管理"></a>2.6 Linux 内存管理</h2><h3 id="Linux-内存管理方式"><a href="#Linux-内存管理方式" class="headerlink" title="Linux 内存管理方式"></a>Linux 内存管理方式</h3><p><strong>Linux 内存主要采用的是页式内存管理，但同时也不可避免地涉及了段机制</strong>。</p>
<p>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址（通常是没被段式内存管理映射的地址）概念，段只被用于访问控制和内存保护。</p>
<p>在 Linux 操作系统中，虚拟地址空间的内部又被分为内核空间和用户空间两部分，不同位数的系统，地址空间的范围也不同。比如最常见的 32 位和 64 位系统，如下所示：</p>
<p><img src="images/3a6cb4e3f27241d3b09b4766bb0b1124.png" alt="img"></p>
<ul>
<li>32 位系统的内核空间占用 1G，位于最高处，剩下的 3G 是用户空间；</li>
<li>64 位系统的内核空间和用户空间都是 128T，分别占据整个内存空间的最高和最低处，剩下的中间部分是未定义的。</li>
</ul>
<p>内核空间与用户空间的区别：</p>
<ul>
<li>进程在用户态时，只能访问用户空间内存</li>
<li>只有进入内核态后，才可以访问内核空间的内存</li>
</ul>
<p>虽然每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p>
<p><img src="images/48403193b7354e618bf336892886bcff.png" alt="img"></p>
<h3 id="面试题：Linux-内存满了，会发生什么？"><a href="#面试题：Linux-内存满了，会发生什么？" class="headerlink" title="面试题：Linux 内存满了，会发生什么？"></a>面试题：Linux 内存满了，会发生什么？</h3><p>内核在给应用程序分配物理内存的时候，如果空闲物理内存不够，那么就会进行内存回收的工作，主要有两种方式：</p>
<ul>
<li>后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程异步的，不会阻塞进程的执行。</li>
<li>直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是同步的，会阻塞进程的执行。</li>
</ul>
<p>可被回收的内存类型有文件页和匿名页：</p>
<ul>
<li>文件页的回收：对于干净页是直接释放内存，这个操作不会影响性能，而对于脏页会先写回到磁盘再释放内存，这个操作会发生磁盘 I/O 的，这个操作是会影响系统性能的。</li>
<li>匿名页的回收：如果开启了 Swap 机制，那么 Swap 机制会将不常访问的匿名页换出到磁盘中，下次访问时，再从磁盘换入到内存中，这个操作是会影响系统性能的。</li>
</ul>
<p>文件页和匿名页的回收都是基于 LRU 算法，也就是优先回收不常访问的内存。回收内存的操作基本都会发生磁盘 I/O 的，如果回收内存的操作很频繁，意味着磁盘 I/O 次数会很多，这个过程势必会影响系统的性能。</p>
<p>针对回收内存导致的性能影响，常见的解决方式。</p>
<ul>
<li>设置 /proc/sys/vm/swappiness，调整文件页和匿名页的回收倾向，尽量倾向于回收文件页；</li>
<li>设置 /proc/sys/vm/min_free_kbytes，调整 kswapd 内核线程异步回收内存的时机；</li>
<li>设置 /proc/sys/vm/zone_reclaim_mode，调整 NUMA 架构下内存回收策略，建议设置为 0，这样在回收本地内存之前，会在其他 Node 寻找空闲内存，从而避免在系统还有很多空闲内存的情况下，因本地 Node 的本地内存不足，发生频繁直接内存回收导致性能下降的问题；</li>
</ul>
<p>在经历完直接内存回收后，空闲的物理内存大小依然不够，那么就会触发 OOM 机制，OOM killer 就会根据每个进程的内存占用情况和 oom_score_adj 的值进行打分，得分最高的进程就会被首先杀掉。</p>
<p>我们可以通过调整进程的 /proc/[pid]/oom_score_adj 值，来降低被 OOM killer 杀掉的概率。</p>
<h3 id="面试题：在-4GB-物理内存的机器上，申请-8G-内存会怎么样？"><a href="#面试题：在-4GB-物理内存的机器上，申请-8G-内存会怎么样？" class="headerlink" title="面试题：在 4GB 物理内存的机器上，申请 8G 内存会怎么样？"></a>面试题：在 4GB 物理内存的机器上，申请 8G 内存会怎么样？</h3><p>在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。</p>
<p>在 64位 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。如果这块虚拟内存被访问了，要看系统有没有 Swap 分区：</p>
<ul>
<li>如果没有 Swap 分区，因为物理空间不够，进程会被操作系统杀掉，原因是 OOM（内存溢出）。</li>
<li>如果有 Swap 分区，即使物理内存只有 4GB，程序也能正常使用 8GB 的内存，进程可以正常运行。</li>
</ul>
<h2 id="2-7-总结"><a href="#2-7-总结" class="headerlink" title="2.7 总结"></a>2.7 总结</h2><p>为了在多进程环境下，使得进程之间的内存地址不受影响，相互隔离，于是操作系统就为每个进程独立分配一套虚拟地址空间，每个程序只关心自己的虚拟地址就可以，实际上大家的虚拟地址都是一样的，但分布到物理地址内存是不一样的。作为程序，也不用关心物理地址的事情。</p>
<p>每个进程都有自己的虚拟空间，而物理内存只有一个，所以当启用了大量的进程，物理内存必然会很紧张，于是操作系统会通过内存交换技术，把不常使用的内存暂时存放到硬盘（换出），在需要的时候再装载回物理内存（换入）。</p>
<p>那既然有了虚拟地址空间，那必然要把虚拟地址「映射」到物理地址，这个事情通常由操作系统来维护。</p>
<p>那么对于虚拟地址与物理地址的映射关系，可以有分段和分页的方式，同时两者结合都是可以的。</p>
<p>内存分段是根据程序的逻辑角度，分成了栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。但是每个段的大小都不是统一的，这就会导致外部内存碎片和内存交换效率低的问题。</p>
<p>于是，就出现了内存分页，把虚拟空间和物理空间分成大小固定的页，如在 Linux 系统中，每一页的大小为 4KB。由于分了页后，就不会产生细小的内存碎片，解决了内存分段的外部内存碎片问题。同时在内存交换的时候，写入硬盘也就一个页或几个页，这就大大提高了内存交换的效率。</p>
<p>再来，为了解决简单分页产生的页表过大的问题，就有了多级页表，它解决了空间上的问题，但这就会导致 CPU 在寻址的过程中，需要有很多层表参与，加大了时间上的开销。于是根据程序的局部性原理，在 CPU 芯片中加入了 TLB，负责缓存最近常被访问的页表项，大大提高了地址的转换速度。</p>
<p>Linux 系统主要采用了分页管理，但是由于 Intel 处理器的发展史，Linux 系统无法避免分段管理。于是 Linux 就把所有段的基地址设为 0，也就意味着所有程序的地址空间都是线性地址空间（虚拟地址），相当于屏蔽了 CPU 逻辑地址的概念，所以段只被用于访问控制和内存保护。</p>
<p>最后，说下虚拟内存有什么作用：</p>
<ol>
<li>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。</li>
<li>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就解决了多进程之间地址冲突的问题。</li>
<li>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。</li>
</ol>
<h1 id="3-进程管理"><a href="#3-进程管理" class="headerlink" title="3 进程管理"></a>3 进程管理</h1><h2 id="3-1-进程"><a href="#3-1-进程" class="headerlink" title="3.1 进程"></a>3.1 进程</h2><h3 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h3><p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「<strong>进程</strong>」（Process）。</p>
<h3 id="并行-amp-并发"><a href="#并行-amp-并发" class="headerlink" title="并行 &amp; 并发"></a>并行 &amp; 并发</h3><p>现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻地等硬盘返回数据的话，那 CPU 的利用率是非常低的。所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个<strong>中断</strong>，于是 CPU 再继续运行这个进程。</p>
<p>这种<strong>多个程序、交替执行</strong>的思想，就有 CPU 管理多个进程的初步想法。虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生<strong>并行</strong>的错觉，实际上这是<strong>并发</strong>。</p>
<p><img src="images/5-%E5%B9%B6%E5%8F%91%E4%B8%8E%E5%B9%B6%E8%A1%8C.jpg" alt="并发与并行"></p>
<h3 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h3><p>CPU 可以从一个进程切换到另外一个进程，在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。</p>
<p>所以，可以发现进程有着「运行 - 暂停 - 运行」的活动规律。</p>
<p>一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。</p>
<p>在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态：</p>
<p><img src="images/7-%E8%BF%9B%E7%A8%8B%E4%B8%89%E4%B8%AA%E5%9F%BA%E6%9C%AC%E7%8A%B6%E6%80%81.jpg" alt="进程的三种基本状态"></p>
<ul>
<li><strong>运行状态</strong>（Running）：该时刻进程占用 CPU；</li>
<li><strong>就绪状态</strong>（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行；</li>
<li><strong>阻塞状态</strong>（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；</li>
</ul>
<p>当然，进程还有另外两个基本状态：</p>
<ul>
<li><strong>创建状态</strong>（new）：进程正在被创建时的状态；</li>
<li><strong>结束状态</strong>（Exit）：进程正在从系统中消失时的状态；</li>
</ul>
<p>于是，一个完整的进程状态的变迁如下图：</p>
<p><img src="images/8-%E8%BF%9B%E7%A8%8B%E4%BA%94%E4%B8%AA%E7%8A%B6%E6%80%81.jpg" alt="进程五种状态的变迁"></p>
<p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。</p>
<p>那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是<strong>挂起状态</strong>。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回，但此时进程还驻留内存中。</p>
<p>挂起状态可以分为两种：</p>
<ul>
<li><strong>阻塞挂起状态</strong>：进程在外存（硬盘）并等待某个事件的出现；</li>
<li><strong>就绪挂起状态</strong>：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li>
</ul>
<p>这两种挂起状态加上前面的五种状态，就变成了七种状态变迁：</p>
<p><img src="images/10-%E8%BF%9B%E7%A8%8B%E4%B8%83%E4%B8%AD%E7%8A%B6%E6%80%81.jpg" alt="七种状态变迁"></p>
<p>导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p>
<ul>
<li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>
<li>用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程。</li>
</ul>
<h3 id="进程控制块"><a href="#进程控制块" class="headerlink" title="进程控制块"></a>进程控制块</h3><p>在操作系统中，是用<strong>进程控制块</strong>（process control block，PCB）数据结构来描述进程的。PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p>
<p>PCB包含的信息包括：</p>
<ul>
<li><p>进程描述信息：</p>
<ul>
<li><p>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</p>
</li>
<li><p>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</p>
</li>
</ul>
</li>
<li><p>进程控制和管理信息：</p>
<ul>
<li><p>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</p>
</li>
<li><p>进程优先级：进程抢占 CPU 时的优先级；</p>
</li>
</ul>
</li>
<li><p>资源分配清单：</p>
<ul>
<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。</li>
</ul>
</li>
<li><p>CPU 相关信息：</p>
<ul>
<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>
</ul>
</li>
</ul>
<p>那么每个 PCB 是如何组织的呢？通常是通过<strong>链表</strong>的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如：</p>
<ul>
<li>将所有处于就绪状态的进程链在一起，称为就绪队列；</li>
<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；</li>
<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>
</ul>
<p><img src="images/12-PCB%E7%8A%B6%E6%80%81%E9%93%BE%E8%A1%A8%E7%BB%84%E7%BB%87.jpg" alt="就绪队列和阻塞队列"></p>
<p>除了链接的组织方式，还有索引方式，它的工作原理是将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。但是一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。</p>
<h3 id="进程的上下文切换"><a href="#进程的上下文切换" class="headerlink" title="进程的上下文切换"></a>进程的上下文切换</h3><p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。</p>
<h4 id="CPU-上下文切换"><a href="#CPU-上下文切换" class="headerlink" title="CPU 上下文切换"></a>CPU 上下文切换</h4><p>大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行，实际上这些任务并不是同时运行的，只是因为系统在很短的时间内，通过调度让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。</p>
<p>任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。所以，操作系统需要事先帮 CPU 设置好 <strong>CPU 寄存器</strong>和<strong>程序计数器</strong>。</p>
<ul>
<li>CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。</li>
<li>程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。</li>
</ul>
<p>所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 <strong>CPU 上下文</strong>。</p>
<p><strong>CPU 上下文切换</strong>就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p>
<p>系统内核会存储保存下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。</p>
<p>上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：<strong>进程上下文切换</strong>、<strong>线程上下文切换</strong>和<strong>中断上下文切换</strong>。</p>
<h4 id="进程的上下文切换到底是切换什么呢？"><a href="#进程的上下文切换到底是切换什么呢？" class="headerlink" title="进程的上下文切换到底是切换什么呢？"></a>进程的上下文切换到底是切换什么呢？</h4><p>首先，进程是由内核管理和调度的，所以进程的切换只能发生在内核态。所以，<strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源</strong>。</p>
<p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：</p>
<p><img src="images/13-%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2.jpg" alt="进程上下文切换"></p>
<h4 id="发生进程上下文切换有哪些场景？"><a href="#发生进程上下文切换有哪些场景？" class="headerlink" title="发生进程上下文切换有哪些场景？"></a>发生进程上下文切换有哪些场景？</h4><ul>
<li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li>
<li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li>
<li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li>
<li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li>
<li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li>
</ul>
<h2 id="3-2-线程"><a href="#3-2-线程" class="headerlink" title="3.2 线程"></a>3.2 线程</h2><h3 id="为什么使用线程？"><a href="#为什么使用线程？" class="headerlink" title="为什么使用线程？"></a>为什么使用线程？</h3><p>假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个：</p>
<ul>
<li>从视频文件当中读取数据；</li>
<li>对读取的数据进行解压缩；</li>
<li>把解压缩后的视频数据播放出来；</li>
</ul>
<p>对于单进程的实现方式：</p>
<p><img src="images/14-%E5%8D%95%E7%BA%BF%E7%A8%8Bmp4%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B.jpg" alt="单进程实现方式"></p>
<p>但是存在以下问题：</p>
<ul>
<li>播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，Read 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放；</li>
<li>各个函数之间不是并发执行，影响资源的使用效率；</li>
</ul>
<p>那改进成多进程的方式：</p>
<p><img src="images/15-%E5%A4%9A%E8%BF%9B%E7%A8%8Bmp4-%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B.jpg" alt="多进程实现方式"></p>
<p>依然会存在问题：</p>
<ul>
<li>进程之间如何通信，共享数据？</li>
<li>维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息；</li>
</ul>
<p>那到底如何解决呢？需要有一种新的实体，满足以下特性：</p>
<ul>
<li>实体之间可以并发运行；</li>
<li>实体之间共享相同的地址空间；</li>
</ul>
<p>这个新的实体，就是<strong>线程</strong>(Thread)，线程之间可以并发运行且共享相同的地址空间。</p>
<h3 id="线程"><a href="#线程" class="headerlink" title="线程"></a>线程</h3><p><strong>线程是进程当中的一条执行流程</strong>。同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p>
<p>线程的优点：</p>
<ul>
<li>一个进程中可以同时存在多个线程；</li>
<li>各个线程之间可以并发执行；</li>
<li>各个线程之间可以共享地址空间和文件等资源；</li>
</ul>
<p>线程的缺点：</p>
<ul>
<li>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C/C++ 语言，Java语言中的线程奔溃不会造成进程崩溃）</li>
</ul>
<h3 id="线程与进程的比较"><a href="#线程与进程的比较" class="headerlink" title="线程与进程的比较"></a>线程与进程的比较</h3><p>线程与进程的比较如下：</p>
<ul>
<li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
<p>所以，不管是时间效率，还是空间效率线程比进程都要高。</p>
<h3 id="线程的上下文切换"><a href="#线程的上下文切换" class="headerlink" title="线程的上下文切换"></a>线程的上下文切换</h3><p>在前面我们知道了，线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。</p>
<p>所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的，但是线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。</p>
<ul>
<li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样。</li>
<li>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。</li>
</ul>
<p>所以，线程的上下文切换相比进程，开销要小很多。</p>
<h3 id="线程的实现"><a href="#线程的实现" class="headerlink" title="线程的实现"></a>线程的实现</h3><p>主要有三种线程的实现方式：</p>
<ul>
<li><strong>用户线程</strong>（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理。</li>
<li><strong>内核线程</strong>（Kernel Thread）：在内核中实现的线程，是由内核管理的线程。</li>
<li><strong>轻量级进程</strong>（Light Weight Process）：在内核中来支持用户线程。</li>
</ul>
<p>用户线程的执行是依赖于内核线程的，用户线程在用户态创建，但是最终都需要映射到内核级别的线程之上去运行。那么，这还需要考虑一个问题，用户线程和内核线程的对应关系。</p>
<p>首先，第一种关系是多对一的关系，也就是多个用户线程对应同一个内核线程：</p>
<p><img src="images/17-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B-%E4%B8%80%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB.jpg" alt="多对一"></p>
<p>第二种是一对一的关系，也就是一个用户线程对应一个内核线程：</p>
<p><img src="images/18-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B-%E4%B8%80%E5%AF%B9%E4%B8%80%E5%85%B3%E7%B3%BB.jpg" alt="一对一"></p>
<p>第三种是多对多的关系，也就是多个用户线程对应到多个内核线程：</p>
<p><img src="images/19-%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B%E4%B8%8E%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B-%E5%A4%9A%E5%AF%B9%E5%A4%9A%E5%85%B3%E7%B3%BB.jpg" alt="多对多"></p>
<h4 id="用户线程"><a href="#用户线程" class="headerlink" title="用户线程"></a>用户线程</h4><p><strong>用户线程</strong>是基于用户态的线程管理库来实现的，那么<strong>线程控制块</strong>（Thread Control Block, TCB） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。所以，<strong>用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理</strong>，包括线程的创建、终止、同步和调度等。</p>
<p>用户级线程的模型，也就类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程。</p>
<p>用户线程的优点：</p>
<ul>
<li>每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li>
<li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li>
</ul>
<p>用户线程的缺点：</p>
<ul>
<li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</li>
<li>当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</li>
<li>由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；</li>
</ul>
<h4 id="内核线程"><a href="#内核线程" class="headerlink" title="内核线程"></a>内核线程</h4><p>用户进程可以通过 API 创建用户态的线程，也可以通过系统调用创建内核态的线程。</p>
<p><strong>内核线程</strong>是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。</p>
<p>内核线程的模型，也就类似前面提到的一对一的关系，即一个用户线程对应一个内核线程。</p>
<p>内核线程的优点：</p>
<ul>
<li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li>
<li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li>
</ul>
<p>内核线程的缺点：</p>
<ul>
<li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li>
<li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；</li>
</ul>
<h4 id="轻量级进程"><a href="#轻量级进程" class="headerlink" title="轻量级进程"></a>轻量级进程</h4><p><strong>轻量级进程</strong>（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是每个 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。</p>
<p>在大多数系统中，LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。</p>
<p>在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：</p>
<ul>
<li>1 : 1，即一个 LWP 对应 一个用户线程；</li>
<li>N : 1，即一个 LWP 对应多个用户线程；</li>
<li>M : N，即多个 LWP 对应多个用户线程；</li>
</ul>
<p>接下来针对上面这三种对应关系说明它们优缺点。先看下图的 LWP 模型：</p>
<p><img src="images/22-LWP.jpg" alt="LWP 模型"></p>
<p>1 : 1 模式：一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。</p>
<ul>
<li><p>优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；</p>
</li>
<li><p>缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。</p>
</li>
</ul>
<p>N : 1 模式：多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。</p>
<ul>
<li>优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；</li>
<li>缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。</li>
</ul>
<p>M : N 模式：根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。</p>
<ul>
<li>优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。</li>
</ul>
<p>组合模式：如上图的进程 5，此进程结合 1:1 模型和 M:N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。</p>
<h2 id="3-3-进程调度"><a href="#3-3-进程调度" class="headerlink" title="3.3 进程调度"></a>3.3 进程调度</h2><p>进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。</p>
<p>选择一个进程运行这一功能是在操作系统中完成的，通常称为<strong>调度程序</strong>（scheduler）。</p>
<h3 id="调度时机"><a href="#调度时机" class="headerlink" title="调度时机"></a>调度时机</h3><p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p>
<p>比如，以下状态的变化都会触发操作系统的调度：</p>
<ul>
<li>从就绪态 -&gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li>
<li>从运行态 -&gt; 阻塞态：当进程发生 I/O 事件而阻塞时，操作系统必须选择另外一个进程运行；</li>
<li>从运行态 -&gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；</li>
</ul>
<p>因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。</p>
<p>另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p>
<ul>
<li>非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li>
<li>抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片轮转机制</strong>。</li>
</ul>
<h3 id="调度原则"><a href="#调度原则" class="headerlink" title="调度原则"></a>调度原则</h3><ul>
<li>CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>
<li>系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li>周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>
<li>等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li>
<li>响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ul>
<h3 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h3><h4 id="先来先服务调度算法"><a href="#先来先服务调度算法" class="headerlink" title="先来先服务调度算法"></a>先来先服务调度算法</h4><p>最简单的一个调度算法，就是非抢占式的<strong>先来先服务</strong>（First Come First Serve, FCFS）算法了。</p>
<p><img src="images/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg" alt="FCFS 调度算法"></p>
<p>顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</p>
<p>这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。</p>
<p>FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。</p>
<h4 id="最短作业优先调度算法"><a href="#最短作业优先调度算法" class="headerlink" title="最短作业优先调度算法"></a>最短作业优先调度算法</h4><p><strong>最短作业优先</strong>（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。</p>
<p><img src="images/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg" alt="SJF 调度算法"></p>
<p>这显然对长作业不利，很容易造成一种极端现象。</p>
<p>比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行，即产生饥饿现象。</p>
<h4 id="高响应比优先调度算法"><a href="#高响应比优先调度算法" class="headerlink" title="高响应比优先调度算法"></a>高响应比优先调度算法</h4><p>前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。</p>
<p>那么，<strong>高响应比优先</strong> （Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。</p>
<p>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：</p>
<p><img src="images/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg" alt="img"></p>
<p>怎么才能知道一个进程要求服务的时间？这不是不可预知的吗？对的，这是不可预估的。所以，高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的。</p>
<h4 id="时间片轮转调度算法"><a href="#时间片轮转调度算法" class="headerlink" title="时间片轮转调度算法"></a>时间片轮转调度算法</h4><p>最古老、最简单、最公平且使用最广的算法就是<strong>时间片轮转</strong>（Round Robin, RR）调度算法。</p>
<p><img src="images/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg" alt="RR 调度算法"></p>
<p>每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。</p>
<ul>
<li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li>
<li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li>
</ul>
<p>另外，时间片的长度就是一个很关键的点：</p>
<ul>
<li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li>
<li>如果设得太长又可能引起对短作业进程的响应时间变长</li>
</ul>
<p>一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值。</p>
<h4 id="最高优先级调度算法"><a href="#最高优先级调度算法" class="headerlink" title="最高优先级调度算法"></a>最高优先级调度算法</h4><p>前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。</p>
<p>但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为<strong>最高优先级</strong>（Highest Priority First，HPF）调度算法。</p>
<p>进程的优先级可以分为，静态优先级和动态优先级：</p>
<ul>
<li>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li>
<li>动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。</li>
</ul>
<p>该算法也有两种处理优先级高的方法，非抢占式和抢占式：</p>
<ul>
<li>非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。</li>
<li>抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。</li>
</ul>
<p>但是依然有缺点，可能会导致低优先级的进程永远不会运行，导致饥饿。</p>
<h4 id="多级反馈队列调度算法"><a href="#多级反馈队列调度算法" class="headerlink" title="多级反馈队列调度算法"></a>多级反馈队列调度算法</h4><p><strong>多级反馈队列</strong>（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>
<ul>
<li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li>
<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列。</li>
</ul>
<p><img src="images/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg" alt="多级反馈队列"></p>
<p>它的工作步骤是：</p>
<ul>
<li>设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；</li>
<li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li>
<li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li>
</ul>
<p>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。</p>
<h2 id="3-4-进程通信"><a href="#3-4-进程通信" class="headerlink" title="3.4 进程通信"></a>3.4 进程通信</h2><p>每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。</p>
<p><img src="images/4-%E8%BF%9B%E7%A8%8B%E7%A9%BA%E9%97%B4.jpg" alt="img"></p>
<h3 id="匿名管道"><a href="#匿名管道" class="headerlink" title="匿名管道"></a>匿名管道</h3><pre><code>$ ps auxf | grep mysql</code></pre>
<p>Linux 命令里的「|」竖线就是一个<strong>管道</strong>，它的功能是将前一个命令（ps auxf）的输出，作为后一个命令（grep mysql）的输入，从这功能描述，可以看出管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才行。</p>
<p>同时，我们得知上面这种管道是没有名字，所以「|」表示的管道称为<strong>匿名管道</strong>，用完了就销毁。</p>
<p>其实，<strong>所谓的管道，就是内核里面的一串缓存</strong>。从管道的一段写入的数据，实际上是缓存在内核中的，另一端读取，也就是从内核中读取这段数据。另外，管道传输的数据是无格式的流且大小受限。</p>
<p>对于匿名管道，它的<strong>通信范围是存在父子关系的进程</strong>。因为管道没有实体，也就是没有管道文件，只能通过 fork 来复制父进程 fd 文件描述符，来达到通信的目的。</p>
<h3 id="命名管道"><a href="#命名管道" class="headerlink" title="命名管道"></a>命名管道</h3><p>管道还有另外一个类型是<strong>命名管道</strong>，也被叫做 FIFO，因为数据是先进先出的传输方式。</p>
<p>在使用命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：</p>
<pre><code>$ mkfifo myPipe</code></pre>
<p>myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：</p>
<pre><code>$ ls -l
prw-r--r--. 1 root    root         0 Jul 17 02:45 myPipe</code></pre>
<p>接下来，我们往 myPipe 这个管道写入数据：</p>
<pre><code>$ echo &quot;hello&quot; &gt; myPipe  // 将数据写进管道
                         // 停住了 ...</code></pre>
<p>你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。</p>
<p>于是，我们执行另外一个命令来读取这个管道里的数据：</p>
<pre><code>$ cat &lt; myPipe  // 读取管道里的数据
hello</code></pre>
<p>可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。</p>
<p>对于命名管道，它<strong>可以在不相关的进程间也能相互通信</strong>。因为命令管道，提前创建了一个类型为管道的设备文件，在进程里只要使用这个设备文件，就可以相互通信。</p>
<p>缺点：</p>
<ul>
<li>管道这种通信方式效率低，不适合进程间频繁地交换数据。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。</li>
<li>不管是匿名管道还是命名管道，进程写入的数据都是缓存在内核中，另一个进程读取数据时候自然也是从内核中获取，同时通信数据都遵循先进先出原则，不支持 lseek 之类的文件定位操作。</li>
</ul>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><p>前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。</p>
<p>对于这个问题，<strong>消息队列</strong>的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。</p>
<p>消息队列是<strong>保存在内核中的消息链表</strong>，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</p>
<p>缺点：</p>
<ul>
<li>消息队列<strong>不适合比较大数据的传输</strong>，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。</li>
<li>消息队列通信过程中，<strong>存在用户态与内核态之间的数据拷贝开销</strong>，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</li>
</ul>
<h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><p>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那<strong>共享内存</strong>的方式，就很好的解决了这一问题。</p>
<p>现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。</p>
<p>共享内存的机制，就是<strong>拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</p>
<p><img src="images/9-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98.jpg" alt="img"></p>
<h3 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h3><p>用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。</p>
<p>为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，<strong>信号量</strong>就实现了这一保护机制。</p>
<p>信号量其实是一个<strong>整型的计数器</strong>，主要用于<strong>实现进程间的互斥与同步</strong>，而不是用于缓存进程间通信的数据。</p>
<p>信号量表示资源的数量，控制信号量的方式有两种原子操作：</p>
<ul>
<li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;= 0，则表明还有资源可使用，进程可正常继续执行。</li>
<li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程</li>
</ul>
<p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。</p>
<p>初始信号量为 1:</p>
<p><img src="images/10-%E4%BF%A1%E5%8F%B7%E9%87%8F-%E4%BA%92%E6%96%A5.jpg" alt="img"></p>
<ol>
<li>进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。</li>
<li>若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。</li>
<li>直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。</li>
</ol>
<p>信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。</p>
<p>初始化信号量为 0：</p>
<p><img src="images/11-%E4%BF%A1%E5%8F%B7%E9%87%8F-%E5%90%8C%E6%AD%A5.jpg" alt="img"></p>
<ol>
<li>如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；</li>
<li>接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；</li>
<li>最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。</li>
</ol>
<p>信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。</p>
<h3 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h3><p>上面说的进程间通信，都是常规状态下的工作模式。对于异常情况下的工作模式，就需要用<strong>信号</strong>的方式来通知进程。</p>
<p>信号跟信号量虽然名字相似度 66.66%，但两者用途完全不一样。在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 <code>kill -l</code> 命令，查看所有的信号。</p>
<p>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如：</p>
<ul>
<li>Ctrl+C 产生 SIGINT 信号，表示终止该进程。</li>
<li>Ctrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束。</li>
</ul>
<p>如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：</p>
<ul>
<li>kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程。</li>
</ul>
<p>所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。</p>
<p><strong>信号是进程间通信机制中唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式：</p>
<ul>
<li>执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</li>
<li>捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</li>
<li>忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。</li>
</ul>
<h3 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h3><p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 <strong>Socket</strong> 通信了。</p>
<p>通过创建Socket的类型，可以实现实现 TCP 字节流通信、UDP 数据报通信和本地进程间通信。本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。</p>
<h2 id="3-5-互斥-amp-同步"><a href="#3-5-互斥-amp-同步" class="headerlink" title="3.5 互斥 &amp; 同步"></a>3.5 互斥 &amp; 同步</h2><h3 id="互斥"><a href="#互斥" class="headerlink" title="互斥"></a>互斥</h3><p>由于对某个资源的访问存在<strong>竞争条件</strong>（race condition），当多线程相互竞争操作共享变量时，每次运行都可能得到不同的结果，因此输出的结果存在<strong>不确定性</strong>（indeterminate）。</p>
<p>由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为<strong>临界区</strong>（critical section），它是访问共享资源的代码片段，一定不能给多线程同时执行。</p>
<p>我们希望这段代码是<strong>互斥</strong>（mutualexclusion）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。</p>
<h3 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h3><p>我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。</p>
<p>比如，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。</p>
<p>所谓<strong>同步</strong>（synchronization），就是并发进程/线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程/线程同步。</p>
<h3 id="锁-amp-信号量"><a href="#锁-amp-信号量" class="headerlink" title="锁 &amp; 信号量"></a>锁 &amp; 信号量</h3><p>为了实现进程/线程间正确的互斥和同步，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p>
<ul>
<li>锁：加锁、解锁操作</li>
<li>信号量：P、V 操作</li>
</ul>
<h4 id="锁"><a href="#锁" class="headerlink" title="锁"></a>锁</h4><p>任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。</p>
<p>根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。</p>
<p>所谓忙等待锁，也可以称之为自旋锁（spin lock），比如Java里的CAS。</p>
<p>无等待锁顾明思议就是获取不到锁的时候，把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行，比如Java里的synchronized。</p>
<h4 id="信号量-1"><a href="#信号量-1" class="headerlink" title="信号量"></a>信号量</h4><p>通常<strong>信号量表示资源的数量</strong>，对应的变量是一个整型（sem）变量。</p>
<p>另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：</p>
<ul>
<li>P 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程/线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞</li>
<li>V 操作：将 sem 加 1，相加后，如果 sem &lt;= 0，唤醒一个等待中的进程/线程，表明 V 操作不会阻塞</li>
</ul>
<p>P 操作是用在进入临界区之前，V 操作是用在离开临界区之后，这两个操作是必须成对出现的。参考上文进程通信中的信号量方式。</p>
<h4 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h4><ol>
<li>生产者-消费者问题</li>
<li>哲学家就餐问题</li>
<li>读者-写者问题</li>
</ol>
<h2 id="3-6-死锁"><a href="#3-6-死锁" class="headerlink" title="3.6 死锁"></a>3.6 死锁</h2><p>在多线程编程中，我们为了防止多线程竞争共享资源而导致数据错乱，都会在操作共享资源之前加上互斥锁，只有成功获得到锁的线程，才能操作共享资源，获取不到锁的线程就只能等待，直到锁被释放。</p>
<p>那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了<strong>死锁</strong>（Dead Lock）。</p>
<p>死锁只有同时满足以下四个条件才会发生：</p>
<ol>
<li>互斥</li>
<li>请求保持</li>
<li>不剥夺</li>
<li>循环等待</li>
</ol>
<h3 id="互斥条件"><a href="#互斥条件" class="headerlink" title="互斥条件"></a>互斥条件</h3><p>互斥条件是指多个线程不能同时使用同一个资源。</p>
<p>比如下图，如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。</p>
<p><img src="images/%E4%BA%92%E6%96%A5%E6%9D%A1%E4%BB%B6.png" alt="img"></p>
<h3 id="请求保持条件"><a href="#请求保持条件" class="headerlink" title="请求保持条件"></a>请求保持条件</h3><p>持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。</p>
<p><img src="images/%E6%8C%81%E6%9C%89%E5%B9%B6%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6.png" alt="img"></p>
<h3 id="不剥夺条件"><a href="#不剥夺条件" class="headerlink" title="不剥夺条件"></a>不剥夺条件</h3><p>不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。</p>
<p><img src="images/%E4%B8%8D%E5%8F%AF%E5%89%A5%E5%A4%BA%E6%9D%A1%E4%BB%B6.png" alt="img"></p>
<h3 id="循环等待条件"><a href="#循环等待条件" class="headerlink" title="循环等待条件"></a>循环等待条件</h3><p>环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。</p>
<p>比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。</p>
<p><img src="images/%E7%8E%AF%E8%B7%AF%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6.png" alt="img"></p>
<h3 id="避免死锁问题的发生"><a href="#避免死锁问题的发生" class="headerlink" title="避免死锁问题的发生"></a>避免死锁问题的发生</h3><p>避免死锁问题就只需要破环产生死锁的其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环循环等待条件。</p>
<p>那什么是资源有序分配法呢？线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。</p>
<h1 id="4-文件系统"><a href="#4-文件系统" class="headerlink" title="4 文件系统"></a>4 文件系统</h1><h2 id="4-1-文件系统的基本组成"><a href="#4-1-文件系统的基本组成" class="headerlink" title="4.1 文件系统的基本组成"></a>4.1 文件系统的基本组成</h2><h3 id="索引节点-amp-目录项"><a href="#索引节点-amp-目录项" class="headerlink" title="索引节点 &amp; 目录项"></a>索引节点 &amp; 目录项</h3><p><strong>文件系统是操作系统中负责管理持久数据的子系统</strong>，说简单点，就是负责把用户的文件存到磁盘硬件中，因为即使计算机断电了，磁盘里的数据并不会丢失，所以可以持久化地保存文件。</p>
<p>文件系统的基本数据单位是文件，它的目的是对磁盘上的文件进行组织管理，那组织的方式不同，就会形成不同的文件系统。</p>
<p>Linux 最经典的一句话是：「<strong>一切皆文件</strong>」，不仅有普通的文件和目录，就连块设备、管道、socket 等，也都是统一交给文件系统管理的。</p>
<p>Linux 文件系统会为每个文件分配两个数据结构：<strong>索引节点</strong>（index node）和<strong>目录项</strong>（directory entry），它们主要用来记录文件的元信息和目录层次结构。</p>
<ul>
<li>索引节点，也就是 <strong>inode</strong>，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。</li>
<li>目录项，也就是 <strong>dentry</strong>，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。</li>
</ul>
<p>由于索引节点唯一标识一个文件，而目录项记录着文件的名字，所以目录项和索引节点的关系是多对一，也就是说，一个文件可以有多个别名。比如，硬链接的实现就是多个目录项中的索引节点指向同一个文件。</p>
<h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><p>注意，<strong>目录</strong>（directory）也是文件，也是用索引节点唯一标识，和普通文件不同的是，普通文件在磁盘里面保存的是文件数据，而目录文件在磁盘里面保存子目录或文件。</p>
<p>目录项和目录是一个东西吗？</p>
<ul>
<li>虽然名字很相近，但是它们不是一个东西，目录是个文件，持久化存储在磁盘，而目录项是内核一个数据结构，缓存在内存。</li>
<li>如果查询目录频繁从磁盘读，效率会很低，所以内核会把已经读过的目录用目录项这个数据结构缓存在内存，下次再次读到相同的目录时，只需从内存读就可以，大大提高了文件系统的效率。</li>
<li>此外，目录项这个数据结构不只是表示目录，也是可以表示文件的。</li>
</ul>
<h3 id="文件数据是如何存储在磁盘？"><a href="#文件数据是如何存储在磁盘？" class="headerlink" title="文件数据是如何存储在磁盘？"></a>文件数据是如何存储在磁盘？</h3><p>磁盘读写的最小单位是<strong>扇区</strong>，扇区的大小只有 512B 大小，很明显，如果每次读写都以这么小为单位，那读写的效率会非常低。所以，文件系统把多个扇区组成了一个<strong>逻辑块</strong>，每次读写的最小单位就是逻辑块（数据块），Linux 中的逻辑块大小为 4KB，也就是一次性读写 8 个扇区，这将大大提高了磁盘的读写的效率。</p>
<p><img src="images/%E7%9B%AE%E5%BD%95%E9%A1%B9%E5%92%8C%E7%B4%A2%E5%BC%95%E5%85%B3%E7%B3%BB%E5%9B%BE.png" alt="img"></p>
<p>索引节点是存储在硬盘上的数据，那么为了加速文件的访问，通常会把索引节点加载到内存中。</p>
<p>磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区：</p>
<ul>
<li>超级块，用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等</li>
<li>索引节点区，用来存储索引节点</li>
<li>数据块区，用来存储文件或目录数据</li>
</ul>
<p>我们不可能把超级块和索引节点区全部加载到内存，这样内存肯定撑不住，所以只有当需要使用的时候，才将其加载进内存，它们加载进内存的时机是不同的：</p>
<ul>
<li>超级块：当文件系统挂载时进入内存；</li>
<li>索引节点区：当文件被访问时进入内存；</li>
</ul>
<h2 id="4-2-虚拟文件系统"><a href="#4-2-虚拟文件系统" class="headerlink" title="4.2 虚拟文件系统"></a>4.2 虚拟文件系统</h2><p>文件系统的种类众多，而操作系统希望<strong>对用户提供一个统一的接口</strong>，于是在用户层与文件系统层引入了中间层，这个中间层就称为<strong>虚拟文件系统</strong>（Virtual File System，VFS）。</p>
<p>VFS 定义了一组所有文件系统都支持的数据结构和标准接口，这样程序员不需要了解文件系统的工作原理，只需要了解 VFS 提供的统一接口即可。</p>
<p>在 Linux 文件系统中，用户空间、系统调用、虚拟文件系统、缓存、文件系统以及存储之间的关系如下图：</p>
<p><img src="images/%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F.png" alt="img"></p>
<h2 id="4-3-文件的使用"><a href="#4-3-文件的使用" class="headerlink" title="4.3 文件的使用"></a>4.3 文件的使用</h2><p>我们从用户角度来看文件的话，就是我们要怎么使用文件。首先，我们得通过系统调用来打开一个文件。</p>
<p><img src="images/%E5%86%99%E5%88%B0%E7%A3%81%E7%9B%98%E8%BF%87%E7%A8%8B.png" alt="write 的过程"></p>
<ul>
<li>首先用 open 系统调用打开文件，open 的参数中包含文件的路径名和文件名。</li>
<li>使用 write 写数据，其中 write 使用 open 所返回的文件描述符，并不使用文件名作为参数。</li>
<li>使用完文件后，要用 close 系统调用关闭文件，避免资源的泄露。</li>
</ul>
<p>我们打开了一个文件后，操作系统会跟踪进程打开的所有文件，所谓的跟踪呢，就是操作系统为每个进程维护一个打开文件表，文件表里的每一项代表「<strong>文件描述符</strong>」，所以说<strong>文件描述符是打开文件的标识</strong>。</p>
<p>在用户视角里，文件就是一个持久化的数据结构，但操作系统并不会关心你想存在磁盘上的任何的数据结构，操作系统的视角是如何把文件数据和磁盘块对应起来。所以，用户和操作系统对文件的读写操作是有差异的，用户习惯以字节的方式读写文件，而操作系统则是以数据块来读写文件，那屏蔽掉这种差异的工作就是文件系统了。</p>
<h2 id="4-4-文件的存储"><a href="#4-4-文件的存储" class="headerlink" title="4.4 文件的存储"></a>4.4 文件的存储</h2><p>文件的数据是要存储在硬盘上面的，数据在磁盘上的存放方式，就像程序在内存中存放的方式那样，有以下两种：</p>
<ul>
<li>连续空间存放方式</li>
<li>非连续空间存放方式</li>
</ul>
<h3 id="连续空间存放方式"><a href="#连续空间存放方式" class="headerlink" title="连续空间存放方式"></a>连续空间存放方式</h3><p><strong>连续空间存放</strong>方式顾名思义，文件存放在磁盘「连续的」物理空间中。这种模式下，文件的数据都是紧密相连，读写效率很高，因为一次磁盘寻道就可以读出整个文件。</p>
<p>使用连续存放的方式有一个前提，必须先知道一个文件的大小，这样文件系统才会根据文件的大小在磁盘上找到一块连续的空间分配给文件。所以，文件头里需要指定「<strong>起始块的位置</strong>」和「<strong>长度</strong>」，有了这两个信息就可以很好的表示文件存放方式是一块连续的磁盘空间。注意，此处说的文件头，就类似于 Linux 的 inode。</p>
<p>连续空间存放的方式虽然读写效率高，但是有「<strong>磁盘空间碎片</strong>」和「<strong>文件长度不易扩展</strong>」的缺陷。</p>
<h3 id="非连续空间存放方式"><a href="#非连续空间存放方式" class="headerlink" title="非连续空间存放方式"></a>非连续空间存放方式</h3><p><strong>非连续空间存放</strong>方式分为「<strong>链表方式</strong>」和「<strong>索引方式</strong>」。</p>
<h4 id="链表方式"><a href="#链表方式" class="headerlink" title="链表方式"></a>链表方式</h4><p>链表的方式存放是离散的，不连续的，于是就可以消除磁盘碎片，可大大提高磁盘空间的利用率，同时文件的长度可以动态扩展。根据实现的方式的不同，链表可分为「隐式链表」和「显式链接」两种形式。</p>
<p>文件要以「<strong>隐式链表</strong>」的方式存放的话，实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，这样一个数据块连着一个数据块，从链头开始就可以顺着指针找到所有的数据块，所以存放的方式可以是不连续的。</p>
<p>隐式链表的存放方式的缺点在于<strong>无法直接访问数据块</strong>，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失。</p>
<p>如果取出每个磁盘块的指针，把它放在内存的一个表中，就可以解决上述隐式链表的两个不足。这种实现方式就是「<strong>显式链接</strong>」，它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。</p>
<p>对于显式链接的工作方式，我们举个例子，文件 A 依次使用了磁盘块 4、7、2、10 和 12 ，文件 B 依次使用了磁盘块 6、3、11 和 14 。利用下图中的表，可以从第 4 块开始，顺着链走到最后，找到文件 A 的全部磁盘块。同样，从第 6 块开始，顺着链走到最后，也能够找出文件 B 的全部磁盘块。最后，这两个链都以一个不属于有效磁盘编号的特殊标记（如 -1 ）结束。内存中的这样一个表格称为<strong>文件分配表</strong>（File Allocation Table，FAT）。</p>
<p><img src="images/%E6%96%87%E4%BB%B6%E5%88%86%E9%85%8D%E8%A1%A8.png" alt="显式链接"></p>
<p>由于查找记录的过程是在内存中进行的，因而不仅显著地提高了检索速度，而且大大减少了访问磁盘的次数。但也正是整个表都存放在内存中的关系，它的主要的缺点是不适用于大磁盘。比如，对于 200GB 的磁盘和 1KB 大小的块，这张表需要有 2 亿项，每一项对应于这 2 亿个磁盘块中的一个块，每项如果需要 4 个字节，那这张表要占用 800MB 内存，很显然 FAT 方案对于大磁盘而言不太合适。</p>
<h4 id="索引方式"><a href="#索引方式" class="headerlink" title="索引方式"></a>索引方式</h4><p>链表的方式解决了连续分配的磁盘碎片和文件动态扩展的问题，但是不能有效支持直接访问（FAT除外），索引的方式可以解决这个问题。</p>
<p>索引的实现是为每个文件创建一个「索引数据块」，里面存放的是指向文件数据块的指针列表，说白了就像书的目录一样，要找哪个章节的内容，看目录查就可以。另外，文件头需要包含指向「索引数据块」的指针，这样就可以通过文件头知道索引数据块的位置，再通过索引数据块里的索引信息找到对应的数据块。</p>
<p>创建文件时，索引块的所有指针都设为空。当首次写入第 i 块时，先从空闲空间中取得一个块，再将其地址写到索引块的第 i 个条目。</p>
<p><img src="images/%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F-%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F.png" alt="索引的方式"></p>
<p>索引的优点在于：</p>
<ul>
<li>文件的创建、增大、缩小很方便；</li>
<li>不会有碎片的问题；</li>
<li>支持顺序读写和随机读写；</li>
</ul>
<p>索引的缺点在于：</p>
<ul>
<li>由于索引数据也是存放在磁盘块的，如果文件很小，明明只需一块就可以存放的下，但还是需要额外分配一块来存放索引数据，所以缺陷之一就是存储索引带来的开销。</li>
</ul>
<p>如果文件很大，大到一个索引数据块放不下索引信息，这时又要如何处理大文件的存放呢？我们可以通过组合的方式，来处理大文件的存。</p>
<p>先来看看链表 + 索引的组合，这种组合称为「<strong>链式索引块</strong>」，它的实现方式是在索引数据块留出一个存放下一个索引数据块的指针，于是当一个索引数据块的索引信息用完了，就可以通过指针的方式，找到下一个索引数据块的信息。那这种方式也会出现前面提到的链表方式的问题，万一某个指针损坏了，后面的数据也就会无法读取了。</p>
<p><img src="images/%E9%93%BE%E5%BC%8F%E7%B4%A2%E5%BC%95%E5%9D%97.png" alt="链式索引块"></p>
<p>还有另外一种组合方式是索引 + 索引的方式，这种组合称为「多级索引块」，实现方式是通过一个索引块来存放多个索引数据块，一层套一层索引。</p>
<p><img src="images/%E5%A4%9A%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%9D%97.png" alt="多级索引块"></p>
<p>实现方式的比较：</p>
<p><img src="images/%E6%96%87%E4%BB%B6%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F%E6%AF%94%E8%BE%83-20221019142022165.png" alt="img"></p>
<p>Unix的文件系统组合了这些文件存放方式的优点，根据文件的大小，存放的方式会有所变化，能很灵活地支持小文件和大文件的存放。</p>
<h2 id="4-5-空闲空间管理"><a href="#4-5-空闲空间管理" class="headerlink" title="4.5 空闲空间管理"></a>4.5 空闲空间管理</h2><p>前面说到的文件的存储是针对已经被占用的数据块组织和管理，接下来的问题是，如果我要保存一个数据块，我应该放在硬盘上的哪个位置呢？难道需要将所有的块扫描一遍，找个空的地方随便放吗？这种方式效率就太低了，所以针对磁盘的空闲空间也是要引入管理的机制。</p>
<h3 id="空闲表法"><a href="#空闲表法" class="headerlink" title="空闲表法"></a>空闲表法</h3><p>空闲表法就是为所有空闲空间建立一张表，表内容包括空闲区的第一个块号和该空闲区的块个数，注意，这个方式是连续分配的。如下图：</p>
<p><img src="images/%E7%A9%BA%E9%97%B2%E8%A1%A8%E6%B3%95.png" alt="空闲表法"></p>
<p>当请求分配磁盘空间时，系统依次扫描空闲表里的内容，直到找到一个合适的空闲区域为止。当用户撤销一个文件时，系统回收文件空间。这时，也需顺序扫描空闲表，寻找一个空闲表条目并将释放空间的第一个物理块号及它占用的块数填到这个条目中。</p>
<p>这种方法仅当有少量的空闲区时才有较好的效果。因为，如果存储空间中有着大量的小的空闲区，则空闲表变得很大，这样查询效率会很低。另外，这种分配技术适用于建立连续文件。</p>
<h3 id="空闲链表法"><a href="#空闲链表法" class="headerlink" title="空闲链表法"></a>空闲链表法</h3><p>我们也可以使用「链表」的方式来管理空闲空间，每一个空闲块里有一个指针指向下一个空闲块，这样也能很方便的找到空闲块并管理起来。如下图：</p>
<p><img src="images/%E7%A9%BA%E9%97%B2%E5%9D%97%E9%93%BE%E8%A1%A8.png" alt="空闲链表法"></p>
<p>当创建文件需要一块或几块时，就从链头上依次取下一块或几块。反之，当回收空间时，把这些空闲块依次接到链头上。</p>
<p>这种技术只要在主存中保存一个指针，令它指向第一个空闲块。其特点是简单，但不能随机访问，工作效率低，因为每当在链上增加或移动空闲块时需要做很多 I/O 操作，同时数据块的指针消耗了一定的存储空间。</p>
<p>空闲表法和空闲链表法都不适合用于大型文件系统，因为这会使空闲表或空闲链表太大。</p>
<h3 id="位图法"><a href="#位图法" class="headerlink" title="位图法"></a>位图法</h3><p>位图是利用二进制的一位来表示磁盘中一个盘块的使用情况，磁盘上所有的盘块都有一个二进制位与之对应。当值为 0 时，表示对应的盘块空闲，值为 1 时，表示对应的盘块已分配。它形式如下：</p>
<pre><code>1111110011111110001110110111111100111 ...</code></pre>
<p>在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，因为 inode 也是存储在磁盘的，自然也要有对其管理。</p>
<h2 id="4-6-文件系统的结构"><a href="#4-6-文件系统的结构" class="headerlink" title="4.6 文件系统的结构"></a>4.6 文件系统的结构</h2><p>前面提到 Linux 是用位图的方式管理空闲空间，用户在创建一个新文件时，Linux 内核会通过 inode 的位图找到空闲可用的 inode，并进行分配。要存储数据时，会通过块的位图找到空闲的块，并分配，但仔细计算一下还是有问题的。</p>
<p>数据块的位图是放在磁盘块里的，假设是放在一个块里，一个块 4K，每位表示一个数据块，共可以表示 4 * 1024 * 8 = 2^15 个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 2^15 * 4 * 1024 = 2^27 个 byte，也就是 128M。</p>
<p>也就是说按照上面的结构，如果采用「一个块的位图 + 一系列的块」，外加「一个块的 inode 的位图 + 一系列的 inode 的结构」能表示的最大空间也就 128M，这太少了，现在很多文件都比这个大。</p>
<p>在 Linux 文件系统，把这个结构称为一个块组，那么有 N 多的块组，就能够表示 N 大的文件：</p>
<p><img src="images/%E5%9D%97%E7%BB%84.png" alt="img"></p>
<p>最前面的第一个块是引导块，在系统启动时用于启用引导，接着后面就是一个一个连续的块组了，块组的内容如下：</p>
<ul>
<li>超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。</li>
<li>块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。</li>
<li>数据位图和 inode 位图， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。</li>
<li>inode 列表，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。</li>
<li>数据块，包含文件的有用数据。</li>
</ul>
<p>可以会发现每个块组里有很多重复的信息，比如超级块和块组描述符表，这两个都是全局信息，而且非常的重要，这么做是有两个原因：</p>
<ul>
<li>如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。</li>
<li>通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。</li>
</ul>
<h2 id="4-7-目录的存储"><a href="#4-7-目录的存储" class="headerlink" title="4.7 目录的存储"></a>4.7 目录的存储</h2><p>和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。</p>
<p>在目录文件的块中，最简单的保存格式就是列表，就是一项一项地将目录下的文件信息（如文件名、文件 inode、文件类型等）列在表里。列表中每一项就代表该目录下的文件的文件名和对应的 inode，通过这个 inode，就可以找到真正的文件。</p>
<p><img src="images/%E7%9B%AE%E5%BD%95%E5%93%88%E5%B8%8C%E8%A1%A8.png" alt="目录格式哈希表"></p>
<p>通常，第一项是「.」，表示当前目录，第二项是「..」，表示上一级目录，接下来就是一项一项的文件名和 inode。</p>
<p>如果一个目录有超级多的文件，我们要想在这个目录下找文件，按照列表一项一项的找，效率就不高了。于是，保存目录的格式改成哈希表，对文件名进行哈希计算，把哈希值保存起来，如果我们要查找一个目录下面的文件名，可以通过名称取哈希。如果哈希能够匹配上，就说明这个文件的信息在相应的块里面。</p>
<p>Linux 系统的 ext 文件系统就是采用了哈希表，来保存目录的内容，这种方法的优点是查找非常迅速，插入和删除也较简单，不过需要一些预备措施来避免哈希冲突。</p>
<p>目录查询是通过在磁盘上反复搜索完成，需要不断地进行 I/O 操作，开销较大。所以，为了减少 I/O 操作，把当前使用的文件目录缓存在内存，以后要使用该文件时只要在内存中操作，从而降低了磁盘操作次数，提高了文件系统的访问速度。</p>
<h2 id="4-8-软链接和硬链接"><a href="#4-8-软链接和硬链接" class="headerlink" title="4.8 软链接和硬链接"></a>4.8 软链接和硬链接</h2><p>有时候我们希望给某个文件取个别名，那么在 Linux 中可以通过<strong>硬链接</strong>（Hard Link） 和<strong>软链接</strong>（Symbolic Link） 的方式来实现，它们都是比较特殊的文件，但是实现方式也是不相同的。</p>
<p><strong>硬链接是多个目录项中的「索引节点」指向一个文件</strong>，也就是指向同一个 inode，但是 inode 是不可能跨越文件系统的，每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。</p>
<p><img src="images/%E7%A1%AC%E9%93%BE%E6%8E%A5-2.png" alt="硬链接"></p>
<p>软链接相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。</p>
<p><img src="images/%E8%BD%AF%E9%93%BE%E6%8E%A5.png" alt="软链接"></p>
<h2 id="4-9-文件-I-O"><a href="#4-9-文件-I-O" class="headerlink" title="4.9 文件 I/O"></a>4.9 文件 I/O</h2><h3 id="缓冲与非缓冲-I-O"><a href="#缓冲与非缓冲-I-O" class="headerlink" title="缓冲与非缓冲 I/O"></a>缓冲与非缓冲 I/O</h3><p>文件操作的标准库是可以实现数据的缓存，那么根据「是否利用标准库缓冲」，可以把文件 I/O 分为缓冲 I/O 和非缓冲 I/O：</p>
<ul>
<li>缓冲 I/O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。</li>
<li>非缓冲 I/O，直接通过系统调用访问文件，不经过标准库缓存。</li>
</ul>
<p>这里所说的「缓冲」特指标准库内部实现的缓冲。比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。</p>
<h3 id="直接与非直接-I-O"><a href="#直接与非直接-I-O" class="headerlink" title="直接与非直接 I/O"></a>直接与非直接 I/O</h3><p>我们都知道磁盘 I/O 是非常慢的，所以 Linux 内核为了减少磁盘 I/O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「<strong>Page Cache</strong>」，只有当缓存满足某些条件的时候，才发起磁盘 I/O 的请求。</p>
<p>那么，根据是「否利用操作系统的缓存」，可以把文件 I/O 分为直接 I/O 与非直接 I/O：</p>
<ul>
<li>直接 I/O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。</li>
<li>非直接 I/O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。</li>
</ul>
<p>如果用了非直接 I/O 进行写数据操作，内核什么情况下才会把缓存数据写入到磁盘？</p>
<ul>
<li>在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；</li>
<li>用户主动调用 sync，内核缓存会刷到磁盘上；</li>
<li>当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；</li>
<li>内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；</li>
</ul>
<h3 id="阻塞与非阻塞-I-O-VS-同步与异步-I-O"><a href="#阻塞与非阻塞-I-O-VS-同步与异步-I-O" class="headerlink" title="阻塞与非阻塞 I/O VS 同步与异步 I/O"></a>阻塞与非阻塞 I/O VS 同步与异步 I/O</h3><p>为什么把阻塞 / 非阻塞与同步与异步放一起说的呢？因为它们确实非常相似，也非常容易混淆，不过它们之间的关系还是有点微妙的。</p>
<p>先来看看<strong>阻塞 I/O</strong>，当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。</p>
<p>注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。过程如下图：</p>
<p>![阻塞 I/O](images/阻塞 I_O.png)</p>
<p>知道了阻塞 I/O ，来看看<strong>非阻塞 I/O</strong>，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。过程如下图：</p>
<p>![非阻塞 I/O](images/非阻塞 I_O .png)</p>
<p>注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</p>
<p>应用程序每次轮询内核的 I/O 是否准备好，感觉有点傻乎乎，因为轮询的过程中，应用程序啥也做不了，只是在循环。为了解决这种傻乎乎轮询方式，于是 <strong>I/O 多路复用</strong>技术就出来了，如 select、poll，它是通过 I/O 事件分发，当内核数据准备好时，再以事件通知应用程序进行操作。</p>
<p>这个做法大大改善了 CPU 的利用率，因为当调用了 I/O 多路复用接口，如果没有事件发生，那么当前线程就会发生阻塞，这时 CPU 会切换其他线程执行任务，等内核发现有事件到来的时候，会唤醒阻塞在 I/O 多路复用接口的线程，然后用户可以进行后续的事件处理。</p>
<p>整个流程要比阻塞 IO 要复杂，似乎也更浪费性能。但 I/O 多路复用接口最大的优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后不断地调用 I/O 多路复用接口读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。</p>
<p>下图是使用 select I/O 多路复用过程。注意，read 获取数据的过程（数据从内核态拷贝到用户态的过程），也是一个同步的过程，需要等待：</p>
<p>![I/O 多路复用](images/基于非阻塞 I_O 的多路复用.png)</p>
<p>实际上，无论是阻塞 I/O、非阻塞 I/O，还是基于非阻塞 I/O 的多路复用都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</p>
<p>而真正的<strong>异步 I/O</strong> 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。</p>
<p>当我们发起 aio_read 之后，就立即返回，内核自动将数据从内核空间拷贝到应用程序空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图：</p>
<p>![异步 I/O](images/异步 I_O.png)</p>
<h2 id="4-10-Page-Cache"><a href="#4-10-Page-Cache" class="headerlink" title="4.10 Page Cache"></a>4.10 Page Cache</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>为了理解 Page Cache，我们不妨先看一下 Linux 的文件 I/O 系统，如下图所示：</p>
<p><img src="images/72568a29816fa9b505f15edac68adee2.jpeg" alt="img"></p>
<p>上图中，红色部分为 Page Cache。可见 Page Cache 的本质是由 Linux 内核管理的内存区域。我们通过 mmap 以及 buffered I/O 将文件读取到内存空间实际上都是读取到 Page Cache 中。</p>
<p>通过读取 /proc/meminfo 文件，能够实时获取系统内存情况：</p>
<pre><code>$ cat /proc/meminfo
...
Buffers:            1224 kB
Cached:           111472 kB
SwapCached:        36364 kB
Active:          6224232 kB
Inactive:         979432 kB
Active(anon):    6173036 kB
Inactive(anon):   927932 kB
Active(file):      51196 kB
Inactive(file):    51500 kB
...
Shmem:             10000 kB
...
SReclaimable:      43532 kB
...</code></pre>
<p>根据上面的数据，你可以简单得出这样的公式（等式两边之和都是 112696 KB）：</p>
<pre><code>Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached</code></pre>
<p>两边等式都是 Page Cache，即：</p>
<pre><code>Page Cache = Buffers + Cached + SwapCached</code></pre>
<h3 id="page-与-Page-Cache"><a href="#page-与-Page-Cache" class="headerlink" title="page 与 Page Cache"></a>page 与 Page Cache</h3><p>page 是内存管理分配的基本单位， Page Cache 由多个 page 构成。page 在操作系统中通常为 4KB 大小（32bits/64bits），而 Page Cache 的大小则为 4KB 的整数倍。</p>
<p>另一方面，并不是所有 page 都被组织为 Page Cache。</p>
<p>Linux 系统上供用户可访问的内存分为两个类型，即：</p>
<ul>
<li>File-backed pages：文件备份页也就是 Page Cache 中的 page，对应于磁盘上的若干数据块；对于这些页最大的问题是脏页回盘；</li>
<li>Anonymous pages：匿名页不对应磁盘上的任何磁盘数据块，它们是进程的运行是内存空间（例如方法栈、局部变量表等属性）；</li>
</ul>
<p>为什么 Linux 不把 Page Cache 称为 block cache，这不是更好吗？这是因为从磁盘中加载到内存的数据不仅仅放在 Page Cache 中，还放在 buffer cache 中。</p>
<p>内存是一种珍惜资源，当内存不够用时，内存管理单元（Memory Mangament Unit）需要提供调度算法来回收相关内存空间。内存空间回收的方式通常就是 swap，即交换到持久化存储设备上。</p>
<p>File-backed pages（Page Cache）的内存回收代价较低。Page Cache 通常对应于一个文件上的若干顺序块，因此可以通过顺序 I/O 的方式落盘。另一方面，如果 Page Cache 上没有进行写操作（所谓的没有脏页），甚至不会将 Page Cache 回盘，因为数据的内容完全可以通过再次读取磁盘文件得到。</p>
<p>Page Cache 的主要难点在于脏页回盘，这个内容会在后面进行详细说明。</p>
<p>Anonymous pages 的内存回收代价较高。这是因为 Anonymous pages 通常随机地写入持久化交换设备。另一方面，无论是否有写操作，为了确保数据不丢失，Anonymous pages 在 swap 时必须持久化到磁盘。</p>
<h3 id="Swap-与缺页中断"><a href="#Swap-与缺页中断" class="headerlink" title="Swap 与缺页中断"></a>Swap 与缺页中断</h3><p>Swap 机制指的是当物理内存不够用，内存管理单元（Memory Mangament Unit，MMU）需要提供调度算法来回收相关内存空间，然后将清理出来的内存空间给当前内存申请方。</p>
<p>Swap 机制存在的本质原因是 Linux 系统提供了虚拟内存管理机制，每一个进程认为其独占内存空间，因此所有进程的内存空间之和远远大于物理内存。所有进程的内存空间之和超过物理内存的部分就需要交换到磁盘上。</p>
<p>操作系统以 page 为单位管理内存，当进程发现需要访问的数据不在内存时，操作系统可能会将数据以页的方式加载到内存中。上述过程被称为缺页中断，当操作系统发生缺页中断时，就会通过系统调用将 page 再次读到内存中。</p>
<p>但主内存的空间是有限的，当主内存中不包含可以使用的空间时，操作系统会从选择合适的物理内存页驱逐回磁盘，为新的内存页让出位置，选择待驱逐页的过程在操作系统中叫做页面替换（Page Replacement），替换操作又会触发 swap 机制。</p>
<p>如果物理内存足够大，那么可能不需要 Swap 机制，但是 Swap 在这种情况下还是有一定优势：对于有发生内存泄漏几率的应用程序（进程），Swap 交换分区更是重要，这可以确保内存泄露不至于导致物理内存不够用，最终导致系统崩溃。但内存泄露会引起频繁的 swap，此时非常影响操作系统的性能。</p>
<p>为什么 SwapCached 也是 Page Cache 的一部分？</p>
<p>这是因为当匿名页（Inactive(anon) 以及 Active(anon)）先被交换（swap out）到磁盘上后，然后再加载回（swap in）内存中，由于读入到内存后原来的 Swap File 还在，所以 SwapCached 也可以认为是 File-backed page，即属于 Page Cache。这个过程如下图所示：</p>
<p><img src="images/cbba24cac4668625c4e32d8cf641cf9c.jpeg" alt="图片"></p>
<h3 id="Page-Cache-与-buffer-cache"><a href="#Page-Cache-与-buffer-cache" class="headerlink" title="Page Cache 与 buffer cache"></a>Page Cache 与 buffer cache</h3><p>用一句话来解释：Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。</p>
<ul>
<li>页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；</li>
<li>块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。</li>
</ul>
<p>Page Cache 与 buffer cache 的共同目的都是加速数据 I/O：</p>
<ul>
<li>写数据时首先写到缓存，将写入的页标记为 dirty，然后向外部存储 flush，也就是缓存写机制中的 write-back（另一种是 write-through，Linux 默认情况下不采用）；</li>
<li>读数据时首先读取缓存，如果未命中，再去外部存储读取，并且将读取来的数据也加入缓存。操作系统总是积极地将所有空闲内存都用作 Page Cache 和 buffer cache，当内存不够用时也会用 LRU 等算法淘汰缓存页。</li>
</ul>
<p>在 Linux 2.4 版本的内核之前，Page Cache 与 buffer cache 是完全分离的。但是，块设备大多是磁盘，磁盘上的数据又大多通过文件系统来组织，这种设计导致很多数据被缓存了两次，浪费内存。</p>
<p>所以在 2.4 版本内核之后，两块缓存近似融合在了一起：如果一个文件的页加载到了 Page Cache，那么同时 buffer cache 只需要维护块指向页的指针就可以了。只有那些没有文件表示的块，或者绕过了文件系统直接操作（如dd命令）的块，才会真正放到 buffer cache 里。</p>
<p>因此，我们现在提起 Page Cache，基本上都同时指 Page Cache 和 buffer cache 两者，本文之后也不再区分，直接统称为 Page Cache。</p>
<h3 id="Page-Cache-与预读"><a href="#Page-Cache-与预读" class="headerlink" title="Page Cache 与预读"></a>Page Cache 与预读</h3><p>操作系统为基于 Page Cache 的读缓存机制提供预读机制（PAGE_READAHEAD），一个例子是：</p>
<ul>
<li>用户线程仅仅请求读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。</li>
<li>但是操作系统出于局部性原理会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；</li>
</ul>
<h3 id="Page-Cache-与文件持久化的一致性和可靠性"><a href="#Page-Cache-与文件持久化的一致性和可靠性" class="headerlink" title="Page Cache 与文件持久化的一致性和可靠性"></a>Page Cache 与文件持久化的一致性和可靠性</h3><p>任何系统引入缓存，就会引发一致性问题：内存中的数据与磁盘中的数据不一致，例如常见后端架构中的 Redis 缓存与 MySQL 数据库就存在一致性问题。</p>
<p>Linux 提供多种机制来保证数据一致性，但无论是单机上的内存与磁盘一致性，还是分布式组件中节点 1 与节点 2 、节点 3 的数据一致性问题，理解的关键是 trade-off：吞吐量与数据一致性保证是一对矛盾。</p>
<p>首先，需要我们理解一下文件的数据。文件 = 数据 + 元数据。元数据用来描述文件的各种属性，也必须存储在磁盘上。因此，我们说保证文件一致性其实包含了两个方面：数据一致+元数据一致。文件的元数据包括：文件大小、创建时间、访问时间、属主属组等信息。</p>
<p>我们考虑如下一致性问题：如果发生写操作并且对应的数据在 Page Cache 中，那么写操作就会直接作用于 Page Cache 中，此时如果数据还没刷新到磁盘，那么内存中的数据就领先于磁盘，此时对应 page 就被称为 Dirty page。</p>
<p>当前 Linux 下以两种方式实现文件一致性：</p>
<ul>
<li>Write Through（写穿）：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；</li>
<li>Write Back（写回）：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；</li>
</ul>
<p>上述两种方式最终都依赖于系统调用，主要分为如下三种系统调用：</p>
<ul>
<li>fsync(intfd)：将 fd 代表的文件的脏数据和脏元数据全部刷新至磁盘中。</li>
<li>fdatasync(fd)：将 fd 代表的文件的脏数据刷新至磁盘，同时对必要的元数据刷新至磁盘中，这里所说的必要的概念是指：对接下来访问文件有关键作用的信息，如文件大小，而文件修改时间等不属于必要信息</li>
<li>sync()：则是对系统中所有的脏的文件数据元数据刷新至磁盘中</li>
</ul>
<p>上述三种系统调用可以分别由用户进程与内核进程发起。下面我们研究一下内核线程的相关特性：</p>
<ol>
<li><p>创建的针对回写任务的内核线程数由系统中持久存储设备决定，为每个存储设备创建单独的刷新线程；</p>
</li>
<li><p>关于多线程的架构问题，Linux 内核采取了 Lighthttp 的做法，即系统中存在一个管理线程和多个刷新线程（每个持久存储设备对应一个刷新线程）。管理线程监控设备上的脏页面情况，若设备一段时间内没有产生脏页面，就销毁设备上的刷新线程；若监测到设备上有脏页面需要回写且尚未为该设备创建刷新线程，那么创建刷新线程处理脏页面回写。而刷新线程的任务较为单调，只负责将设备中的脏页面回写至持久存储设备中。</p>
</li>
<li><p>刷新线程刷新设备上脏页面大致设计如下：</p>
</li>
</ol>
<ul>
<li>每个设备保存脏文件链表，保存的是该设备上存储的脏文件的 inode 节点。所谓的回写文件脏页面即回写该 inode 链表上的某些文件的脏页面；</li>
<li>系统中存在多个回写时机，第一是应用程序主动调用回写接口（fsync，fdatasync 以及 sync 等），第二管理线程周期性地唤醒设备上的回写线程进行回写，第三是某些应用程序/内核任务发现内存不足时要回收部分缓存页面而事先进行脏页面回写，设计一个统一的框架来管理这些回写任务非常有必要。</li>
</ul>
<p>Write Through 与 Write back 在持久化的可靠性上有所不同：</p>
<ul>
<li>Write Through 以牺牲系统 I/O 吞吐量作为代价，向上层应用确保一旦写入，数据就已经落盘，不会丢失；</li>
<li>Write back 在系统发生宕机的情况下无法确保数据已经落盘，因此存在数据丢失的问题。不过，在程序挂了，例如被 kill -9，Page Cache 中的数据操作系统还是会确保落盘；</li>
</ul>
<h3 id="Page-Cache-的优劣势"><a href="#Page-Cache-的优劣势" class="headerlink" title="Page Cache 的优劣势"></a>Page Cache 的优劣势</h3><p>优势：</p>
<ol>
<li>加快数据访问</li>
</ol>
<p>如果数据能够在内存中进行缓存，那么下一次访问就不需要通过磁盘 I/O 了，直接命中内存缓存即可。</p>
<p>由于内存访问比磁盘访问快很多，因此加快数据访问是 Page Cache 的一大优势。</p>
<ol start="2">
<li>减少 I/O 次数，提高系统磁盘 I/O 吞吐量</li>
</ol>
<p>得益于 Page Cache 的缓存以及预读能力，而程序又往往符合局部性原理，因此通过一次 I/O 将多个 page 装入 Page Cache 能够减少磁盘 I/O 次数， 进而提高系统磁盘 I/O 吞吐量。</p>
<p>劣势：</p>
<ol>
<li>最直接的缺点是需要占用额外物理内存空间</li>
</ol>
<p>物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I/O 负载的上升。</p>
<ol start="2">
<li>对应用层并没有提供很好的管理 API，几乎是透明管理</li>
</ol>
<p>应用层即使想优化 Page Cache 的使用策略也很难进行。因此一些应用选择在用户空间实现自己的 page 管理，而不使用 page cache，例如 MySQL InnoDB 存储引擎以 16KB 的页进行管理。</p>
<ol start="3">
<li>在某些应用场景下比 Direct I/O 多一次磁盘读 I/O 以及磁盘写 I/O</li>
</ol>
<p>Direct I/O 即直接 I/O。其名字中的”直接”二字用于区分使用 page cache 机制的缓存 I/O：</p>
<ul>
<li>缓存文件 I/O：用户空间要读写一个文件并不直接与磁盘交互，而是中间夹了一层缓存，即 page cache；</li>
<li>直接文件 I/O：用户空间读取的文件直接与磁盘交互，没有中间 page cache 层；</li>
</ul>
<p>“直接”在这里还有另一层语义：其他所有技术中，数据至少需要在内核空间存储一份，但是在 Direct I/O 技术中，数据直接存储在用户空间中，绕过了内核。</p>
<p><img src="images/503d7d5d3f330d64fcade48b312f767d.jpeg" alt="directIO"></p>
<p>此时用户空间直接通过 DMA 的方式与磁盘以及网卡进行数据拷贝。</p>
<p>Direct I/O 的读写非常有特点：</p>
<ul>
<li>Write 操作：由于其不使用 page cache，所以其进行写文件，如果返回成功，数据就真的落盘了（不考虑磁盘自带的缓存）；</li>
<li>Read 操作：由于其不使用 page cache，每次读操作是真的从磁盘中读取，不会从文件系统的缓存中读取。</li>
</ul>
<h3 id="进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？"><a href="#进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？" class="headerlink" title="进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？"></a>进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？</h3><p>答案，是不会的。</p>
<p><img src="images/1541c881598f554920355f0a3c5780fd.png" alt="img"></p>
<p>因为进程在执行 write （使用缓冲 IO）系统调用的时候，实际上是将文件数据写到了内核的 page cache，它是文件系统中用于缓存文件数据的缓冲，所以即使进程崩溃了，文件数据还是保留在内核的 page cache，我们读数据的时候，也是从内核的 page cache 读取，因此还是依然读的进程崩溃前写入的数据。</p>
<p>内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。</p>
<p>当然， 我们也可以在程序里调用 fsync 函数，在写文文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。</p>
<h2 id="4-11-磁盘调度算法"><a href="#4-11-磁盘调度算法" class="headerlink" title="4.11 磁盘调度算法"></a>4.11 磁盘调度算法</h2><p>我们来看看磁盘的结构，如下图：</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.jpg" alt="磁盘的结构"></p>
<p>常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 512 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。</p>
<p>磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。</p>
<p>寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。</p>
<p>假设有下面一个请求序列，每个数字代表磁道的位置：98，183，37，122，14，124，65，67</p>
<p>初始磁头当前的位置是在第 53 磁道。</p>
<p>接下来，分别对以上的序列，作为每个调度算法的例子。</p>
<h3 id="先来先服务"><a href="#先来先服务" class="headerlink" title="先来先服务"></a>先来先服务</h3><p>先来先服务（First-Come，First-Served，FCFS），顾名思义，先到来的请求，先被服务。</p>
<p>那按照这个序列的话：</p>
<p>98，183，37，122，14，124，65，67</p>
<p>那么，磁盘的写入顺序是从左到右，如下图：</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.png" alt="先来先服务"></p>
<p>先来先服务算法总共移动了 640 个磁道的距离，这么一看这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。</p>
<h3 id="最短寻道时间优先"><a href="#最短寻道时间优先" class="headerlink" title="最短寻道时间优先"></a>最短寻道时间优先</h3><p>最短寻道时间优先（Shortest Seek First，SSF）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求，还是以这个序列为例子：</p>
<p>98，183，37，122，14，124，65，67</p>
<p>那么，那么根据距离磁头（ 53 位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序：</p>
<p>65，67，37，14，98，122，124，183</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%9C%80%E7%9F%AD%E5%AF%BB%E9%81%93%E6%97%B6%E9%97%B4%E4%BC%98%E5%85%88.png" alt="最短寻道时间优先"></p>
<p>磁头移动的总距离是 236 磁道，相比先来先服务性能提高了不少。</p>
<p>但这个算法可能存在某些请求的饥饿，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183 磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里产生饥饿的原因是磁头在一小块区域来回移动。</p>
<h3 id="扫描算法"><a href="#扫描算法" class="headerlink" title="扫描算法"></a>扫描算法</h3><p>最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。</p>
<p>为了防止这个问题，可以规定：磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（Scan）算法。这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。</p>
<p>还是以这个序列为例子，磁头的初始位置是 53：</p>
<p>98，183，37，122，14，124，65，67</p>
<p>那么，假设扫描调度算先朝磁道号减少的方向移动，具体请求则会是下列从左到右的顺序：</p>
<p>37，14，0，65，67，98，122，124，183</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95.png" alt="扫描算法"></p>
<p>磁头先响应左边的请求，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。</p>
<p>扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。</p>
<h3 id="循环扫描算法"><a href="#循环扫描算法" class="headerlink" title="循环扫描算法"></a>循环扫描算法</h3><p>扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。</p>
<p>循环扫描（Circular Scan, CSCAN ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。</p>
<p>还是以这个序列为例子，磁头的初始位置是 53：</p>
<p>98，183，37，122，14，124，65，67</p>
<p>那么，假设循环扫描调度算先朝磁道增加的方向移动，具体请求会是下列从左到右的顺序：</p>
<p>65，67，98，122，124，183，199，0，14，37</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-SCAN%E7%AE%97%E6%B3%95.png" alt="循环扫描算法"></p>
<p>磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。</p>
<p>循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。</p>
<h3 id="LOOK-与-C-LOOK算法"><a href="#LOOK-与-C-LOOK算法" class="headerlink" title="LOOK 与 C-LOOK算法"></a>LOOK 与 C-LOOK算法</h3><p>我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。</p>
<p>那这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。</p>
<p>那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求。</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-LOOK%E7%AE%97%E6%B3%95.png" alt="LOOK 算法"></p>
<p>而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。</p>
<p><img src="images/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-LOOK%E7%AE%97%E6%B3%95.png" alt="C-LOOK 算法"></p>
<h1 id="5-设备管理"><a href="#5-设备管理" class="headerlink" title="5 设备管理"></a>5 设备管理</h1><h2 id="5-1-设备控制器"><a href="#5-1-设备控制器" class="headerlink" title="5.1 设备控制器"></a>5.1 设备控制器</h2><p>我们的电脑设备可以接非常多的输入输出设备，比如键盘、鼠标、显示器、网卡、硬盘、打印机、音响等等，每个设备的用法和功能都不同，那操作系统是如何把这些输入输出设备统一管理的呢?</p>
<p>为了屏蔽设备之间的差异，每个设备都有一个叫设备控制器（Device Control） 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等。</p>
<p><img src="images/I_O%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84.png" alt="计算机 I/O 系统结构"></p>
<p>因为这些控制器都很清楚的知道对应设备的用法和功能，所以 CPU 是通过设备控制器来和设备打交道的。</p>
<p>设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信，比如：</p>
<ul>
<li>通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行某些其他操作。</li>
<li>通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。</li>
</ul>
<p>实际上，控制器是有三类寄存器：</p>
<ul>
<li><strong>数据寄存器</strong>（Data Register）：CPU 向 I/O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I/O 设备。</li>
<li><strong>命令寄存器</strong>（Command Register）：CPU 发送一个命令，告诉 I/O 设备，要进行输入/输出操作，于是就会交给 I/O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。</li>
<li><strong>状态寄存器</strong>（Status Register）：目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。</li>
</ul>
<p>CPU 通过读写设备控制器中的寄存器控制设备，这可比 CPU 直接控制输入输出设备，要方便和标准很多。</p>
<p>另外， 输入输出设备可分为两大类 ：</p>
<ul>
<li><strong>块设备</strong>：把数据存储在固定大小的块中，每个块有自己的地址，硬盘、USB 是常见的块设备。</li>
<li><strong>字符设备</strong>：以字符为单位发送或接收一个字符流，字符设备是不可寻址的，也没有任何寻道操作，鼠标是常见的字符设备。</li>
</ul>
<p>块设备通常传输的数据量会非常大，于是控制器设立了一个可读写的<strong>数据缓冲区</strong>：</p>
<ul>
<li>CPU 写入数据到控制器的缓冲区时，当缓冲区的数据囤够了一部分，才会发给设备。</li>
<li>CPU 从控制器的缓冲区读取数据时，也需要缓冲区囤够了一部分，才拷贝到内存。</li>
</ul>
<p>这样做是为了减少对设备的频繁操作。</p>
<p>CPU 与设备的控制寄存器和数据缓冲区进行通信存在两个方法：</p>
<ul>
<li>端口 I/O，每个控制寄存器被分配一个 I/O 端口，可以通过特殊的汇编指令操作这些寄存器，比如 in/out 类似的指令。</li>
<li>内存映射 I/O，将所有控制寄存器映射到内存空间中，这样就可以像读写内存一样读写数据缓冲区。</li>
</ul>
<h2 id="5-2-I-O-控制方式"><a href="#5-2-I-O-控制方式" class="headerlink" title="5.2 I/O 控制方式"></a>5.2 I/O 控制方式</h2><p>在前面我知道，每种设备都有一个设备控制器，控制器相当于一个小 CPU，它可以自己处理一些事情，但有个问题是，当 CPU 给设备发送了一个指令，让设备控制器去读设备的数据，它读完的时候，要怎么通知 CPU 呢？</p>
<ol>
<li><strong>轮询等待</strong></li>
</ol>
<p>控制器的寄存器一般会有状态标记位，用来标识输入或输出操作是否完成。于是，我们想到第一种轮询等待的方法，让 CPU 一直查寄存器的状态，直到状态标记为完成，很明显，这种方式非常的傻瓜，它会占用 CPU 的全部时间。</p>
<ol start="2">
<li><strong>中断</strong></li>
</ol>
<p>那我们就想到第二种方法 —— 中断，通知操作系统数据已经准备好了。我们一般会有一个硬件的中断控制器，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，一个中断产生了，CPU 需要停下当前手里的事情来处理中断。</p>
<p>但中断的方式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占用 CPU 大量的时间。对于这一类设备的问题的解决方法是使用 <strong>DMA</strong>（Direct Memory Access） 功能，它可以使得设备在 CPU 不参与的情况下，能够自行完成把设备 I/O 数据放入到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的支持。</p>
<p><img src="images/DMA%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86.png" alt="img"></p>
<p>DMA 的工作方式如下：</p>
<ul>
<li>CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；</li>
<li>接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；</li>
<li>当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器；</li>
<li>DMA 控制器收到信号后，DMA 控制器发中断通知 CPU 指令完成，CPU 就可以直接用内存里面现成的数据了；</li>
</ul>
<p>可以看到， CPU 当要读取磁盘数据的时候，只需给 DMA 控制器发送指令，然后返回去做其他事情，当磁盘数据拷贝到内存后，DMA 控制机器通过中断的方式，告诉 CPU 数据已经准备好了，可以从内存读数据了。仅仅在传送开始和结束时需要 CPU 干预。</p>
<h2 id="5-3-设备驱动程序"><a href="#5-3-设备驱动程序" class="headerlink" title="5.3 设备驱动程序"></a>5.3 设备驱动程序</h2><p>虽然设备控制器屏蔽了设备的众多细节，但每种设备的控制器的寄存器、缓冲区等使用模式都是不同的，所以为了屏蔽「设备控制器」的差异，引入了<strong>设备驱动程序</strong>。</p>
<p><img src="images/%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F.png" alt="img"></p>
<p>设备控制器不属于操作系统范畴，它是属于硬件，而设备驱动程序属于操作系统的一部分，操作系统的内核代码可以像本地调用代码一样使用设备驱动程序的接口，而设备驱动程序是面向设备控制器的代码，它发出操控设备控制器的指令后，才可以操作设备控制器。</p>
<p>不同的设备控制器虽然功能不同，但是<strong>设备驱动程序会提供统一的接口给操作系统</strong>，这样不同的设备驱动程序，就可以以相同的方式接入操作系统。</p>
<p>前面提到了不少关于中断的事情，设备完成了事情，则会发送中断来通知操作系统。那操作系统就需要有一个地方来处理这个中断，这个地方也就是在设备驱动程序里，它会及时响应控制器发来的中断请求，并根据这个中断的类型调用相应的中断处理程序进行处理。</p>
<p>通常，设备驱动程序初始化的时候，要先注册一个该设备的中断处理函数。中断处理程序的处理流程：</p>
<ol>
<li>在 I/O 时，设备控制器如果已经准备好数据，则会通过中断控制器向 CPU 发送中断请求；</li>
<li>保护被中断进程的 CPU 上下文；</li>
<li>转入相应的设备中断处理函数；</li>
<li>进行中断处理；</li>
<li>恢复被中断进程的上下文；</li>
</ol>
<h2 id="5-4-通用块层"><a href="#5-4-通用块层" class="headerlink" title="5.4 通用块层"></a>5.4 通用块层</h2><p>对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的<strong>通用块层</strong>，来管理不同的块设备。</p>
<p>通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：</p>
<ol>
<li>向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；</li>
<li>通用层还会给文件系统和应用程序发来的 I/O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I/O 调度，主要目的是为了提高磁盘读写的效率。</li>
</ol>
<p>Linux 内存支持 5 种 I/O 调度算法，分别是：</p>
<ol>
<li>没有调度算法，是的，你没听错，它不对文件系统和应用程序的 I/O 做任何处理，这种算法常用在虚拟机 I/O 中，此时磁盘 I/O 调度算法交由物理机系统负责。</li>
<li>先入先出调度算法，这是最简单的 I/O 调度算法，先进入 I/O 调度队列的 I/O 请求先发生。</li>
<li>完全公平调度算法，大部分系统都把这个算法作为默认的 I/O 调度器，它为每个进程维护了一个 I/O 调度队列，并按照时间片来均匀分布每个进程的 I/O 请求。</li>
<li>优先级调度算法，顾名思义，优先级高的 I/O 请求先发生， 它适用于运行大量进程的系统，像是桌面环境、多媒体应用等。</li>
<li>最终期限调度算法，分别为读、写请求创建了不同的 I/O 队列，这样可以提高机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适用于在 I/O 压力比较大的场景，比如数据库等。</li>
</ol>
<h2 id="5-5-存储系统-I-O-软件分层"><a href="#5-5-存储系统-I-O-软件分层" class="headerlink" title="5.5 存储系统 I/O 软件分层"></a>5.5 存储系统 I/O 软件分层</h2><p>可以把 Linux 存储系统的 I/O 由上到下可以分为三个层次</p>
<ol>
<li>文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。</li>
<li>通用块层，包括块设备的 I/O 队列和 I/O 调度器，它会对文件系统的 I/O 请求进行排队，再通过 I/O 调度器，选择一个 I/O 发给下一层的设备层。</li>
<li>设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I/O 操作。</li>
</ol>
<p>他们整个的层次关系如下图：</p>
<p><img src="images/I_O%E8%BD%AF%E4%BB%B6%E5%88%86%E5%B1%82.png" alt="img"></p>
<p>有了文件系统接口之后，不但可以通过文件系统的命令行操作设备，也可以通过应用程序，调用 read、write 函数，就像读写文件一样操作设备，所以说设备在 Linux 下，也只是一个特殊的文件。</p>
<p>但是，除了读写操作，还需要有检查特定于设备的功能和属性。于是，需要 ioctl 接口，它表示输入输出控制接口，是用于配置和修改特定设备属性的通用接口。</p>
<p>另外，存储系统的 I/O 是整个系统最慢的一个环节，所以 Linux 提供了不少缓存机制来提高 I/O 的效率：</p>
<ul>
<li>为了提高文件访问的效率，会使用页缓存、索引节点缓存、目录项缓存等多种缓存机制，目的是为了减少对块设备的直接调用。</li>
<li>为了提高块设备的访问效率， 会使用缓冲区，来缓存块设备的数据。</li>
</ul>
<h1 id="6-网络系统"><a href="#6-网络系统" class="headerlink" title="6 网络系统"></a>6 网络系统</h1><h2 id="6-1-DMA-amp-零拷贝"><a href="#6-1-DMA-amp-零拷贝" class="headerlink" title="6.1 DMA &amp; 零拷贝"></a>6.1 DMA &amp; 零拷贝</h2><h3 id="DMA介绍"><a href="#DMA介绍" class="headerlink" title="DMA介绍"></a>DMA介绍</h3><p>在没有 DMA 技术前，I/O 的过程是这样的：</p>
<ol>
<li>CPU 发出对应的指令给磁盘控制器，然后返回；</li>
<li>磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断；</li>
<li>CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。</li>
</ol>
<p>![img](images/I_O 中断.png)</p>
<p>可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU 来搬运的话，肯定忙不过来。</p>
<p>计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是<strong>直接内存访问</strong>（Direct Memory Access） 技术。简单理解就是，在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。</p>
<p>![img](images/DRM I_O 过程.png)</p>
<ul>
<li>用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li>
<li>操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；</li>
<li>DMA 进一步将 I/O 请求发送给磁盘；</li>
<li>磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；</li>
<li>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务；</li>
<li>当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；</li>
<li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；</li>
</ul>
<p>可以看到， 整个数据传输的过程，CPU 不再参与数据搬运的工作，而是全程由 DMA 完成，但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。</p>
<h3 id="传统的文件传输"><a href="#传统的文件传输" class="headerlink" title="传统的文件传输"></a>传统的文件传输</h3><p>如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。</p>
<p>传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。一般会需要两个系统调用：</p>
<pre><code class="c">read(file, tmp_buf, len);
write(socket, tmp_buf, len);</code></pre>
<p>代码很简单，虽然就两行代码，但是这里面发生了不少的事：</p>
<p><img src="images/%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93.png" alt="img"></p>
<p>首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p>
<p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。</p>
<p>其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p>
<ul>
<li>第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li>
<li>第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。</li>
<li>第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。</li>
<li>第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li>
</ul>
<p>我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。这种简单又传统的文件传输方式，存在冗余的上下文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p>
<h3 id="如何优化文件传输的性能？"><a href="#如何优化文件传输的性能？" class="headerlink" title="如何优化文件传输的性能？"></a>如何优化文件传输的性能？</h3><ol>
<li>减少「用户态与内核态的上下文切换」的次数</li>
</ol>
<p>读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。</p>
<p>而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。</p>
<p>所以，要想减少上下文切换到次数，就要减少系统调用的次数。</p>
<ol start="2">
<li>减少「数据拷贝」的次数</li>
</ol>
<p>在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。</p>
<p>因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。</p>
<h3 id="零拷贝"><a href="#零拷贝" class="headerlink" title="零拷贝"></a>零拷贝</h3><p>零拷贝技术实现的方式通常有 2 种。</p>
<h4 id="mmap-write"><a href="#mmap-write" class="headerlink" title="mmap + write"></a>mmap + write</h4><p>在前面我们知道，read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。</p>
<pre><code>buf = mmap(file, len);
write(sockfd, buf, len);</code></pre>
<p>mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。</p>
<p>![mmap + write 零拷贝.png](images/mmap + write 零拷贝.png.webp)</p>
<ul>
<li>应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li>
<li>应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li>
<li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li>
</ul>
<p>因此，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。</p>
<p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p>
<h4 id="sendfile"><a href="#sendfile" class="headerlink" title="sendfile"></a>sendfile</h4><p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()，函数形式如下：</p>
<pre><code>#include &lt;sys/socket.h&gt;
ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);</code></pre>
<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p>
<p>首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p>
<p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：</p>
<p><img src="images/senfile-3%E6%AC%A1%E6%8B%B7%E8%B4%9D.png" alt="img"></p>
<p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p>
<p>从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下：</p>
<p><img src="images/senfile-%E9%9B%B6%E6%8B%B7%E8%B4%9D.png" alt="img"></p>
<ul>
<li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li>
<li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li>
</ul>
<p>这就是所谓的<strong>零拷贝</strong>（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</p>
<p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</p>
<p>所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。</p>
<p>事实上，Kafka 这个开源项目，就利用了「零拷贝」技术，从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。追溯 Kafka 文件传输的代码，你会发现，最终它调用了 Java NIO 库里的 transferTo 方法，如果 Linux 系统支持 sendfile() 系统调用，那么 transferTo() 实际上最后就会使用到 sendfile() 系统调用函数。</p>
<p>另外，Nginx 也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下：</p>
<pre><code>http &#123;
...
    sendfile on
...
&#125;</code></pre>
<p>sendfile 配置的具体意思:</p>
<ul>
<li>设置为 on 表示，使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换，和 2 次数据拷贝。</li>
<li>设置为 off 表示，使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换，和 4 次数据拷贝。</li>
</ul>
<h3 id="PageCache-有什么作用？"><a href="#PageCache-有什么作用？" class="headerlink" title="PageCache 有什么作用？"></a>PageCache 有什么作用？</h3><p>回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存也叫做页缓存 <strong>PageCache</strong>。</p>
<p>由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。</p>
<p>读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。</p>
<p>但是，内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。那问题来了，选择哪些磁盘数据拷贝到内存呢？</p>
<p>我们都知道程序运行的时候，具有「<strong>局部性</strong>」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 PageCache 来<strong>缓存最近被访问的数据</strong>，<strong>当空间不足时淘汰最久未被访问的缓存</strong>（LRU）。所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。</p>
<p>还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，PageCache 使用了「<strong>预读功能</strong>」。比如，假设 read 方法每次只会读 32 KB 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。</p>
<p>所以，PageCache 的优点主要是两个：</p>
<ul>
<li>缓存最近被访问的数据；</li>
<li>预读功能；</li>
</ul>
<p>这两个做法，将大大提高读写磁盘的性能。</p>
<p>但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能。</p>
<p>这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：</p>
<ul>
<li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li>
<li>PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；</li>
</ul>
<p>所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。</p>
<h3 id="大文件传输用什么方式实现？"><a href="#大文件传输用什么方式实现？" class="headerlink" title="大文件传输用什么方式实现？"></a>大文件传输用什么方式实现？</h3><p>我们先来看看最初的例子，当调用 read 方法读取文件时，进程实际上会阻塞在 read 方法调用，因为要等待磁盘数据的返回。对于阻塞的问题，可以用<strong>异步 I/O</strong> 来解决，它工作方式如下图：</p>
<p>![img](images/异步 IO 的过程.png)</p>
<p>它把读操作分为两部分：</p>
<ul>
<li>前半部分，内核向磁盘发起读请求，但是可以不等待数据就位就可以返回，于是进程此时可以处理其他任务；</li>
<li>后半部分，当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的通知，再去处理数据；</li>
</ul>
<p>而且，我们可以发现，异步 I/O 并没有涉及到 PageCache，所以使用异步 I/O 就意味着要绕开 PageCache。</p>
<p>绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。</p>
<p>前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。于是，在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。</p>
<p>直接 I/O 应用场景常见的两种：</p>
<ul>
<li>应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；</li>
<li>传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。</li>
</ul>
<p>另外，由于直接 I/O 绕过了 PageCache，就无法享受内核的这两点的优化：</p>
<ul>
<li>内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后「合并」成一个更大的 I/O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</li>
<li>内核也会「预读」后续的 I/O 请求放在 PageCache 中，一样是为了减少对磁盘的操作；</li>
</ul>
<p>所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：</p>
<ul>
<li>传输大文件的时候，使用「异步 I/O + 直接 I/O」；</li>
<li>传输小文件的时候，则使用「零拷贝技术」；</li>
</ul>
<p>在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：</p>
<pre><code>location /video/ &#123; 
    sendfile on; 
    aio on; 
    directio 1024m; 
&#125;</code></pre>
<p>当文件大小大于 directio 值后，使用「异步 I/O + 直接 I/O」，否则使用「零拷贝技术」。</p>
<h2 id="6-2-I-O-多路复用-amp-select-poll-epoll"><a href="#6-2-I-O-多路复用-amp-select-poll-epoll" class="headerlink" title="6.2 I/O 多路复用 &amp; select/poll/epoll"></a>6.2 I/O 多路复用 &amp; select/poll/epoll</h2><h3 id="最基本的-Socket-模型"><a href="#最基本的-Socket-模型" class="headerlink" title="最基本的 Socket 模型"></a>最基本的 Socket 模型</h3><p>要想客户端和服务器能在网络中通信，那必须得使用 Socket 编程，它是进程间通信里比较特别的方式，特别之处在于它是可以跨主机间通信。</p>
<p>Socket 的中文名叫作插口，咋一看还挺迷惑的。事实上，双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候，都通过这个“口子”。这样一看，是不是觉得很像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。</p>
<p>创建 Socket 的时候，可以指定网络层使用的是 IPv4 还是 IPv6，传输层使用的是 TCP 还是 UDP。UDP 的 Socket 编程相对简单些，这里我们只介绍基于 TCP 的 Socket 编程。</p>
<p>服务器的程序要先跑起来，然后等待客户端的连接和数据，我们先来看看服务端的 Socket 编程过程是怎样的：</p>
<ol>
<li><p>服务端首先调用 socket() 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket </p>
</li>
<li><p>接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？</p>
<ul>
<li>绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。</li>
<li>绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；</li>
</ul>
</li>
<li><p>调用 listen() 函数进行监听，此时对应 TCP 状态图中的 listen，如果我们要判定服务器中一个网络程序有没有启动，可以通过 netstat 命令查看对应的端口号是否有被监听。</p>
</li>
<li><p>服务端进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。</p>
</li>
</ol>
<p>那客户端是怎么发起连接的呢？客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。</p>
<p>在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列：</p>
<ul>
<li>一个是还没完全建立连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握手的连接，此时服务端处于 syn_rcvd 的状态；</li>
<li>一个是一件建立连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握手的连接，此时服务端处于 established 状态；</li>
</ul>
<p>当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。</p>
<p>注意，监听的 Socket 和真正用来传数据的 Socket 是两个：</p>
<ul>
<li>一个叫作监听 Socket；</li>
<li>一个叫作已连接 Socket；</li>
</ul>
<p>连接建立后，客户端和服务端就开始相互传输数据了，双方都可以通过 read() 和 write() 函数来读写数据。</p>
<p>至此， TCP 协议的 Socket 程序的调用过程就结束了，整个过程如下图：</p>
<p><img src="images/tcp_socket.png" alt="img"></p>
<p>读写 Socket 的方式，好像读写文件一样，基于 Linux 一切皆文件的理念，在内核中 Socket 也是以「文件」的形式存在的，也是有对应的文件描述符。</p>
<h3 id="如何服务更多的用户？"><a href="#如何服务更多的用户？" class="headerlink" title="如何服务更多的用户？"></a>如何服务更多的用户？</h3><p>前面提到的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I/O 时，或者读写操作发生阻塞时，其他客户端是无法与服务端连接的。</p>
<p>可如果我们服务器只能服务一个客户，那这样就太浪费资源了，于是我们要改进这个网络 I/O 模型，以支持更多的客户端。</p>
<p>在改进网络 I/O 模型前，先来提一个问题，你知道服务器单机理论最大能连接多少个客户端？</p>
<p>TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP, 本机端口, 对端IP, 对端端口。</p>
<p>服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接。因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以最大 TCP 连接数 = 客户端 IP 数×客户端端口数。对于 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数约为 2 的 48 次方。</p>
<p>这个理论值相当“丰满”，但是服务器肯定承载不了那么大的连接数，主要会受两个方面的限制：</p>
<ul>
<li>文件描述符，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目；</li>
<li>系统内存，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的；</li>
</ul>
<p>那如果服务器的内存只有 2 GB，网卡是千兆的，能支持并发 1 万请求吗？并发 1 万请求，也就是经典的 C10K 问题 ，C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。</p>
<p>从硬件资源角度看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 200KB 的内存和 100Kbit 的网络带宽就可以满足并发 1 万个请求。不过，要想真正实现 C10K 的服务器，要考虑的地方在于服务器的网络 I/O 模型，效率低的模型，会加重系统开销，从而会离 C10K 的目标越来越远。</p>
<h3 id="多进程模型"><a href="#多进程模型" class="headerlink" title="多进程模型"></a>多进程模型</h3><p>基于最原始的阻塞网络 I/O， 如果服务器要支持多个客户端，其中比较传统的方式，就是使用多进程模型，也就是为每个客户端分配一个进程来处理请求。</p>
<p>服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。</p>
<p>这两个进程刚复制完的时候，几乎一模一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。</p>
<p>正因为子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了。</p>
<p>可以发现，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。</p>
<p><img src="images/%E5%A4%9A%E8%BF%9B%E7%A8%8B.png" alt="img"></p>
<p>另外，当「子进程」退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作，就会变成僵尸进程，随着僵尸进程越多，会慢慢耗尽我们的系统资源。因此，父进程要“善后”好自己的孩子，怎么善后呢？那么有两种方式可以在子进程退出后回收资源，分别是调用 wait() 和 waitpid() 函数。</p>
<p>这种用多个进程来应付多个客户端的方式，在应对 100 个客户端还是可行的，但是当客户端数量高达一万时，肯定扛不住的，因为每产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣。进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</p>
<h3 id="多线程模型"><a href="#多线程模型" class="headerlink" title="多线程模型"></a>多线程模型</h3><p>既然进程间上下文切换的“包袱”很重，那我们就搞个比较轻量级的模型来应对多用户的请求 —— 多线程模型。</p>
<p>线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多。</p>
<p>当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。</p>
<p>如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。</p>
<p>那么，我们可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。</p>
<p><img src="images/%E7%BA%BF%E7%A8%8B%E6%B1%A0.png" alt="img"></p>
<p>需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。</p>
<p>上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程/线程，操作系统就算死扛也是扛不住的。</p>
<h3 id="I-O-多路复用"><a href="#I-O-多路复用" class="headerlink" title="I/O 多路复用"></a>I/O 多路复用</h3><p>既然为每个请求分配一个进程/线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 I/O 多路复用技术。</p>
<p>一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。</p>
<p>我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。</p>
<p>select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。</p>
<h3 id="select-poll"><a href="#select-poll" class="headerlink" title="select/poll"></a>select/poll</h3><p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。</p>
<p>所以，对于 select 这种方式，需要进行 <strong>2 次「遍历」文件描述符集合</strong>，一次是在内核态里，一个次是在用户态里 ，而且还会发生 <strong>2 次「拷贝」文件描述符集合</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p>
<p>select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。</p>
<p>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。</p>
<p>但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此<strong>都需要遍历文件描述符集合来找到可读或可写的 Socket</strong>，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p>
<h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><p>epoll 通过两个方面，很好解决了 select/poll 的问题：</p>
<ol>
<li>epoll 在内核里<strong>使用红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select/poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</li>
<li>epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。</li>
</ol>
<p><img src="images/epoll.png" alt="img"></p>
<p>epoll 的方式即使监听的 Socket 数量越多的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了，上限就为系统定义的进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。</p>
<h4 id="边缘触发和水平触发"><a href="#边缘触发和水平触发" class="headerlink" title="边缘触发和水平触发"></a>边缘触发和水平触发</h4><p>epoll 支持两种事件触发模式，分别是<strong>边缘触发</strong>（edge-triggered，ET）和<strong>水平触发</strong>（level-triggered，LT）。</p>
<ul>
<li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li>
<li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；</li>
</ul>
<p>举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是水平触发的方式。这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了。</p>
<h2 id="6-3-高性能网络模式：Reactor-和-Proactor"><a href="#6-3-高性能网络模式：Reactor-和-Proactor" class="headerlink" title="6.3 高性能网络模式：Reactor 和 Proactor"></a>6.3 高性能网络模式：Reactor 和 Proactor</h2><h3 id="演进"><a href="#演进" class="headerlink" title="演进"></a>演进</h3><p>如果要让服务器服务多个客户端，那么最直接的方式就是为每一条连接创建线程。其实创建进程也是可以的，原理是一样的，进程和线程的区别在于线程比较轻量级些，线程的创建和线程间切换的成本要小些，为了描述简述，后面都以线程为例。</p>
<p>处理完业务逻辑后，随着连接关闭后线程也同样要销毁了，但是这样不停地创建和销毁线程，不仅会带来性能开销，也会造成浪费资源，而且如果要连接几万条连接，创建几万个线程去应对也是不现实的。要这么解决这个问题呢？我们可以使用「资源复用」的方式，也就是不用再为每个连接创建线程，而是创建一个「线程池」，将连接分配给线程，然后一个线程可以处理多个连接的业务。</p>
<p>不过，这样又引来一个新的问题，线程怎样才能高效地处理多个连接的业务？</p>
<p>当一个连接对应一个线程时，线程一般采用「read -&gt; 业务处理 -&gt; send」的处理流程，如果当前连接没有数据可读，那么线程会阻塞在 read 操作上（ socket 默认情况是阻塞 I/O），不过这种阻塞方式并不影响其他线程。</p>
<p>但是引入了线程池，那么一个线程要处理多个连接的业务，线程在处理某个连接的 read 操作时，如果遇到没有数据可读，就会发生阻塞，那么线程就没办法继续处理其他连接的业务。</p>
<p>要解决这一个问题，最简单的方式就是将 socket 改成非阻塞，然后线程不断地轮询调用 read 操作来判断是否有数据，这种方式虽然该能够解决阻塞的问题，但是解决的方式比较粗暴，因为轮询是要消耗 CPU 的，而且随着一个线程处理的连接越多，轮询的效率就会越低。</p>
<p>上面的问题在于，线程并不知道当前连接是否有数据可读，从而需要每次通过 read 去试探。</p>
<p>那有没有办法在只有当连接上有数据的时候，线程才去发起读请求呢？答案是有的，实现这一技术的就是 I/O 多路复用。</p>
<p>I/O 多路复用技术会用一个系统调用函数来监听我们所有关心的连接，也就说可以在一个监控线程里面监控很多的连接。</p>
<p>我们熟悉的 select/poll/epoll 就是内核提供给用户态的多路复用系统调用，线程可以通过一个系统调用函数从内核中获取多个事件。</p>
<p>select/poll/epoll 是如何获取网络事件的呢？在获取事件时，先把我们要关心的连接传给内核，再由内核检测：</p>
<ul>
<li>如果没有事件发生，线程只需阻塞在这个系统调用，而无需像前面的线程池方案那样轮训调用 read 操作来判断是否有数据。</li>
<li>如果有事件发生，内核会返回产生了事件的连接，线程就会从阻塞状态返回，然后在用户态中再处理这些连接对应的业务即可。</li>
</ul>
<h3 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h3><p>当下开源软件能做到网络高性能的原因就是 I/O 多路复用吗？是的，基本是基于 I/O 多路复用，用过 I/O 多路复用接口写网络程序的同学，肯定知道是面向过程的方式写代码的，这样的开发的效率不高。</p>
<p>于是，大佬们基于面向对象的思想，对 I/O 多路复用作了一层封装，让使用者不用考虑底层网络 API 的细节，只需要关注应用代码的编写。大佬们还为这种模式取了个让人第一时间难以理解的名字：<strong>Reactor 模式</strong>。</p>
<p>这里的反应指的是「对事件反应」，也就是来了一个事件，Reactor 就有相对应的反应/响应。事实上，Reactor 模式也叫 <strong>Dispatcher 模式</strong>，我觉得这个名字更贴合该模式的含义，即 I/O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程。</p>
<p>Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p>
<ul>
<li><strong>Reactor</strong>：负责监听和分发事件，事件类型包含连接事件、读写事件；</li>
<li><strong>处理资源池</strong>：负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</li>
</ul>
<p>Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：</p>
<ul>
<li>Reactor 的数量可以只有一个，也可以有多个；</li>
<li>处理资源池可以是单个进程 / 线程，也可以是多个进程 /线程；</li>
</ul>
<p>将上面的两个因素排列组设一下，理论上就可以有 4 种方案选择：</p>
<ul>
<li>单 Reactor 单进程 / 线程；</li>
<li>单 Reactor 多进程 / 线程；</li>
<li>多 Reactor 单进程 / 线程；</li>
<li>多 Reactor 多进程 / 线程；</li>
</ul>
<p>其中，「多 Reactor 单进程 / 线程」实现方案相比「单 Reactor 单进程 / 线程」方案，不仅复杂而且也没有性能优势，因此实际中并没有应用。剩下的 3 个方案都是比较经典的，且都有应用在实际的项目中。方案具体使用进程还是线程，要看使用的编程语言以及平台有关：</p>
<ul>
<li>Java 语言一般使用线程，比如 Netty;</li>
<li>C 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。</li>
</ul>
<h4 id="单-Reactor-单进程-线程"><a href="#单-Reactor-单进程-线程" class="headerlink" title="单 Reactor 单进程 / 线程"></a>单 Reactor 单进程 / 线程</h4><p>一般来说，C 语言实现的是「单 Reactor 单进程」的方案，因为 C 语编写完的程序，运行后就是一个独立的进程，不需要在进程中再创建线程。</p>
<p>而 Java 语言实现的是「单 Reactor 单线程」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，我们写的 Java 程序只是其中的一个线程而已。</p>
<p>「单 Reactor 单进程」的方案示意图：</p>
<p><img src="images/%E5%8D%95Reactor%E5%8D%95%E8%BF%9B%E7%A8%8B.png" alt="img"></p>
<p>可以看到进程里有 Reactor、Acceptor、Handler 这三个对象：</p>
<ul>
<li><strong>Reactor</strong> 对象的作用是监听和分发事件；</li>
<li><strong>Acceptor</strong> 对象的作用是获取连接；</li>
<li><strong>Handler</strong> 对象的作用是处理业务；</li>
</ul>
<p>对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。</p>
<p>接下来，介绍下「单 Reactor 单进程」这个方案：</p>
<ul>
<li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>
<li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li>
<li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li>
<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>
</ul>
<p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。</p>
<p>但是，这种方案存在 2 个缺点：</p>
<ol>
<li>因为只有一个进程，无法充分利用 多核 CPU 的性能；</li>
<li>Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；</li>
</ol>
<p>所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。</p>
<p>Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p>
<h4 id="单-Reactor-多线程-多进程"><a href="#单-Reactor-多线程-多进程" class="headerlink" title="单 Reactor 多线程 / 多进程"></a>单 Reactor 多线程 / 多进程</h4><p>如果要克服「单 Reactor 单线程 / 进程」方案的缺点，那么就需要引入多线程 / 多进程，这样就产生了单 Reactor 多线程 / 多进程的方案。</p>
<p><img src="images/%E5%8D%95Reactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="img"></p>
<ul>
<li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>
<li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li>
<li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li>
</ul>
<p>上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：</p>
<ul>
<li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；</li>
<li>子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；</li>
</ul>
<p>单 Reator 多线程的方案优势在于能够充分利用多核 CPU 的能，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。</p>
<p>例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。</p>
<p>要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。</p>
<p>聊完单 Reactor 多线程的方案，接着来看看单 Reactor 多进程的方案。事实上，单 Reactor 多进程相比单 Reactor 多线程实现起来很麻烦，主要因为要考虑子进程 &lt;-&gt; 父进程的双向通信，并且父进程还得知道子进程要将数据发送给哪个客户端。</p>
<p>而多线程间可以共享数据，虽然要额外考虑并发问题，但是这远比进程间通信的复杂度低得多，因此实际应用中也看不到单 Reactor 多进程的模式。</p>
<p>另外，「单 Reactor」的模式还有个问题，因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。</p>
<h4 id="多-Reactor-多进程-线程"><a href="#多-Reactor-多进程-线程" class="headerlink" title="多 Reactor 多进程 / 线程"></a>多 Reactor 多进程 / 线程</h4><p>要解决「单 Reactor」的问题，就是将「单 Reactor」实现成「多 Reactor」，这样就产生了第 多 Reactor 多进程 / 线程的方案。</p>
<p><img src="images/%E4%B8%BB%E4%BB%8EReactor%E5%A4%9A%E7%BA%BF%E7%A8%8B.png" alt="img"></p>
<ul>
<li>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</li>
<li>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。</li>
<li>如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。</li>
<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>
</ul>
<p>多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：</p>
<ul>
<li>主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。</li>
<li>主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。</li>
</ul>
<p>大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。</p>
<p>采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。</p>
<h3 id="Proactor"><a href="#Proactor" class="headerlink" title="Proactor"></a>Proactor</h3><p>前面提到的 Reactor 是非阻塞同步网络模式，而 <strong>Proactor</strong> 是<strong>异步网络模式</strong>。</p>
<p>无论是同步阻塞I/O还是同步非阻塞I/O，最后一次 read 调用，获取数据的过程都是一个同步的过程，是需要等待的过程，这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</p>
<p>而真正的异步 I/O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。</p>
<p>当我们发起 aio_read （异步 I/O） 之后，就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，应用程序并不需要主动发起拷贝动作。</p>
<p>Proactor 正是采用了异步 I/O 技术，所以被称为异步网络模型。Reactor 和 Proactor 的区别主要是：</p>
<ul>
<li>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。</li>
<li>Proactor 是异步网络模式， 感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read/write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。</li>
</ul>
<p>因此，Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I/O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。</p>
<p>举个实际生活中的例子，Reactor 模式就是快递员在楼下，给你打电话告诉你快递到你家小区了，你需要自己下楼来拿快递。而在 Proactor 模式下，快递员直接将快递送到你家门口，然后通知你。</p>
<p>无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I/O 事件，而 Proactor 模式则是基于「已完成」的 I/O 事件。</p>
<p>Proactor 模式的示意图：</p>
<p><img src="images/Proactor.png" alt="img"></p>
<ul>
<li>Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；</li>
<li>Asynchronous Operation Processor 负责处理注册请求，并处理 I/O 操作；</li>
<li>Asynchronous Operation Processor 完成 I/O 操作后通知 Proactor；</li>
<li>Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；</li>
<li>Handler 完成业务处理；</li>
</ul>
<p>可惜的是，在 Linux 下的异步 I/O 是不完善的， aio 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。</p>
<p>而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 IOCP，是由操作系统级别实现的异步 I/O，真正意义上异步 I/O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。</p>
<h2 id="6-4-一致性哈希"><a href="#6-4-一致性哈希" class="headerlink" title="6.4 一致性哈希"></a>6.4 一致性哈希</h2><h3 id="如何分配请求？"><a href="#如何分配请求？" class="headerlink" title="如何分配请求？"></a>如何分配请求？</h3><p>大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。但是问题来了，现在有那么多个节点（后面统称服务器为节点，因为少一个字），要如何分配客户端的请求呢？</p>
<p>其实这个问题就是「<strong>负载均衡问题</strong>」。解决负载均衡问题的算法很多，不同的负载均衡算法，对应的就是不同的分配策略，适应的业务场景也不同。</p>
<p>最简单的方式，引入一个中间的负载均衡层，让它将外界的请求「轮流」的转发给内部的集群。比如集群有 3 个节点，外界请求有 3 个，那么每个节点都会处理 1 个请求，达到了分配请求的目的。</p>
<p><img src="images/d3279ad754257977f98e702cb156e9cf.png" alt="img"></p>
<p>考虑到每个节点的硬件配置有所区别，我们可以引入权重值，将硬件配置更好的节点的权重值设高，然后根据各个节点的权重值，按照一定比重分配在不同的节点上，让硬件配置更好的节点承担更多的请求，这种算法叫做加权轮询。</p>
<p>加权轮询算法使用场景是建立在每个节点存储的数据都是相同的前提。所以，每次读数据的请求，访问任意一个节点都能得到结果。</p>
<p>但是，加权轮询算法是无法应对「分布式系统（数据分片的系统）」的，因为分布式系统中，每个节点存储的数据是不同的。</p>
<p>当我们想提高系统的容量，就会将数据水平切分到不同的节点来存储，也就是将数据分布到了不同的节点。比如一个分布式 KV（key-valu） 缓存系统，某个 key 应该到哪个或者哪些节点上获得，应该是确定的，不是说任意访问一个节点都可以得到缓存结果的。</p>
<p>因此，我们要想一个能应对分布式系统的负载均衡算法。</p>
<h3 id="使用哈希算法有什么问题？"><a href="#使用哈希算法有什么问题？" class="headerlink" title="使用哈希算法有什么问题？"></a>使用哈希算法有什么问题？</h3><p>有的同学可能很快就想到了：哈希算法。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。</p>
<p>哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。如果客户端要获取指定 key 的数据，通过该公式可以定位节点。</p>
<p>比如经过上面这个公式计算后得到的值是 0，就说明该 key 需要去第一个节点获取。</p>
<p>但是有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。</p>
<p>举个例子，假设我们有一个由 A、B、C 三个节点组成分布式 KV 缓存系统，基于计算公式 hash(key) % 3 将数据进行了映射，每个节点存储了不同的数据：</p>
<p><img src="images/025ddcaabece1f4b5823dfb1fb7340ef.png" alt="img"></p>
<p>现在有 3 个查询 key 的请求，分别查询 key-01，key-02，key-03 的数据，这三个 key 分别经过 hash() 函数计算后的值为 hash( key-01) = 6、hash( key-02) = 7、hash(key-03) = 8，然后再对这些值进行取模运算。通过这样的哈希算法，每个 key 都可以定位到对应的节点。</p>
<p><img src="images/ed14c96417e08b4f916e0cd23d12b7bd.png" alt="img"></p>
<p>当 3 个节点不能满足业务需求了，这时我们增加了一个节点，节点的数量从 3 变化为 4，意味取模哈希函数中基数的变化，这样会导致大部分映射关系改变，如下图：</p>
<p><img src="images/392c54cfb9ec47f5191008aa1d27d6b5.png" alt="img"></p>
<p>比如，之前的 hash(key-01) % 3 = 0，就变成了 hash(key-01) % 4 = 2，查询 key-01 数据时，寻址到了节点 C，而 key-01 的数据是存储在节点 A 上的，不是在节点 C，所以会查询不到数据。</p>
<p>同样的道理，如果我们对分布式系统进行缩容，比如移除一个节点，也会因为取模哈希函数中基数的变化，可能出现查询不到数据的问题。要解决这个问题的办法，就需要我们进行迁移数据，比如节点的数量从 3 变化为 4 时，要基于新的计算公式 hash(key) % 4 ，重新对数据和节点做映射。假设总数据条数为 M，哈希算法在面对节点数量变化时，最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)，这样数据的迁移成本太高了。</p>
<p>所以，我们应该要重新想一个新的算法，来避免分布式系统在扩容或者缩容时，发生过多的数据迁移。</p>
<h3 id="使用一致性哈希算法有什么问题？"><a href="#使用一致性哈希算法有什么问题？" class="headerlink" title="使用一致性哈希算法有什么问题？"></a>使用一致性哈希算法有什么问题？</h3><p>一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。</p>
<p>一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。</p>
<p>我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为哈希环，如下图：</p>
<p><img src="images/0ea3960fef48d4cbaeb4bec4345301e7.png" alt="img"></p>
<p>一致性哈希要进行两步哈希：</p>
<ul>
<li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li>
<li>第二步：当对数据进行存储或访问时，对数据进行哈希映射；</li>
</ul>
<p>所以，一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。</p>
<p>问题来了，对「数据」进行哈希映射得到一个结果，要怎么找到存储该数据的节点呢？</p>
<p>答案是，映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。</p>
<p>举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置：</p>
<p><img src="images/83d7f363643353c92d252e34f1d4f687.png" alt="img"></p>
<p>接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。</p>
<p>比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。</p>
<p><img src="images/30c2c70721c12f9c140358fbdc5f2282.png" alt="img"></p>
<p>所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：</p>
<ul>
<li>首先，对 key 进行哈希计算，确定此 key 在环上的位置；</li>
<li>然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。</li>
</ul>
<p>知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？</p>
<p>假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置：</p>
<p><img src="images/f8909edef2f3949f8945bb99380baab3.png" alt="img"></p>
<p>你可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。</p>
<p>假设节点数量从 3 减少到了 2，比如将节点 A 移除：</p>
<p><img src="images/31485046f1303b57d8aaeaab103ea7ab.png" alt="img"></p>
<p>你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。</p>
<p>因此，在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。</p>
<p>上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。</p>
<p>比如，下图中 3 个节点的映射位置都在哈希环的右半边：</p>
<p><img src="images/d528bae6fcec2357ba2eb8f324ad9fd5.png" alt="img"></p>
<p>这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这肯定不行的呀，说好的负载均衡呢，这种情况一点都不均衡。</p>
<p>另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。</p>
<p>比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。</p>
<p>所以，一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题。</p>
<h3 id="如何通过虚拟节点提高均衡度？"><a href="#如何通过虚拟节点提高均衡度？" class="headerlink" title="如何通过虚拟节点提高均衡度？"></a>如何通过虚拟节点提高均衡度？</h3><p>要想解决节点能在哈希环上分配不均匀的问题，就是要有大量的节点，节点数越多，哈希环上的节点分布的就越均匀。</p>
<p>但问题是，实际中我们没有那么多节点。所以这个时候我们就加入<strong>虚拟节点</strong>，也就是对一个真实节点做多个副本。</p>
<p>具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。</p>
<p>比如对每个节点分别设置 3 个虚拟节点：</p>
<ul>
<li>对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03</li>
<li>对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03</li>
<li>对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03</li>
</ul>
<p>引入虚拟节点后，原本哈希环上只有 3 个节点的情况，就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍：</p>
<p><img src="images/dbb57b8d6071d011d05eeadd93269e13.png" alt="img"></p>
<p>你可以看到，节点数量多了后，节点在哈希环上的分布就相对均匀了。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。</p>
<p>上面为了方便你理解，每个真实节点仅包含 3 个虚拟节点，这样能起到的均衡效果其实很有限。而在实际的工程中，虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。</p>
<p>另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高。</p>
<p>比如，当某个节点被移除时，对应该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了节点变化导致的压力。</p>
<p>而且，有了虚拟节点后，还可以为硬件配置更好的节点增加权重，比如对权重更高的节点增加更多的虚拟机节点即可。</p>
<p>因此，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。</p>
<hr>
<blockquote>
<p>Reference：<a target="_blank" rel="noopener" href="https://xiaolincoding.com/network/#%E9%80%82%E5%90%88%E4%BB%80%E4%B9%88%E7%BE%A4%E4%BD%93">小林coding图解网络</a></p>
</blockquote>

            <div class="post-copyright">
    <div class="content">
        <p>最后更新： 2023年01月01日 18:42</p>
        <p>原始链接： <a class="post-url" href="/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/" title="图解系统">http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/</a></p>
        <footer>
            <a href="http://muquanrui.com">
                <img src="/images/logo.png" alt="MU Quanrui">
                MU Quanrui
            </a>
        </footer>
    </div>
</div>

      
        
            
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;">赏</a>
</div>

<div id="reward" class="post-modal reward-lay">
    <a class="close" href="javascript:;" id="reward-close">×</a>
    <span class="reward-title">
        <i class="icon icon-quote-left"></i>
        请我吃糖~
        <i class="icon icon-quote-right"></i>
    </span>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/images/wechat_code.jpg" alt="打赏二维码">
        </div>
        <div class="reward-select">
            
            <label class="reward-select-item checked" data-id="wechat" data-wechat="/images/wechat_code.jpg">
                <img class="reward-select-item-wechat" src="/images/wechat.png" alt="微信">
            </label>
            
            
            <label class="reward-select-item" data-id="alipay" data-alipay="/images/alipay_code.jpg">
                <img class="reward-select-item-alipay" src="/images/alipay.png" alt="支付宝">
            </label>
            
        </div>
    </div>
</div>


        
    </div>
    <footer class="article-footer">
        
        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/&title=《图解系统》 — Quanrui's Blog&pic=cover.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/&title=《图解系统》 — Quanrui's Blog&source=Carpe diem." data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《图解系统》 — Quanrui's Blog&url=http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/&via=http://muquanrui.com" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://muquanrui.com/2022/10/17/Computer%20Science/Operating%20System/%E5%9B%BE%E8%A7%A3%E7%B3%BB%E7%BB%9F/" alt="微信分享二维码">
</div>

<div class="mask"></div>

        
        <ul class="article-footer-menu">
            
            
  <li class="article-footer-tags">
    <i class="fa fa-tags"></i>
      
    <a href="/tags/Computer-Science/" class="color2">Computer Science</a>
      
    <a href="/tags/Operating-System/" class="color2">Operating System</a>
      
  </li>

        </ul>
        
    </footer>
  </div>
</article>


    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
        <div class= "post-toc-name">Table of Contents</div>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#1-%E7%A1%AC%E4%BB%B6%E7%BB%93%E6%9E%84"><span class="post-toc-text">1 硬件结构</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-1-%E5%86%AF%E8%AF%BA%E4%BE%9D%E6%9B%BC%E6%A8%A1%E5%9E%8B"><span class="post-toc-text">1.1 冯诺依曼模型</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%85%E5%AD%98"><span class="post-toc-text">内存</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8"><span class="post-toc-text">中央处理器</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%80%BB%E7%BA%BF"><span class="post-toc-text">总线</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BE%93%E5%85%A5%E3%80%81%E8%BE%93%E5%87%BA%E8%AE%BE%E5%A4%87"><span class="post-toc-text">输入、输出设备</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-2-%E7%BA%BF%E8%B7%AF%E4%BD%8D%E5%AE%BD%E4%B8%8E-CPU-%E4%BD%8D%E5%AE%BD"><span class="post-toc-text">1.2 线路位宽与 CPU 位宽</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-3-%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%BF%87%E7%A8%8B"><span class="post-toc-text">1.3 程序执行的基本过程</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#a-1-2-%E6%89%A7%E8%A1%8C%E5%85%B7%E4%BD%93%E8%BF%87%E7%A8%8B"><span class="post-toc-text">a &#x3D; 1 + 2 执行具体过程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%8C%87%E4%BB%A4"><span class="post-toc-text">指令</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-4-%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="post-toc-text">1.4 存储器的层次结构</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%AF%84%E5%AD%98%E5%99%A8"><span class="post-toc-text">寄存器</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#CPU-Cache"><span class="post-toc-text">CPU Cache</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#L1-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98"><span class="post-toc-text">L1 高速缓存</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#L2-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98"><span class="post-toc-text">L2 高速缓存</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#L3-%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98"><span class="post-toc-text">L3 高速缓存</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%85%E5%AD%98-1"><span class="post-toc-text">内存</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#SSD-HDD-%E7%A1%AC%E7%9B%98"><span class="post-toc-text">SSD&#x2F;HDD 硬盘</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%AD%98%E5%82%A8%E5%99%A8%E7%9A%84%E5%B1%82%E6%AC%A1%E5%85%B3%E7%B3%BB"><span class="post-toc-text">存储器的层次关系</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-5-CPU-%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7"><span class="post-toc-text">1.5 CPU 缓存一致性</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%99%E7%9B%B4%E8%BE%BE"><span class="post-toc-text">写直达</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%99%E5%9B%9E"><span class="post-toc-text">写回</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BC%93%E5%AD%98%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98"><span class="post-toc-text">缓存一致性问题</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%80%BB%E7%BA%BF%E5%97%85%E6%8E%A2"><span class="post-toc-text">总线嗅探</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#MESI-%E5%8D%8F%E8%AE%AE"><span class="post-toc-text">MESI 协议</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#1-6-%E6%95%B0%E5%AD%97%E5%9C%A8%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E8%A1%A8%E7%A4%BA"><span class="post-toc-text">1.6 数字在计算机中的表示</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%B4%9F%E6%95%B0%E8%A6%81%E7%94%A8%E8%A1%A5%E7%A0%81%E8%A1%A8%E7%A4%BA%EF%BC%9F"><span class="post-toc-text">为什么负数要用补码表示？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%8D%81%E8%BF%9B%E5%88%B6%E5%B0%8F%E6%95%B0%E4%B8%8E%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="post-toc-text">十进制小数与二进制的转换</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%98%AF%E6%80%8E%E4%B9%88%E5%AD%98%E5%B0%8F%E6%95%B0%E7%9A%84%EF%BC%9F"><span class="post-toc-text">计算机是怎么存小数的？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#0-1-0-2-0-3"><span class="post-toc-text">0.1 + 0.2 &#x3D;&#x3D; 0.3 ?</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#2-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="post-toc-text">2 内存管理</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-1-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98"><span class="post-toc-text">2.1 虚拟内存</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-2-%E5%86%85%E5%AD%98%E5%88%86%E6%AE%B5"><span class="post-toc-text">2.2 内存分段</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%88%86%E6%AE%B5%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D"><span class="post-toc-text">分段机制介绍</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%85%E5%AD%98%E7%A2%8E%E7%89%87%E7%9A%84%E9%97%AE%E9%A2%98"><span class="post-toc-text">内存碎片的问题</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%86%85%E5%AD%98%E4%BA%A4%E6%8D%A2%E7%9A%84%E6%95%88%E7%8E%87%E4%BD%8E%E7%9A%84%E9%97%AE%E9%A2%98"><span class="post-toc-text">内存交换的效率低的问题</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-3-%E5%86%85%E5%AD%98%E5%88%86%E9%A1%B5"><span class="post-toc-text">2.3 内存分页</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%88%86%E9%A1%B5%E6%9C%BA%E5%88%B6%E4%BB%8B%E7%BB%8D"><span class="post-toc-text">分页机制介绍</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%88%86%E9%A1%B5%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E5%88%86%E6%AE%B5%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="post-toc-text">分页如何解决分段的问题？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%99%9A%E6%8B%9F%E5%9C%B0%E5%9D%80%E5%92%8C%E7%89%A9%E7%90%86%E5%9C%B0%E5%9D%80%E7%9A%84%E6%98%A0%E5%B0%84"><span class="post-toc-text">虚拟地址和物理地址的映射</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A4%9A%E7%BA%A7%E9%A1%B5%E8%A1%A8"><span class="post-toc-text">多级页表</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#TLB"><span class="post-toc-text">TLB</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-4-%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95"><span class="post-toc-text">2.4 页面置换算法</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD"><span class="post-toc-text">缺页中断</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="post-toc-text">页面置换的作用</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%9C%80%E4%BD%B3%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%EF%BC%88OPT%EF%BC%89"><span class="post-toc-text">最佳页面置换算法（OPT）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%85%88%E8%BF%9B%E5%85%88%E5%87%BA%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%EF%BC%88FIFO%EF%BC%89"><span class="post-toc-text">先进先出置换算法（FIFO）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%9C%80%E8%BF%91%E6%9C%80%E4%B9%85%E6%9C%AA%E4%BD%BF%E7%94%A8%E7%9A%84%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%EF%BC%88LRU%EF%BC%89"><span class="post-toc-text">最近最久未使用的置换算法（LRU）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%97%B6%E9%92%9F%E9%A1%B5%E9%9D%A2%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%EF%BC%88Lock%EF%BC%89"><span class="post-toc-text">时钟页面置换算法（Lock）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%9C%80%E4%B8%8D%E5%B8%B8%E7%94%A8%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95%EF%BC%88LFU%EF%BC%89"><span class="post-toc-text">最不常用置换算法（LFU）</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-5-%E6%AE%B5%E9%A1%B5%E5%BC%8F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="post-toc-text">2.5 段页式内存管理</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-6-Linux-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="post-toc-text">2.6 Linux 内存管理</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Linux-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%96%B9%E5%BC%8F"><span class="post-toc-text">Linux 内存管理方式</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9ALinux-%E5%86%85%E5%AD%98%E6%BB%A1%E4%BA%86%EF%BC%8C%E4%BC%9A%E5%8F%91%E7%94%9F%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="post-toc-text">面试题：Linux 内存满了，会发生什么？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%9A%E5%9C%A8-4GB-%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%9A%84%E6%9C%BA%E5%99%A8%E4%B8%8A%EF%BC%8C%E7%94%B3%E8%AF%B7-8G-%E5%86%85%E5%AD%98%E4%BC%9A%E6%80%8E%E4%B9%88%E6%A0%B7%EF%BC%9F"><span class="post-toc-text">面试题：在 4GB 物理内存的机器上，申请 8G 内存会怎么样？</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#2-7-%E6%80%BB%E7%BB%93"><span class="post-toc-text">2.7 总结</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#3-%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86"><span class="post-toc-text">3 进程管理</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-1-%E8%BF%9B%E7%A8%8B"><span class="post-toc-text">3.1 进程</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%9B%E7%A8%8B"><span class="post-toc-text">进程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%B9%B6%E8%A1%8C-amp-%E5%B9%B6%E5%8F%91"><span class="post-toc-text">并行 &amp; 并发</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81"><span class="post-toc-text">进程的状态</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%9B%E7%A8%8B%E6%8E%A7%E5%88%B6%E5%9D%97"><span class="post-toc-text">进程控制块</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"><span class="post-toc-text">进程的上下文切换</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#CPU-%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"><span class="post-toc-text">CPU 上下文切换</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E5%88%B0%E5%BA%95%E6%98%AF%E5%88%87%E6%8D%A2%E4%BB%80%E4%B9%88%E5%91%A2%EF%BC%9F"><span class="post-toc-text">进程的上下文切换到底是切换什么呢？</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%8F%91%E7%94%9F%E8%BF%9B%E7%A8%8B%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E6%9C%89%E5%93%AA%E4%BA%9B%E5%9C%BA%E6%99%AF%EF%BC%9F"><span class="post-toc-text">发生进程上下文切换有哪些场景？</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-2-%E7%BA%BF%E7%A8%8B"><span class="post-toc-text">3.2 线程</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E7%BA%BF%E7%A8%8B%EF%BC%9F"><span class="post-toc-text">为什么使用线程？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BA%BF%E7%A8%8B"><span class="post-toc-text">线程</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%AF%94%E8%BE%83"><span class="post-toc-text">线程与进程的比较</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2"><span class="post-toc-text">线程的上下文切换</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="post-toc-text">线程的实现</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B"><span class="post-toc-text">用户线程</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B"><span class="post-toc-text">内核线程</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E8%BD%BB%E9%87%8F%E7%BA%A7%E8%BF%9B%E7%A8%8B"><span class="post-toc-text">轻量级进程</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-3-%E8%BF%9B%E7%A8%8B%E8%B0%83%E5%BA%A6"><span class="post-toc-text">3.3 进程调度</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%B0%83%E5%BA%A6%E6%97%B6%E6%9C%BA"><span class="post-toc-text">调度时机</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%B0%83%E5%BA%A6%E5%8E%9F%E5%88%99"><span class="post-toc-text">调度原则</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">调度算法</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">先来先服务调度算法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">最短作业优先调度算法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E9%AB%98%E5%93%8D%E5%BA%94%E6%AF%94%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">高响应比优先调度算法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">时间片轮转调度算法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E6%9C%80%E9%AB%98%E4%BC%98%E5%85%88%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">最高优先级调度算法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">多级反馈队列调度算法</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-4-%E8%BF%9B%E7%A8%8B%E9%80%9A%E4%BF%A1"><span class="post-toc-text">3.4 进程通信</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%8C%BF%E5%90%8D%E7%AE%A1%E9%81%93"><span class="post-toc-text">匿名管道</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%91%BD%E5%90%8D%E7%AE%A1%E9%81%93"><span class="post-toc-text">命名管道</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="post-toc-text">消息队列</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="post-toc-text">共享内存</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F"><span class="post-toc-text">信号量</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BF%A1%E5%8F%B7"><span class="post-toc-text">信号</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Socket"><span class="post-toc-text">Socket</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-5-%E4%BA%92%E6%96%A5-amp-%E5%90%8C%E6%AD%A5"><span class="post-toc-text">3.5 互斥 &amp; 同步</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BA%92%E6%96%A5"><span class="post-toc-text">互斥</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%90%8C%E6%AD%A5"><span class="post-toc-text">同步</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%94%81-amp-%E4%BF%A1%E5%8F%B7%E9%87%8F"><span class="post-toc-text">锁 &amp; 信号量</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E9%94%81"><span class="post-toc-text">锁</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E4%BF%A1%E5%8F%B7%E9%87%8F-1"><span class="post-toc-text">信号量</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98"><span class="post-toc-text">常见问题</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#3-6-%E6%AD%BB%E9%94%81"><span class="post-toc-text">3.6 死锁</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BA%92%E6%96%A5%E6%9D%A1%E4%BB%B6"><span class="post-toc-text">互斥条件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%AF%B7%E6%B1%82%E4%BF%9D%E6%8C%81%E6%9D%A1%E4%BB%B6"><span class="post-toc-text">请求保持条件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%B8%8D%E5%89%A5%E5%A4%BA%E6%9D%A1%E4%BB%B6"><span class="post-toc-text">不剥夺条件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%BE%AA%E7%8E%AF%E7%AD%89%E5%BE%85%E6%9D%A1%E4%BB%B6"><span class="post-toc-text">循环等待条件</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E7%9A%84%E5%8F%91%E7%94%9F"><span class="post-toc-text">避免死锁问题的发生</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#4-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="post-toc-text">4 文件系统</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-1-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90"><span class="post-toc-text">4.1 文件系统的基本组成</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%B4%A2%E5%BC%95%E8%8A%82%E7%82%B9-amp-%E7%9B%AE%E5%BD%95%E9%A1%B9"><span class="post-toc-text">索引节点 &amp; 目录项</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%9B%AE%E5%BD%95"><span class="post-toc-text">目录</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%96%87%E4%BB%B6%E6%95%B0%E6%8D%AE%E6%98%AF%E5%A6%82%E4%BD%95%E5%AD%98%E5%82%A8%E5%9C%A8%E7%A3%81%E7%9B%98%EF%BC%9F"><span class="post-toc-text">文件数据是如何存储在磁盘？</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-2-%E8%99%9A%E6%8B%9F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F"><span class="post-toc-text">4.2 虚拟文件系统</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-3-%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="post-toc-text">4.3 文件的使用</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-4-%E6%96%87%E4%BB%B6%E7%9A%84%E5%AD%98%E5%82%A8"><span class="post-toc-text">4.4 文件的存储</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F"><span class="post-toc-text">连续空间存放方式</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%9D%9E%E8%BF%9E%E7%BB%AD%E7%A9%BA%E9%97%B4%E5%AD%98%E6%94%BE%E6%96%B9%E5%BC%8F"><span class="post-toc-text">非连续空间存放方式</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E9%93%BE%E8%A1%A8%E6%96%B9%E5%BC%8F"><span class="post-toc-text">链表方式</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E7%B4%A2%E5%BC%95%E6%96%B9%E5%BC%8F"><span class="post-toc-text">索引方式</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-5-%E7%A9%BA%E9%97%B2%E7%A9%BA%E9%97%B4%E7%AE%A1%E7%90%86"><span class="post-toc-text">4.5 空闲空间管理</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%A9%BA%E9%97%B2%E8%A1%A8%E6%B3%95"><span class="post-toc-text">空闲表法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%A9%BA%E9%97%B2%E9%93%BE%E8%A1%A8%E6%B3%95"><span class="post-toc-text">空闲链表法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BD%8D%E5%9B%BE%E6%B3%95"><span class="post-toc-text">位图法</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-6-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%BB%93%E6%9E%84"><span class="post-toc-text">4.6 文件系统的结构</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-7-%E7%9B%AE%E5%BD%95%E7%9A%84%E5%AD%98%E5%82%A8"><span class="post-toc-text">4.7 目录的存储</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-8-%E8%BD%AF%E9%93%BE%E6%8E%A5%E5%92%8C%E7%A1%AC%E9%93%BE%E6%8E%A5"><span class="post-toc-text">4.8 软链接和硬链接</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-9-%E6%96%87%E4%BB%B6-I-O"><span class="post-toc-text">4.9 文件 I&#x2F;O</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%BC%93%E5%86%B2%E4%B8%8E%E9%9D%9E%E7%BC%93%E5%86%B2-I-O"><span class="post-toc-text">缓冲与非缓冲 I&#x2F;O</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E7%9B%B4%E6%8E%A5%E4%B8%8E%E9%9D%9E%E7%9B%B4%E6%8E%A5-I-O"><span class="post-toc-text">直接与非直接 I&#x2F;O</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%98%BB%E5%A1%9E%E4%B8%8E%E9%9D%9E%E9%98%BB%E5%A1%9E-I-O-VS-%E5%90%8C%E6%AD%A5%E4%B8%8E%E5%BC%82%E6%AD%A5-I-O"><span class="post-toc-text">阻塞与非阻塞 I&#x2F;O VS 同步与异步 I&#x2F;O</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-10-Page-Cache"><span class="post-toc-text">4.10 Page Cache</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="post-toc-text">介绍</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#page-%E4%B8%8E-Page-Cache"><span class="post-toc-text">page 与 Page Cache</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Swap-%E4%B8%8E%E7%BC%BA%E9%A1%B5%E4%B8%AD%E6%96%AD"><span class="post-toc-text">Swap 与缺页中断</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Page-Cache-%E4%B8%8E-buffer-cache"><span class="post-toc-text">Page Cache 与 buffer cache</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Page-Cache-%E4%B8%8E%E9%A2%84%E8%AF%BB"><span class="post-toc-text">Page Cache 与预读</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Page-Cache-%E4%B8%8E%E6%96%87%E4%BB%B6%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E5%92%8C%E5%8F%AF%E9%9D%A0%E6%80%A7"><span class="post-toc-text">Page Cache 与文件持久化的一致性和可靠性</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Page-Cache-%E7%9A%84%E4%BC%98%E5%8A%A3%E5%8A%BF"><span class="post-toc-text">Page Cache 的优劣势</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E8%BF%9B%E7%A8%8B%E5%86%99%E6%96%87%E4%BB%B6%E6%97%B6%EF%BC%8C%E8%BF%9B%E7%A8%8B%E5%8F%91%E7%94%9F%E4%BA%86%E5%B4%A9%E6%BA%83%EF%BC%8C%E5%B7%B2%E5%86%99%E5%85%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BC%9A%E4%B8%A2%E5%A4%B1%E5%90%97%EF%BC%9F"><span class="post-toc-text">进程写文件时，进程发生了崩溃，已写入的数据会丢失吗？</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#4-11-%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95"><span class="post-toc-text">4.11 磁盘调度算法</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1"><span class="post-toc-text">先来先服务</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%9C%80%E7%9F%AD%E5%AF%BB%E9%81%93%E6%97%B6%E9%97%B4%E4%BC%98%E5%85%88"><span class="post-toc-text">最短寻道时间优先</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95"><span class="post-toc-text">扫描算法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%BE%AA%E7%8E%AF%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95"><span class="post-toc-text">循环扫描算法</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#LOOK-%E4%B8%8E-C-LOOK%E7%AE%97%E6%B3%95"><span class="post-toc-text">LOOK 与 C-LOOK算法</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#5-%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86"><span class="post-toc-text">5 设备管理</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-1-%E8%AE%BE%E5%A4%87%E6%8E%A7%E5%88%B6%E5%99%A8"><span class="post-toc-text">5.1 设备控制器</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-2-I-O-%E6%8E%A7%E5%88%B6%E6%96%B9%E5%BC%8F"><span class="post-toc-text">5.2 I&#x2F;O 控制方式</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-3-%E8%AE%BE%E5%A4%87%E9%A9%B1%E5%8A%A8%E7%A8%8B%E5%BA%8F"><span class="post-toc-text">5.3 设备驱动程序</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-4-%E9%80%9A%E7%94%A8%E5%9D%97%E5%B1%82"><span class="post-toc-text">5.4 通用块层</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#5-5-%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F-I-O-%E8%BD%AF%E4%BB%B6%E5%88%86%E5%B1%82"><span class="post-toc-text">5.5 存储系统 I&#x2F;O 软件分层</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#6-%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F"><span class="post-toc-text">6 网络系统</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-1-DMA-amp-%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="post-toc-text">6.1 DMA &amp; 零拷贝</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#DMA%E4%BB%8B%E7%BB%8D"><span class="post-toc-text">DMA介绍</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BC%A0%E7%BB%9F%E7%9A%84%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93"><span class="post-toc-text">传统的文件传输</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E7%9A%84%E6%80%A7%E8%83%BD%EF%BC%9F"><span class="post-toc-text">如何优化文件传输的性能？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E9%9B%B6%E6%8B%B7%E8%B4%9D"><span class="post-toc-text">零拷贝</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#mmap-write"><span class="post-toc-text">mmap + write</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#sendfile"><span class="post-toc-text">sendfile</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#PageCache-%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="post-toc-text">PageCache 有什么作用？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A4%A7%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E7%94%A8%E4%BB%80%E4%B9%88%E6%96%B9%E5%BC%8F%E5%AE%9E%E7%8E%B0%EF%BC%9F"><span class="post-toc-text">大文件传输用什么方式实现？</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-2-I-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-amp-select-poll-epoll"><span class="post-toc-text">6.2 I&#x2F;O 多路复用 &amp; select&#x2F;poll&#x2F;epoll</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%9C%80%E5%9F%BA%E6%9C%AC%E7%9A%84-Socket-%E6%A8%A1%E5%9E%8B"><span class="post-toc-text">最基本的 Socket 模型</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E6%9C%8D%E5%8A%A1%E6%9B%B4%E5%A4%9A%E7%9A%84%E7%94%A8%E6%88%B7%EF%BC%9F"><span class="post-toc-text">如何服务更多的用户？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="post-toc-text">多进程模型</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B"><span class="post-toc-text">多线程模型</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#I-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="post-toc-text">I&#x2F;O 多路复用</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#select-poll"><span class="post-toc-text">select&#x2F;poll</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#epoll"><span class="post-toc-text">epoll</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E8%BE%B9%E7%BC%98%E8%A7%A6%E5%8F%91%E5%92%8C%E6%B0%B4%E5%B9%B3%E8%A7%A6%E5%8F%91"><span class="post-toc-text">边缘触发和水平触发</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-3-%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%EF%BC%9AReactor-%E5%92%8C-Proactor"><span class="post-toc-text">6.3 高性能网络模式：Reactor 和 Proactor</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E6%BC%94%E8%BF%9B"><span class="post-toc-text">演进</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Reactor"><span class="post-toc-text">Reactor</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%8D%95-Reactor-%E5%8D%95%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B"><span class="post-toc-text">单 Reactor 单进程 &#x2F; 线程</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%8D%95-Reactor-%E5%A4%9A%E7%BA%BF%E7%A8%8B-%E5%A4%9A%E8%BF%9B%E7%A8%8B"><span class="post-toc-text">单 Reactor 多线程 &#x2F; 多进程</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#%E5%A4%9A-Reactor-%E5%A4%9A%E8%BF%9B%E7%A8%8B-%E7%BA%BF%E7%A8%8B"><span class="post-toc-text">多 Reactor 多进程 &#x2F; 线程</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Proactor"><span class="post-toc-text">Proactor</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#6-4-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C"><span class="post-toc-text">6.4 一致性哈希</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E5%88%86%E9%85%8D%E8%AF%B7%E6%B1%82%EF%BC%9F"><span class="post-toc-text">如何分配请求？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BD%BF%E7%94%A8%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="post-toc-text">使用哈希算法有什么问题？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E4%BD%BF%E7%94%A8%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98%EF%BC%9F"><span class="post-toc-text">使用一致性哈希算法有什么问题？</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#%E5%A6%82%E4%BD%95%E9%80%9A%E8%BF%87%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9%E6%8F%90%E9%AB%98%E5%9D%87%E8%A1%A1%E5%BA%A6%EF%BC%9F"><span class="post-toc-text">如何通过虚拟节点提高均衡度？</span></a></li></ol></li></ol></li></ol>
        </nav>
    </aside>
    

<nav id="article-nav">
  
    <a href="/2022/12/17/Lifelong%20Learning/Photography/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BD%9C%E6%91%84%E5%BD%B1%E5%89%8D%E6%9C%9F%E6%8B%8D%E6%91%84%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          学习笔记｜摄影前期拍摄入门教程
        
      </span>
    </a>
  
  
    <a href="/2022/10/15/Programming/Methodology/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">设计模式</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>



    
        <div id="SOHUCS" sid="Computer Science/Operating System/图解系统" ></div>
<script type="text/javascript">
    (function(){
        var appid = 'cyvaQ34l4';
        var conf = 'dfbc2f31fdc91ffc75e2035195b4426d';
        var width = window.innerWidth || document.documentElement.clientWidth;
        if (width < 960) {
            window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); } })(); </script>
    
</section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    |
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
    <div class="theme-info">
</p>


      <span class="post-count">本站博文总字数：701.5k</span>
      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2018~2023 MU Quanrui<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>

<!--加载prettify代码高亮js-->
  <script type="text/javascript" src="/google-code-prettify/prettify.js"></script>
  <script type="text/javascript">
    $(document).ready(function(){
      $('pre').addClass('prettyprint linenums');
      $('code').addClass('prettyprint');
      prettyPrint();
    })
  </script>

<script>
  var mihoConfig = {
      root: "http://muquanrui.com",
      animate: true,
      isHome: false,
      share: true,
      reward: 1
  }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-tag" title="Tags">
        <i class="fa fa-tags"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/Blog/">Blog</a><a class="category-link" href="/categories/Data-Structures-Algorithms/">Data Structures & Algorithms</a><a class="category-link" href="/categories/Database/">Database</a><a class="category-link" href="/categories/ENSEEIHT/">ENSEEIHT</a><a class="category-link" href="/categories/Framework/">Framework</a><a class="category-link" href="/categories/Franc%CC%A7ais/">Français</a><a class="category-link" href="/categories/Java-Project/">Java Project</a><a class="category-link" href="/categories/Java-Tutorial/">Java Tutorial</a><a class="category-link" href="/categories/Linux/">Linux</a><a class="category-link" href="/categories/Methodology/">Methodology</a><a class="category-link" href="/categories/Middleware/">Middleware</a><a class="category-link" href="/categories/Network/">Network</a><a class="category-link" href="/categories/Operating-System/">Operating System</a><a class="category-link" href="/categories/Photography/">Photography</a><a class="category-link" href="/categories/Problem-Solving/">Problem Solving</a><a class="category-link" href="/categories/Software/">Software</a><a class="category-link" href="/categories/Tech-Note/">Tech Note</a><a class="category-link" href="/categories/macOS/">macOS</a><a class="category-link" href="/categories/%E5%A2%93%E7%95%94%E5%9B%9E%E5%BF%86%E5%BD%95/">墓畔回忆录</a><a class="category-link" href="/categories/%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/">我的大学</a><a class="category-link" href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/">读书笔记</a>
        </div>
        <div id="sidebar-menu-box-tags">
            <a href="/tags/Blog/" style="font-size: 13.53px;">Blog</a> <a href="/tags/College/" style="font-size: 18.24px;">College</a> <a href="/tags/Computer-Science/" style="font-size: 18.82px;">Computer Science</a> <a href="/tags/Data-Structures-Algorithms/" style="font-size: 10.59px;">Data Structures & Algorithms</a> <a href="/tags/Database/" style="font-size: 12.94px;">Database</a> <a href="/tags/ENSEEIHT/" style="font-size: 14.12px;">ENSEEIHT</a> <a href="/tags/Framework/" style="font-size: 11.76px;">Framework</a> <a href="/tags/Franc%CC%A7ais/" style="font-size: 14.71px;">Français</a> <a href="/tags/Java-Project/" style="font-size: 10px;">Java Project</a> <a href="/tags/Java-Tutorial/" style="font-size: 19.41px;">Java Tutorial</a> <a href="/tags/Java%E5%9F%BA%E7%A1%80/" style="font-size: 18.82px;">Java基础</a> <a href="/tags/Java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8D%B7I/" style="font-size: 14.71px;">Java核心技术卷I</a> <a href="/tags/Lifelong-Learning/" style="font-size: 16.47px;">Lifelong Learning</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Methodology/" style="font-size: 11.76px;">Methodology</a> <a href="/tags/Middleware/" style="font-size: 10.59px;">Middleware</a> <a href="/tags/MySQL/" style="font-size: 10.59px;">MySQL</a> <a href="/tags/Network/" style="font-size: 15.29px;">Network</a> <a href="/tags/Notes/" style="font-size: 15.88px;">Notes</a> <a href="/tags/Operating-System/" style="font-size: 13.53px;">Operating System</a> <a href="/tags/Photography/" style="font-size: 10px;">Photography</a> <a href="/tags/Problem-Solving/" style="font-size: 11.18px;">Problem Solving</a> <a href="/tags/Programming/" style="font-size: 20px;">Programming</a> <a href="/tags/Software/" style="font-size: 10px;">Software</a> <a href="/tags/Spring/" style="font-size: 10.59px;">Spring</a> <a href="/tags/Tech-Note/" style="font-size: 11.76px;">Tech Note</a> <a href="/tags/macOS/" style="font-size: 11.18px;">macOS</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91UML/" style="font-size: 11.76px;">【大学课程】UML</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10.59px;">【大学课程】操作系统</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" style="font-size: 11.76px;">【大学课程】数据库系统</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E9%80%9A%E4%BF%A1/" style="font-size: 11.76px;">【大学课程】计算机接口与通信</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 11.18px;">【大学课程】计算机网络</a> <a href="/tags/%E3%80%90%E5%B0%9A%E7%A1%85%E8%B0%B7%E3%80%91Java/" style="font-size: 17.06px;">【尚硅谷】Java</a> <a href="/tags/%E3%80%90%E7%8E%8B%E9%81%93%E8%80%83%E7%A0%94%E3%80%91%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 12.35px;">【王道考研】操作系统</a> <a href="/tags/%E3%80%90%E7%8E%8B%E9%81%93%E8%80%83%E7%A0%94%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 12.94px;">【王道考研】计算机网络</a> <a href="/tags/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF%EF%BC%9A%E4%BB%8E%E7%A0%81%E5%86%9C%E5%88%B0%E5%B7%A5%E5%8C%A0/" style="font-size: 11.18px;">代码精进之路：从码农到工匠</a> <a href="/tags/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/" style="font-size: 11.76px;">图解网络</a> <a href="/tags/%E5%A2%93%E7%95%94%E5%9B%9E%E5%BF%86%E5%BD%95/" style="font-size: 10.59px;">墓畔回忆录</a> <a href="/tags/%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/" style="font-size: 17.65px;">我的大学</a> <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" style="font-size: 10.59px;">读书笔记</a>
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories">
                    <i class="fa fa-book"></i><span>Categories</span>
                </a>
            </li>
            
            <li>
                <a  href="/tags">
                    <i class="fa fa-tags"></i><span>Tags</span>
                </a>
            </li>
            
            <li>
                <a  href="/about">
                    <i class="fa fa-user"></i><span>About</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            <a href="/tags/Blog/" style="font-size: 13.53px;">Blog</a> <a href="/tags/College/" style="font-size: 18.24px;">College</a> <a href="/tags/Computer-Science/" style="font-size: 18.82px;">Computer Science</a> <a href="/tags/Data-Structures-Algorithms/" style="font-size: 10.59px;">Data Structures & Algorithms</a> <a href="/tags/Database/" style="font-size: 12.94px;">Database</a> <a href="/tags/ENSEEIHT/" style="font-size: 14.12px;">ENSEEIHT</a> <a href="/tags/Framework/" style="font-size: 11.76px;">Framework</a> <a href="/tags/Franc%CC%A7ais/" style="font-size: 14.71px;">Français</a> <a href="/tags/Java-Project/" style="font-size: 10px;">Java Project</a> <a href="/tags/Java-Tutorial/" style="font-size: 19.41px;">Java Tutorial</a> <a href="/tags/Java%E5%9F%BA%E7%A1%80/" style="font-size: 18.82px;">Java基础</a> <a href="/tags/Java%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E5%8D%B7I/" style="font-size: 14.71px;">Java核心技术卷I</a> <a href="/tags/Lifelong-Learning/" style="font-size: 16.47px;">Lifelong Learning</a> <a href="/tags/Linux/" style="font-size: 10px;">Linux</a> <a href="/tags/Methodology/" style="font-size: 11.76px;">Methodology</a> <a href="/tags/Middleware/" style="font-size: 10.59px;">Middleware</a> <a href="/tags/MySQL/" style="font-size: 10.59px;">MySQL</a> <a href="/tags/Network/" style="font-size: 15.29px;">Network</a> <a href="/tags/Notes/" style="font-size: 15.88px;">Notes</a> <a href="/tags/Operating-System/" style="font-size: 13.53px;">Operating System</a> <a href="/tags/Photography/" style="font-size: 10px;">Photography</a> <a href="/tags/Problem-Solving/" style="font-size: 11.18px;">Problem Solving</a> <a href="/tags/Programming/" style="font-size: 20px;">Programming</a> <a href="/tags/Software/" style="font-size: 10px;">Software</a> <a href="/tags/Spring/" style="font-size: 10.59px;">Spring</a> <a href="/tags/Tech-Note/" style="font-size: 11.76px;">Tech Note</a> <a href="/tags/macOS/" style="font-size: 11.18px;">macOS</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91UML/" style="font-size: 11.76px;">【大学课程】UML</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 10.59px;">【大学课程】操作系统</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B3%BB%E7%BB%9F/" style="font-size: 11.76px;">【大学课程】数据库系统</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8E%A5%E5%8F%A3%E4%B8%8E%E9%80%9A%E4%BF%A1/" style="font-size: 11.76px;">【大学课程】计算机接口与通信</a> <a href="/tags/%E3%80%90%E5%A4%A7%E5%AD%A6%E8%AF%BE%E7%A8%8B%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 11.18px;">【大学课程】计算机网络</a> <a href="/tags/%E3%80%90%E5%B0%9A%E7%A1%85%E8%B0%B7%E3%80%91Java/" style="font-size: 17.06px;">【尚硅谷】Java</a> <a href="/tags/%E3%80%90%E7%8E%8B%E9%81%93%E8%80%83%E7%A0%94%E3%80%91%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" style="font-size: 12.35px;">【王道考研】操作系统</a> <a href="/tags/%E3%80%90%E7%8E%8B%E9%81%93%E8%80%83%E7%A0%94%E3%80%91%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" style="font-size: 12.94px;">【王道考研】计算机网络</a> <a href="/tags/%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF%EF%BC%9A%E4%BB%8E%E7%A0%81%E5%86%9C%E5%88%B0%E5%B7%A5%E5%8C%A0/" style="font-size: 11.18px;">代码精进之路：从码农到工匠</a> <a href="/tags/%E5%9B%BE%E8%A7%A3%E7%BD%91%E7%BB%9C/" style="font-size: 11.76px;">图解网络</a> <a href="/tags/%E5%A2%93%E7%95%94%E5%9B%9E%E5%BF%86%E5%BD%95/" style="font-size: 10.59px;">墓畔回忆录</a> <a href="/tags/%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6/" style="font-size: 17.65px;">我的大学</a> <a href="/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" style="font-size: 10.59px;">读书笔记</a>
        </div>
    </div>
</div>
<div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>

<script src="/js/search.js"></script>


<script src="/js/main.js"></script>









  
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  <script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script>
  
<script src="/js/animate.js"></script>



  
<script src="/js/pop-img.js"></script>

  <script>
     $(".article-entry p img").popImg();
  </script>

  </div>
  <!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/love.js"></script>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/z16.model.json"},"display":{"position":"right","width":200,"height":400,"vOffset":-30},"mobile":{"show":false},"react":{"opacity":0.8},"log":false});</script></body>
</html>



